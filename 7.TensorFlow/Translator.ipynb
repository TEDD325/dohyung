{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0000 cost: 3.7452\n",
      "epoch: 0001 cost: 2.6045\n",
      "epoch: 0002 cost: 1.4894\n",
      "epoch: 0003 cost: 1.3045\n",
      "epoch: 0004 cost: 0.7632\n",
      "epoch: 0005 cost: 0.5393\n",
      "epoch: 0006 cost: 0.6049\n",
      "epoch: 0007 cost: 0.3859\n",
      "epoch: 0008 cost: 0.2063\n",
      "epoch: 0009 cost: 0.3731\n",
      "epoch: 0010 cost: 0.1874\n",
      "epoch: 0011 cost: 0.1958\n",
      "epoch: 0012 cost: 0.2331\n",
      "epoch: 0013 cost: 0.0930\n",
      "epoch: 0014 cost: 0.1765\n",
      "epoch: 0015 cost: 0.0428\n",
      "epoch: 0016 cost: 0.0727\n",
      "epoch: 0017 cost: 0.1663\n",
      "epoch: 0018 cost: 0.0993\n",
      "epoch: 0019 cost: 0.0732\n",
      "epoch: 0020 cost: 0.0862\n",
      "epoch: 0021 cost: 0.0622\n",
      "epoch: 0022 cost: 0.0131\n",
      "epoch: 0023 cost: 0.0185\n",
      "epoch: 0024 cost: 0.0076\n",
      "epoch: 0025 cost: 0.0196\n",
      "epoch: 0026 cost: 0.0484\n",
      "epoch: 0027 cost: 0.0245\n",
      "epoch: 0028 cost: 0.0074\n",
      "epoch: 0029 cost: 0.0040\n",
      "epoch: 0030 cost: 0.0052\n",
      "epoch: 0031 cost: 0.0076\n",
      "epoch: 0032 cost: 0.0043\n",
      "epoch: 0033 cost: 0.0188\n",
      "epoch: 0034 cost: 0.0073\n",
      "epoch: 0035 cost: 0.0016\n",
      "epoch: 0036 cost: 0.0022\n",
      "epoch: 0037 cost: 0.0031\n",
      "epoch: 0038 cost: 0.0038\n",
      "epoch: 0039 cost: 0.0111\n",
      "epoch: 0040 cost: 0.0031\n",
      "epoch: 0041 cost: 0.0059\n",
      "epoch: 0042 cost: 0.0020\n",
      "epoch: 0043 cost: 0.0051\n",
      "epoch: 0044 cost: 0.0013\n",
      "epoch: 0045 cost: 0.0014\n",
      "epoch: 0046 cost: 0.0009\n",
      "epoch: 0047 cost: 0.0010\n",
      "epoch: 0048 cost: 0.0020\n",
      "epoch: 0049 cost: 0.0023\n",
      "epoch: 0050 cost: 0.0012\n",
      "epoch: 0051 cost: 0.0051\n",
      "epoch: 0052 cost: 0.0021\n",
      "epoch: 0053 cost: 0.0038\n",
      "epoch: 0054 cost: 0.0010\n",
      "epoch: 0055 cost: 0.0019\n",
      "epoch: 0056 cost: 0.0008\n",
      "epoch: 0057 cost: 0.0004\n",
      "epoch: 0058 cost: 0.0003\n",
      "epoch: 0059 cost: 0.0010\n",
      "epoch: 0060 cost: 0.0030\n",
      "epoch: 0061 cost: 0.0030\n",
      "epoch: 0062 cost: 0.0009\n",
      "epoch: 0063 cost: 0.0017\n",
      "epoch: 0064 cost: 0.0006\n",
      "epoch: 0065 cost: 0.0005\n",
      "epoch: 0066 cost: 0.0009\n",
      "epoch: 0067 cost: 0.0004\n",
      "epoch: 0068 cost: 0.0019\n",
      "epoch: 0069 cost: 0.0008\n",
      "epoch: 0070 cost: 0.0026\n",
      "epoch: 0071 cost: 0.0027\n",
      "epoch: 0072 cost: 0.0005\n",
      "epoch: 0073 cost: 0.0009\n",
      "epoch: 0074 cost: 0.0011\n",
      "epoch: 0075 cost: 0.0016\n",
      "epoch: 0076 cost: 0.0010\n",
      "epoch: 0077 cost: 0.0007\n",
      "epoch: 0078 cost: 0.0007\n",
      "epoch: 0079 cost: 0.0002\n",
      "epoch: 0080 cost: 0.0005\n",
      "epoch: 0081 cost: 0.0002\n",
      "epoch: 0082 cost: 0.0006\n",
      "epoch: 0083 cost: 0.0006\n",
      "epoch: 0084 cost: 0.0002\n",
      "epoch: 0085 cost: 0.0002\n",
      "epoch: 0086 cost: 0.0004\n",
      "epoch: 0087 cost: 0.0003\n",
      "epoch: 0088 cost: 0.0004\n",
      "epoch: 0089 cost: 0.0015\n",
      "epoch: 0090 cost: 0.0009\n",
      "epoch: 0091 cost: 0.0008\n",
      "epoch: 0092 cost: 0.0001\n",
      "epoch: 0093 cost: 0.0002\n",
      "epoch: 0094 cost: 0.0003\n",
      "epoch: 0095 cost: 0.0021\n",
      "epoch: 0096 cost: 0.0014\n",
      "epoch: 0097 cost: 0.0006\n",
      "epoch: 0098 cost: 0.0004\n",
      "epoch: 0099 cost: 0.0005\n",
      "input: [['word', '단어']]\n",
      "model\n",
      " [[[-1.74078989e+00  1.66493189e+00 -8.95577669e-01  6.63071930e-01\n",
      "   -2.73027152e-01 -3.40241075e+00 -1.61078930e+00 -2.52590108e+00\n",
      "   -2.59861350e-01 -9.99241233e-01 -1.40483856e+00 -1.08150756e+00\n",
      "   -2.60343194e-01  3.35953712e-01 -6.90105617e-01 -1.21224034e+00\n",
      "   -3.56391221e-02  6.41362131e-01 -8.20629716e-01 -3.76066279e+00\n",
      "   -1.90157199e+00 -1.80331790e+00 -4.73420322e-03  5.32495081e-02\n",
      "    4.31051105e-02 -8.13850939e-01 -2.98416710e+00  1.11728266e-01\n",
      "   -2.77126145e+00  1.53665390e+01 -4.71394396e+00  5.54033613e+00\n",
      "    7.24436760e-01 -1.10461032e+00 -3.06738186e+00  3.50424504e+00\n",
      "   -2.28689098e+00  1.02746642e+00 -7.40977430e+00  1.42933547e+00\n",
      "   -3.77402282e+00]\n",
      "  [ 1.99839383e-01 -2.11309314e+00 -1.02141261e+00 -2.32286501e+00\n",
      "   -1.88769251e-01  1.26063272e-01 -3.20959854e+00 -3.96655273e+00\n",
      "   -5.96017122e-01 -1.80651116e+00 -1.71941185e+00 -1.79752064e+00\n",
      "   -2.76997995e+00  1.25155675e+00 -3.85555434e+00 -1.19174933e+00\n",
      "   -1.96405840e+00 -2.94826961e+00 -1.63985729e+00 -1.32044828e+00\n",
      "   -2.49407268e+00 -3.56107092e+00 -3.81597662e+00 -2.05777907e+00\n",
      "   -2.12384343e+00 -2.52414727e+00 -1.24603796e+00 -4.20443964e+00\n",
      "   -7.56376565e-01 -1.03706181e+00  1.50250263e+01 -7.71241248e-01\n",
      "    8.14174354e-01 -4.68592852e-01 -3.49851370e+00 -2.15893698e+00\n",
      "    3.98243141e+00 -2.79584503e+00 -3.15466714e+00  8.44588041e-01\n",
      "    3.07289982e+00]\n",
      "  [-2.25062847e+00  1.69266033e+01 -3.84056830e+00 -3.33753538e+00\n",
      "   -1.53349578e+00 -8.56472909e-01 -1.40166342e+00 -2.35284901e+00\n",
      "   -2.99833870e+00 -3.00078797e+00 -1.40876269e+00 -4.59220600e+00\n",
      "   -3.14727378e+00 -2.68930244e+00 -2.43087959e+00 -3.71446443e+00\n",
      "   -1.15042913e+00 -1.47920334e+00 -2.40482187e+00  1.12357780e-01\n",
      "   -2.71701479e+00 -3.69689035e+00 -3.95397842e-03 -2.93334651e+00\n",
      "   -1.50162327e+00 -2.54146290e+00 -1.76417470e+00 -2.67966223e+00\n",
      "   -6.42211318e-01 -1.91690981e-01  1.10515201e+00  5.33594310e-01\n",
      "   -1.40548897e+00 -4.46658731e-02 -3.09294724e+00 -1.32019675e+00\n",
      "   -1.79321170e-01 -1.39183295e+00 -1.25113988e+00 -3.15431356e+00\n",
      "   -5.41538239e-01]]]\n",
      "target: [[29 30  1]]\n",
      "\n",
      "english: word , result: [29 30  1] , korean: 단어\n",
      "english: wodr , result: [31 32  1] , korean: 나무\n",
      "english: love , result: [39 40  1] , korean: 사랑\n",
      "english: loev , result: [39 40  1] , korean: 사랑\n",
      "english: abcd , result: [29 30  1] , korean: 단어\n",
      "english: wide , result: [35 36  1] , korean: 소녀\n",
      "english: gate , result: [33 34  1] , korean: 놀이\n"
     ]
    }
   ],
   "source": [
    "# English to Korean Translation with Tensorflow RNN\n",
    "# written by Sung Kyu Lim\n",
    "# limsk@ece.gatech.edu\n",
    "# 1/7/2019\n",
    "\n",
    "\n",
    "# import related packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "\n",
    "# 41 characters used in the dictionary\n",
    "# S, E, and P are special characters used in RNN\n",
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz단어나무놀이소녀키스사랑']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)\n",
    "n_class = n_input = dic_len\n",
    "\n",
    "\n",
    "# training data\n",
    "# the english word should be of length 4, and the korean 2\n",
    "seq_data = [['word', '단어'], ['wood', '나무'], ['game', '놀이'], ['girl', '소녀'], ['kiss', '키스'], ['love', '사랑']]\n",
    "\n",
    "\n",
    "# one-hot encoding function\n",
    "def make_batch(seq_data):\n",
    "    input_batch = []\n",
    "    output_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        input = [num_dic[n] for n in seq[0]]\n",
    "        output = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]\n",
    "\n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "        output_batch.append(np.eye(dic_len)[output])\n",
    "        target_batch.append(target)\n",
    "\n",
    "    return input_batch, output_batch, target_batch\n",
    "\n",
    "\n",
    "# global parameters\n",
    "learning_rate = 0.01\n",
    "n_hidden = 128\n",
    "total_epoch = 100\n",
    "\n",
    "\n",
    "# in Seq2Seq RNN, we use the following placeholder type\n",
    "# for the encoder and decoder:\n",
    "# [batch size, time steps, input size]\n",
    "enc_input = tf.placeholder(tf.float32, [None, None, n_input])\n",
    "dec_input = tf.placeholder(tf.float32, [None, None, n_input])\n",
    "\n",
    "\n",
    "# in Seq2Seq RNN, we use the following placeholder type\n",
    "# for the output: [batch size, time steps]\n",
    "targets = tf.placeholder(tf.int64, [None, None])\n",
    "\n",
    "\n",
    "# encoder cell definition\n",
    "# we use dropout to avoid overfitting\n",
    "with tf.variable_scope('encode'):\n",
    "    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
    "    _ , enc_states = tf.nn.dynamic_rnn(enc_cell, enc_input, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# decoder cell definition\n",
    "# we use dropout to avoid overfitting\n",
    "with tf.variable_scope('decode'):\n",
    "    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n",
    "\n",
    "    # in Seq2Seq model, we use the encoder output state\n",
    "    # as the initial state for the decoder\n",
    "    dec_outputs, _ = tf.nn.dynamic_rnn(dec_cell, dec_input, initial_state=enc_states, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# instead of tf.matmul(outputs, W)+b, \n",
    "# we use the 'dense' function in tensorflow layers:\n",
    "# 'dense' produces [batch_size, time_step, input_size]\n",
    "# in our case, model shape is (?, ?, 41)\n",
    "model = tf.layers.dense(dec_outputs, n_class, activation=None)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=targets))\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "# print model and target information\n",
    "def info():\n",
    "    sample = [['word', '단어']]\n",
    "    input_batch, output_batch, target_batch = make_batch(sample)\n",
    "    m_info, t_info = sess.run([model, targets], feed_dict = {enc_input: input_batch, \n",
    "        dec_input: output_batch, targets: target_batch})\n",
    "\n",
    "    print('input:', sample)\n",
    "    print('model\\n', m_info)\n",
    "    print('target:', t_info)\n",
    "    print()\n",
    "\n",
    "\n",
    "# training session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "input_batch, output_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([opt, cost], feed_dict={enc_input: input_batch, dec_input: output_batch, \n",
    "        targets: target_batch})\n",
    "    print('epoch: %04d' % epoch, 'cost: %.4f' % loss)\n",
    "\n",
    "info()\n",
    "\n",
    "\n",
    "# test new words\n",
    "new_data = [['word', 'PP'], ['wodr', 'PP'], ['love', 'PP'], ['loev', 'PP'], ['abcd', 'PP'], \n",
    "    ['wide', 'PP'], ['gate', 'PP']]\n",
    "input_batch, output_batch, target_batch = make_batch(new_data)\n",
    "prediction = tf.argmax(model, 2)\n",
    "result = sess.run(prediction, feed_dict = {enc_input: input_batch, dec_input: output_batch, \n",
    "    targets: target_batch})\n",
    "\n",
    "for i in range(len(new_data)):\n",
    "    decoded = [char_arr[i] for i in result[i]]\n",
    "    korean = decoded[0] + decoded[1]\n",
    "    print('english:', new_data[i][0], ', result:', result[i], ', korean:', korean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
