{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=2, random_state=None, shuffle=False)\n",
      "TRAIN: [2 3] TEST: [0 1]\n",
      "[[5 6]\n",
      " [7 8]] [3 4]\n",
      "[[1 2]\n",
      " [3 4]] [1 2]\n",
      "이거가지고 한 번 훈련,,/\n",
      "TRAIN: [0 1] TEST: [2 3]\n",
      "[[1 2]\n",
      " [3 4]] [1 2]\n",
      "[[5 6]\n",
      " [7 8]] [3 4]\n",
      "이거가지고 한 번 훈련,,/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]]) # 훈련데이터\n",
    "y = np.array([1, 2, 3, 4]) # 정답데이터. 일대칭 매칭\n",
    "kf = KFold(n_splits=2) # 모듈 활용. 크로스 밸리데이터를 만들어놓는다. 폴드란 파티션이다.\n",
    "kf.get_n_splits(X) #훈련데이터를 두 개로 분할해서 들고 있는다.\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "for train_index, test_index in kf.split(X): # 분할된 결과 인덱스를 가지고 있는다.\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index) \n",
    "    X_train, X_test = X[train_index], X[test_index]#실제 내용을 가져옴.\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train, y_train)\n",
    "    print(X_test, y_test)\n",
    "    print(\"이거가지고 한 번 훈련,,/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# https://medium.com/towards-data-science/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "\n",
    "import numpy as np\n",
    "import datasource.data as data\n",
    "import os\n",
    "import gzip\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(__file__)) + '/'\n",
    "MNIST_DIR = ROOT_DIR + \"mnist\"\n",
    "FASHION_MNIST_DIR = ROOT_DIR + \"fashion_mnist\"\n",
    "\n",
    "\n",
    "def convertToOneHot(vector, num_classes=None):\n",
    "    \"\"\"\n",
    "    Converts an input 1-D vector of integers into an output\n",
    "    2-D array of one-hot vectors, where an i'th input value\n",
    "    of j will set a '1' in the i'th row, j'th column of the\n",
    "    output array.\n",
    "\n",
    "    Example:\n",
    "        v = np.array([1, 0, 4])\n",
    "        one_hot_v = convertToOneHot(v)\n",
    "        print one_hot_v\n",
    "\n",
    "        [[0 1 0 0 0]\n",
    "         [1 0 0 0 0]\n",
    "         [0 0 0 0 1]]\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(vector, np.ndarray)\n",
    "    assert len(vector) > 0\n",
    "\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(vector)+1\n",
    "    else:\n",
    "        assert num_classes > 0\n",
    "        assert num_classes >= np.max(vector)\n",
    "\n",
    "    t = np.zeros((vector.size, num_classes), dtype=np.float64)\n",
    "    for idx, row in enumerate(t):\n",
    "        row[int(vector[idx])] = 1.0\n",
    "    return t\n",
    "\n",
    "\n",
    "class MNIST_Data(data.Base_Data):\n",
    "    # http://yann.lecun.com/exdb/mnist/\n",
    "    def __init__(self, validation_size=5000, n_splits=1, is_onehot_target=True):\n",
    "        super().__init__(n_splits)\n",
    "        # 앤스플릿 디폴트값이 1. 나중에 12를 줄 예정이다.\n",
    "        # 테스트는 테스트용일뿐. 옵티마이저시엔 사용노. 주어질수도, 안주어질수도 있는 데이터\n",
    "        # 트레인만으로 훈련시켜야하는데 잘됐는지 검증하기 위해 벨리데이션이 필요한 것\n",
    "        # 예를 들면 55000개를 순수 트레인데이터 5000개를 벨리데이션으로 쓰는 식이다.\n",
    "\n",
    "        self.validation_size = validation_size\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "        self.images, self.targets = load_mnist(path=MNIST_DIR, kind='train')#트레인데이터를 의미\n",
    "        self.test_input, self.test_target = load_mnist(path=MNIST_DIR, kind='t10k')#테스트데이터를 의미\n",
    "        self.num_test_data = len(self.test_input)\n",
    "\n",
    "        self.labels = ['Zero', 'One', 'Two', 'Three', 'Four',\n",
    "                       'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
    "\n",
    "        if is_onehot_target:\n",
    "            self.targets = convertToOneHot(self.targets, num_classes=10)\n",
    "\n",
    "        self.reset_kfold()\n",
    "\n",
    "        self.num_train_data = len(self.images) - validation_size\n",
    "        self.num_validation_data = validation_size\n",
    "\n",
    "    def reset_kfold(self):\n",
    "        if self.n_splits == 1:\n",
    "            self.validation_input = self.images[:self.validation_size]# 처음부분부터 벨리데이션을 나눈 것.\n",
    "            self.validation_target = self.targets[:self.validation_size]\n",
    "\n",
    "            self.train_input = self.images[self.validation_size:]\n",
    "            self.train_target = self.targets[self.validation_size:]\n",
    "        else:\n",
    "            kf = KFold(n_splits=self.n_splits)\n",
    "            self.splitted_indices = kf.split(self.images)#6만개를 스플릿해주면 인덱스발생\n",
    "\n",
    "class Fashion_MNIST_Data(data.Base_Data):\n",
    "    # https://github.com/zalandoresearch/fashion-mnist\n",
    "    def __init__(self, validation_size=5000, n_splits=1, is_onehot_target=True):\n",
    "        super().__init__(n_splits)\n",
    "\n",
    "        self.validation_size = validation_size\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "        self.images, self.targets = load_mnist(path=FASHION_MNIST_DIR, kind='train')\n",
    "        self.test_input, self.test_target = load_mnist(path=MNIST_DIR, kind='t10k')\n",
    "        self.num_test_data = len(self.test_input)\n",
    "\n",
    "        self.labels = ['t_shirt_top', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                       'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']\n",
    "\n",
    "        if is_onehot_target:\n",
    "            self.targets = convertToOneHot(self.targets, num_classes=10)\n",
    "\n",
    "        self.reset_kfold()\n",
    "\n",
    "        self.num_train_data = len(self.images) - validation_size\n",
    "        self.num_validation_data = validation_size\n",
    "\n",
    "    def reset_kfold(self):\n",
    "        if self.n_splits == 1:\n",
    "            self.validation_input = self.images[:self.validation_size]\n",
    "            self.validation_target = self.targets[:self.validation_size]\n",
    "\n",
    "            self.train_input = self.images[self.validation_size:]\n",
    "            self.train_target = self.targets[self.validation_size:]\n",
    "        else:\n",
    "            kf = KFold(n_splits=self.n_splits)\n",
    "            self.splitted_indices = kf.split(self.images)\n",
    "\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz' % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8, offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    labels = labels.astype(np.float64, copy=False)\n",
    "    images = images.astype(np.float64, copy=False)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "if __name__ == '__main__': # 라이브러리를 테스트하려는 파이썬의 코딩 스타일\n",
    "    data = MNIST_Data(validation_size=5000, n_splits=12, is_onehot_target=True)\n",
    "    #data = Fashion_MNIST_Data(validation_size=5000, n_splits=12, is_onehot_target=True)\n",
    "\n",
    "    print(\"N_Splits:\", data.n_splits) # 12\n",
    "    for i in range(12):\n",
    "        data.set_next_train_and_validation_data() #큰트롤비1\n",
    "        print(i)\n",
    "        print(data.train_input.shape, np.sum(data.train_input))\n",
    "        print(data.train_target.shape, np.sum(data.train_target))\n",
    "        print()\n",
    "        print(data.validation_input.shape, np.sum(data.validation_input))\n",
    "        print(data.validation_target.shape, np.sum(data.validation_target))\n",
    "        print()\n",
    "        print(data.test_input.shape, np.sum(data.test_input))\n",
    "        print(data.test_target.shape, np.sum(data.test_target))\n",
    "        print()\n",
    "        \n",
    "        \n",
    "# 컨트롤비1\n",
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "class Base_Data:\n",
    "    def __init__(self, n_splits):\n",
    "        self.num_train_data = None\n",
    "        self.num_validation_data = None\n",
    "        self.num_test_data = None\n",
    "\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def set_next_train_and_validation_data(self):\n",
    "        if self.n_splits > 1:\n",
    "            train_indices, validation_indices = next(self.splitted_indices) #인덱스만 들어감. 넥스트에 의해 그 다음 설정.\n",
    "\n",
    "            self.validation_input = self.images[validation_indices]\n",
    "            self.validation_target = self.targets[validation_indices] # 이미지한장에 대한 타겟은 원핫벡터다. 5000개\n",
    "\n",
    "            self.train_input = self.images[train_indices]\n",
    "            self.train_target = self.targets[train_indices]# 5만개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=None, shuffle=False)\n",
      "(array([2, 3, 4, 5]), array([0, 1]))\n",
      "      train용           val용\n",
      "(array([0, 1, 4, 5]), array([2, 3]))\n",
      "      train용           val용\n",
      "(array([0, 1, 2, 3]), array([4, 5]))\n",
      "      train용           val용\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]]) # 6개에 대해서\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=3) \n",
    "\n",
    "print(kf)  \n",
    "splitted_indices = kf.split(X) # 스플릿해\n",
    "for indices in splitted_indices:\n",
    "    print(indices)# X의 인덱스 정보가 들어감. \n",
    "    print(\"      train용           val용\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#/Users/do-hyungkwon/GoogleDrive/git/aiclass/0.Professor/tensorflux/main/vanilla_multi_layer_test\n",
    "import tensorflux.graph as tfg\n",
    "import tensorflux.deep_learning_networks as tfn\n",
    "import tensorflux.enums as tfe\n",
    "import datasource.mnist as mnist\n",
    "import tensorflux.functions as tff\n",
    "import math\n",
    "\n",
    "input_size = 784\n",
    "hidden_layer1_size = 128\n",
    "hidden_layer2_size = 128\n",
    "output_size = 10\n",
    "\n",
    "x = tfg.Placeholder(name=\"x\")\n",
    "target = tfg.Placeholder(name=\"target\")\n",
    "\n",
    "n = tfn.Multi_Layer_Network(\n",
    "    input_size=input_size,\n",
    "    hidden_size_list=[hidden_layer1_size, hidden_layer2_size],\n",
    "    output_size=output_size,\n",
    "    input_node=x,\n",
    "    target_node=target,\n",
    "    initializer=tfe.Initializer.Normal.value,\n",
    "    init_sd=0.01,\n",
    "    # initializer=tfe.Initializer.Xavier.value,\n",
    "    activator=tfe.Activator.ReLU.value,\n",
    "    optimizer=tfe.Optimizer.Adam.value,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "#n.draw_and_show()\n",
    "\n",
    "data = mnist.MNIST_Data(validation_size=5000, n_splits=12, is_onehot_target=True)\n",
    "\n",
    "forward_final_output = n.feed_forward(input_data=data.test_input, is_numba=False)\n",
    "print(forward_final_output.shape)\n",
    "print(tff.accuracy(forward_final_output, data.test_target))\n",
    "\n",
    "batch_size = 1000\n",
    "n.learning(max_epoch=5, data=data, batch_size=batch_size, print_period=1, is_numba=True, verbose=False)#컨트롤비\n",
    "\n",
    "forward_final_output = n.feed_forward(input_data=data.test_input, is_numba=False)\n",
    "print(tff.accuracy(forward_final_output, data.test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import tensorflux.graph as tfg\n",
    "import tensorflux.enums as tfe\n",
    "import tensorflux.layers as tfl\n",
    "import tensorflux.session as tfs\n",
    "import tensorflux.functions as tff\n",
    "import tensorflux.initializers as tfi\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "\n",
    "class Deep_Neural_Network(tfg.Graph):\n",
    "    def __init__(self, input_size, output_size, input_node, target_node, initializer, activator, optimizer, learning_rate):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.input_node = input_node\n",
    "        self.target_node = target_node\n",
    "\n",
    "        self.activator = activator\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer(learning_rate=learning_rate)\n",
    "\n",
    "        self.params = {}\n",
    "        self.optimal_epoch_and_params = None\n",
    "\n",
    "        self.output = None\n",
    "        self.error = None\n",
    "        self.max_epoch = None\n",
    "\n",
    "        self.session = tfs.Session()\n",
    "\n",
    "        self.mode_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=8))\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def initialize_param(self, initializer=tfe.Initializer.Zero.value):\n",
    "        pass\n",
    "\n",
    "    def layering(self, activator=tfe.Activator.ReLU.value):\n",
    "        pass\n",
    "\n",
    "    def backward_propagation(self, is_numba):\n",
    "        pass\n",
    "\n",
    "    def get_params_str(self):\n",
    "        params_str = \"\"\n",
    "        for param_key, param in self.params.items():\n",
    "            params_str = params_str + param_key + \": \" + str(param.value) + \", \"\n",
    "        params_str = params_str[0:-2]\n",
    "        return params_str\n",
    "\n",
    "    def get_all_param_describe(self):\n",
    "        \"\"\"\n",
    "        :return: starts.description\n",
    "        skewness - https://ko.wikipedia.org/wiki/%EB%B9%84%EB%8C%80%EC%B9%AD%EB%8F%84\n",
    "        kurtosis - https://ko.wikipedia.org/wiki/%EC%B2%A8%EB%8F%84\n",
    "        \"\"\"\n",
    "        all_param_flatten_list = []\n",
    "        for param in self.params.values():\n",
    "            all_param_flatten_list.extend([item for item in param.value.flatten()])\n",
    "        return stats.describe(np.array(all_param_flatten_list))\n",
    "\n",
    "    def print_feed_forward(self, num_data, input_data, target_data, is_numba, verbose=False):\n",
    "        for idx in range(num_data):\n",
    "            train_input_data = input_data[idx]\n",
    "            train_target_data = target_data[idx]\n",
    "\n",
    "            output = self.session.run(self.output, {self.input_node: train_input_data}, is_numba, verbose)\n",
    "            print(\"Input Data: {:>5}, Feed Forward Output: {:>6}, Target: {:>6}\".format(\n",
    "                str(train_input_data), np.array2string(output), str(train_target_data)))\n",
    "\n",
    "    def draw_and_show(self, figsize=(8, 8)):\n",
    "        pos = graphviz_layout(self)\n",
    "        plt.figure(figsize=figsize)\n",
    "        nx.draw_networkx(self, pos=pos, with_labels=True)\n",
    "        plt.show(block=True)\n",
    "\n",
    "\n",
    "class Multi_Layer_Network(Deep_Neural_Network):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size_list,\n",
    "                 output_size,\n",
    "                 input_node=None,\n",
    "                 target_node=None,\n",
    "                 initializer=tfe.Initializer.Normal.value,\n",
    "                 init_sd=0.01,\n",
    "                 activator=tfe.Activator.ReLU.value,\n",
    "                 optimizer=tfe.Optimizer.SGD.value,\n",
    "                 learning_rate=0.01):\n",
    "\n",
    "        super().__init__(\n",
    "            input_size,\n",
    "            output_size,\n",
    "            input_node,\n",
    "            target_node,\n",
    "            initializer,\n",
    "            activator,\n",
    "            optimizer,\n",
    "            learning_rate\n",
    "        )\n",
    "\n",
    "        print(\"Multi Layer Network Model - ID:\", self.mode_id)\n",
    "\n",
    "        self.hidden_size_list = hidden_size_list\n",
    "        self.hidden_layer_num = len(hidden_size_list)\n",
    "\n",
    "        self.params_size_list = None\n",
    "        self.layers = OrderedDict()\n",
    "\n",
    "        self.train_error_list = []\n",
    "        self.validation_error_list = []\n",
    "        self.test_accuracy_list = []\n",
    "\n",
    "        self.min_validation_error_epoch = sys.maxsize\n",
    "        self.min_train_error = sys.float_info.max\n",
    "        self.min_validation_error = sys.float_info.max\n",
    "        self.min_fold_idx = sys.maxsize\n",
    "        self.test_accuracy_at_min_validation_error_epoch = 0.0\n",
    "\n",
    "        self.min_validation_error_per_fold = []\n",
    "\n",
    "        self.param_mean_list = {}\n",
    "        self.param_variance_list = {}\n",
    "        self.param_skewness_list = {}\n",
    "        self.param_kurtosis_list = {}\n",
    "\n",
    "        self.output_mean_list = {}\n",
    "        self.output_variance_list = {}\n",
    "        self.output_skewness_list = {}\n",
    "        self.output_kurtosis_list = {}\n",
    "\n",
    "        self.initialize_param(sd=init_sd)\n",
    "        self.layering()\n",
    "\n",
    "    def initialize_param(self, mean=0.0, sd=1.0):\n",
    "        self.params_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]\n",
    "\n",
    "        self.param_mean_list['W'] = {}\n",
    "        self.param_variance_list['W'] = {}\n",
    "        self.param_skewness_list['W'] = {}\n",
    "        self.param_kurtosis_list['W'] = {}\n",
    "\n",
    "        self.param_mean_list['b'] = {}\n",
    "        self.param_variance_list['b'] = {}\n",
    "        self.param_skewness_list['b'] = {}\n",
    "        self.param_kurtosis_list['b'] = {}\n",
    "\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            if self.initializer is tfe.Initializer.Normal.value:\n",
    "                self.params['W' + str(idx)] = self.initializer(\n",
    "                    shape=(self.params_size_list[idx], self.params_size_list[idx + 1]),\n",
    "                    name=\"W\" + str(idx),\n",
    "                    mean=mean,\n",
    "                    sd=sd\n",
    "                ).param\n",
    "            elif self.initializer is tfe.Initializer.Truncated_Normal.value:\n",
    "                self.params['W' + str(idx)] = self.initializer(\n",
    "                    shape=(self.params_size_list[idx], self.params_size_list[idx + 1]),\n",
    "                    name=\"W\" + str(idx),\n",
    "                    mean=mean,\n",
    "                    sd=sd,\n",
    "                    low=-sd,\n",
    "                    upp=sd\n",
    "                ).param\n",
    "            else:\n",
    "                self.params['W' + str(idx)] = self.initializer(\n",
    "                    shape=(self.params_size_list[idx], self.params_size_list[idx + 1]),\n",
    "                    name=\"W\" + str(idx)\n",
    "                ).param\n",
    "\n",
    "            self.params['b' + str(idx)] = tfe.Initializer.Zero.value(\n",
    "                shape=(self.params_size_list[idx + 1],),\n",
    "                name=\"b\" + str(idx)\n",
    "            ).param\n",
    "\n",
    "            self.param_mean_list['W'][idx] = []\n",
    "            self.param_variance_list['W'][idx] = []\n",
    "            self.param_skewness_list['W'][idx] = []\n",
    "            self.param_kurtosis_list['W'][idx] = []\n",
    "\n",
    "            self.param_mean_list['b'][idx] = []\n",
    "            self.param_variance_list['b'][idx] = []\n",
    "            self.param_skewness_list['b'][idx] = []\n",
    "            self.param_kurtosis_list['b'][idx] = []\n",
    "\n",
    "    def layering(self, refitting=False):\n",
    "        input_node = self.input_node\n",
    "\n",
    "        if not refitting:\n",
    "            self.output_mean_list['affine'] = {}\n",
    "            self.output_variance_list['affine'] = {}\n",
    "            self.output_skewness_list['affine'] = {}\n",
    "            self.output_kurtosis_list['affine'] = {}\n",
    "\n",
    "            self.output_mean_list['activation'] = {}\n",
    "            self.output_variance_list['activation'] = {}\n",
    "            self.output_skewness_list['activation'] = {}\n",
    "            self.output_kurtosis_list['activation'] = {}\n",
    "\n",
    "        for idx in range(self.hidden_layer_num):\n",
    "            self.layers['affine' + str(idx)] = tfl.Affine(\n",
    "                self.params['W' + str(idx)],\n",
    "                input_node,\n",
    "                self.params['b' + str(idx)],\n",
    "                name='affine' + str(idx),\n",
    "                graph=self\n",
    "            )\n",
    "            self.layers['activation' + str(idx)] = self.activator(\n",
    "                self.layers['affine' + str(idx)],\n",
    "                name='activation' + str(idx),\n",
    "                graph=self\n",
    "            )\n",
    "            input_node = self.layers['activation' + str(idx)]\n",
    "\n",
    "            if not refitting:\n",
    "                self.output_mean_list['affine'][idx] = []\n",
    "                self.output_variance_list['affine'][idx] = []\n",
    "                self.output_skewness_list['affine'][idx] = []\n",
    "                self.output_kurtosis_list['affine'][idx] = []\n",
    "\n",
    "                self.output_mean_list['activation'][idx] = []\n",
    "                self.output_variance_list['activation'][idx] = []\n",
    "                self.output_skewness_list['activation'][idx] = []\n",
    "                self.output_kurtosis_list['activation'][idx] = []\n",
    "\n",
    "        idx = self.hidden_layer_num\n",
    "        self.layers['affine' + str(idx)] = tfl.Affine(\n",
    "            self.params['W' + str(idx)],\n",
    "            self.layers['activation' + str(idx - 1)],\n",
    "            self.params['b' + str(idx)],\n",
    "            name='affine' + str(idx),\n",
    "            graph=self\n",
    "        )\n",
    "        self.output = self.layers['affine' + str(idx)]\n",
    "\n",
    "        if not refitting:\n",
    "            self.output_mean_list['affine'][idx] = []\n",
    "            self.output_variance_list['affine'][idx] = []\n",
    "            self.output_skewness_list['affine'][idx] = []\n",
    "            self.output_kurtosis_list['affine'][idx] = []\n",
    "\n",
    "        self.error = tfl.SoftmaxWithCrossEntropyLoss(self.output, self.target_node, name=\"SCEL\", graph=self)\n",
    "\n",
    "    def feed_forward(self, input_data, is_numba=False):\n",
    "        return self.session.run(self.output, {self.input_node: input_data}, is_numba, verbose=False)\n",
    "\n",
    "    def backward_propagation(self, is_numba):\n",
    "        grads = {}\n",
    "\n",
    "        d_error = self.error.backward(1.0, is_numba)\n",
    "        din = d_error\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            din = layer.backward(din, is_numba)\n",
    "\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            grads['W' + str(idx)] = self.layers['affine' + str(idx)].dw\n",
    "            grads['b' + str(idx)] = self.layers['affine' + str(idx)].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def learning(self, max_epoch, data, batch_size=1000, print_period=10, is_numba=False, verbose=False):\n",
    "        print(\"-- Learning Started --\")\n",
    "        self.max_epoch = max_epoch\n",
    "\n",
    "        for fold_idx in range(data.n_splits): # 12번\n",
    "            data.set_next_train_and_validation_data()\n",
    "            num_batch = math.ceil(data.num_train_data / batch_size)\n",
    "\n",
    "            if fold_idx == 0:\n",
    "                self.set_learning_process_specification(data, batch_size, 0, print_period, is_numba, fold_idx, max_epoch, verbose)\n",
    "\n",
    "            print(\"Fold: \", fold_idx)\n",
    "            for epoch in range(1, max_epoch + 1): # 5번\n",
    "                for i in range(num_batch):\n",
    "                    i_batch = data.train_input[i * batch_size: i * batch_size + batch_size]\n",
    "                    t_batch = data.train_target[i * batch_size: i * batch_size + batch_size]\n",
    "\n",
    "                    #forward\n",
    "                    self.session.run(\n",
    "                        self.error,\n",
    "                        {\n",
    "                            self.input_node: i_batch,\n",
    "                            self.target_node: t_batch\n",
    "                        },\n",
    "                        is_numba=is_numba,\n",
    "                        verbose=False)\n",
    "\n",
    "                    #backward\n",
    "                    if isinstance(self.optimizer, tfe.Optimizer.NAG.value):\n",
    "                        #cloned_network = copy.deepcopy(self)\n",
    "                        cloned_network = pickle.loads(pickle.dumps(self, -1))\n",
    "                        self.optimizer.update(params=self.params, cloned_network=cloned_network, is_numba=is_numba)\n",
    "                    else:\n",
    "                        grads = self.backward_propagation(is_numba)\n",
    "                        self.optimizer.update(params=self.params, grads=grads)\n",
    "\n",
    "                self.set_learning_process_specification(data, batch_size, epoch, print_period, is_numba, fold_idx, max_epoch, verbose)\n",
    "\n",
    "            print()\n",
    "\n",
    "            self.min_train_error = float(self.train_error_list[self.min_validation_error_epoch])\n",
    "            self.min_validation_error = float(self.validation_error_list[self.min_validation_error_epoch])\n",
    "            self.test_accuracy_at_min_validation_error_epoch = float(self.test_accuracy_list[self.min_validation_error_epoch])\n",
    "\n",
    "            self.min_validation_error_per_fold.append(self.min_validation_error)\n",
    "\n",
    "            print(\"[Best Epoch (based on Validation Error) and Its Performance]\")\n",
    "            print(\"Global Epoch:{:3d} (Fold:{:3d} & Epoch:{:3d}) - Train Error:{:6.5f} - Validation Error:{:6.5f} - Test Accuracy:{:6.5f}\".format(\n",
    "                self.min_validation_error_epoch,\n",
    "                self.min_fold_idx,\n",
    "                self.min_validation_error_epoch - self.max_epoch * self.min_fold_idx,\n",
    "                self.min_train_error,\n",
    "                self.min_validation_error,\n",
    "                self.test_accuracy_at_min_validation_error_epoch\n",
    "            ))\n",
    "            print()\n",
    "\n",
    "        self.load_params(data.n_splits)\n",
    "        self.layering(refitting=True)\n",
    "\n",
    "        self.mean_min_validation_error_for_all_folds = np.mean(self.min_validation_error_per_fold)\n",
    "\n",
    "        print(\"Params are set to the best model!!!\")\n",
    "        print(\"-- Learning Finished --\")\n",
    "        print()\n",
    "\n",
    "    def set_learning_process_specification(self, data, batch_size, epoch, print_period, is_numba, fold_idx, max_epoch, verbose):\n",
    "        batch_mask = np.random.choice(data.num_train_data, batch_size)\n",
    "        i_batch = data.train_input[batch_mask]\n",
    "        t_batch = data.train_target[batch_mask]\n",
    "\n",
    "        train_error = self.session.run(\n",
    "            self.error,\n",
    "            {\n",
    "                self.input_node: i_batch,\n",
    "                self.target_node: t_batch\n",
    "            },\n",
    "            is_numba=is_numba,\n",
    "            verbose=False)\n",
    "        self.train_error_list.append(train_error)\n",
    "\n",
    "        validation_error = self.session.run(\n",
    "            self.error,\n",
    "            {\n",
    "                self.input_node: data.validation_input,\n",
    "                self.target_node: data.validation_target\n",
    "            },\n",
    "            is_numba=is_numba,\n",
    "            verbose=False)\n",
    "        self.validation_error_list.append(validation_error)\n",
    "\n",
    "        min_flag = False\n",
    "        if validation_error < self.min_validation_error:\n",
    "            self.min_validation_error = validation_error\n",
    "            self.min_validation_error_epoch = epoch + fold_idx * max_epoch\n",
    "            self.min_fold_idx = fold_idx\n",
    "            self.save_params()\n",
    "            min_flag = True\n",
    "\n",
    "        forward_final_output = self.feed_forward(input_data=data.test_input, is_numba=is_numba)\n",
    "\n",
    "        test_accuracy = tff.accuracy(forward_final_output, data.test_target)\n",
    "        self.test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            d = self.get_param_describe(layer_num=idx, kind=\"W\")\n",
    "            self.param_mean_list['W'][idx].append(d.mean)\n",
    "            self.param_variance_list['W'][idx].append(d.variance)\n",
    "            self.param_skewness_list['W'][idx].append(d.skewness)\n",
    "            self.param_kurtosis_list['W'][idx].append(d.kurtosis)\n",
    "\n",
    "            d = self.get_param_describe(layer_num=idx, kind=\"b\")\n",
    "            self.param_mean_list['b'][idx].append(d.mean)\n",
    "            self.param_variance_list['b'][idx].append(d.variance)\n",
    "            self.param_skewness_list['b'][idx].append(d.skewness)\n",
    "            self.param_kurtosis_list['b'][idx].append(d.kurtosis)\n",
    "\n",
    "            d = self.get_activation_describe(layer_num=idx, kind=\"affine\")\n",
    "            self.output_mean_list['affine'][idx].append(d.mean)\n",
    "            self.output_variance_list['affine'][idx].append(d.variance)\n",
    "            self.output_skewness_list['affine'][idx].append(d.skewness)\n",
    "            self.output_kurtosis_list['affine'][idx].append(d.kurtosis)\n",
    "\n",
    "            if idx != self.hidden_layer_num:\n",
    "                d = self.get_activation_describe(layer_num=idx, kind=\"activation\")\n",
    "                self.output_mean_list['activation'][idx].append(d.mean)\n",
    "                self.output_variance_list['activation'][idx].append(d.variance)\n",
    "                self.output_skewness_list['activation'][idx].append(d.skewness)\n",
    "                self.output_kurtosis_list['activation'][idx].append(d.kurtosis)\n",
    "\n",
    "        if epoch % print_period == 0:\n",
    "            print(\n",
    "                \"Epoch {:3d} Completed - Train Error:{:6.5f} - Validation Error:{:6.5f} - Test Accuracy:{:6.5f}\".format(\n",
    "                    epoch,\n",
    "                    float(train_error),\n",
    "                    float(validation_error),\n",
    "                    float(test_accuracy)\n",
    "                ),\n",
    "                end=\"\"\n",
    "            )\n",
    "            if min_flag:\n",
    "                print(\" <== Minimal Val. Error\")\n",
    "            else:\n",
    "                print()\n",
    "\n",
    "            if verbose:\n",
    "                self.draw_params_histogram()\n",
    "                for idx in range(self.hidden_layer_num + 1):\n",
    "                    desc_obj = self.get_param_describe(layer_num=idx, kind=\"W\")\n",
    "                    num = \"{:10d}\".format(desc_obj.nobs)\n",
    "                    min = \"{:5.4f}\".format(desc_obj.minmax[0])\n",
    "                    max = \"{:5.4f}\".format(desc_obj.minmax[1])\n",
    "                    mean = \"{:5.4f}\".format(desc_obj.mean)\n",
    "                    variance = \"{:5.4f}\".format(desc_obj.variance)\n",
    "                    skewness = \"{:5.4f}\".format(desc_obj.skewness)\n",
    "                    kurtosis = \"{:5.4f}\".format(desc_obj.kurtosis)\n",
    "\n",
    "                    print('W' + str(idx) + '-',\n",
    "                          \"num:{:10s}, min:{:5s}, max:{:5s}, mean:{:5s}, variance:{:5s}, skewness:{:5s}, kurtosis:{:5s}\".format(\n",
    "                              num, min, max, mean, variance, skewness, kurtosis\n",
    "                          )\n",
    "                    )\n",
    "\n",
    "                for idx in range(self.hidden_layer_num + 1):\n",
    "                    desc_obj = self.get_param_describe(layer_num=idx, kind=\"b\")\n",
    "                    num = \"{:10d}\".format(desc_obj.nobs)\n",
    "                    min = \"{:5.4f}\".format(desc_obj.minmax[0])\n",
    "                    max = \"{:5.4f}\".format(desc_obj.minmax[1])\n",
    "                    mean = \"{:5.4f}\".format(desc_obj.mean)\n",
    "                    variance = \"{:5.4f}\".format(desc_obj.variance)\n",
    "                    skewness = \"{:5.4f}\".format(desc_obj.skewness)\n",
    "                    kurtosis = \"{:5.4f}\".format(desc_obj.kurtosis)\n",
    "\n",
    "                    print('b' + str(idx) + '-',\n",
    "                          \"num:{:10s}, min:{:5s}, max:{:5s}, mean:{:5s}, variance:{:5s}, skewness:{:5s}, kurtosis:{:5s}\".format(\n",
    "                              num, min, max, mean, variance, skewness, kurtosis\n",
    "                          )\n",
    "                    )\n",
    "\n",
    "                print()\n",
    "\n",
    "    def save_params(self):\n",
    "        #optimal_params = copy.deepcopy(self.params)\n",
    "        optimal_params = pickle.loads(pickle.dumps(self.params, -1))\n",
    "        self.optimal_epoch_and_params = [self.min_validation_error_epoch, optimal_params]\n",
    "\n",
    "    def load_params(self, n_splits):\n",
    "        acc_epoch = self.optimal_epoch_and_params[0]\n",
    "        o_epoch = acc_epoch - self.max_epoch * self.min_fold_idx\n",
    "\n",
    "        print(\"Load Params from Fold {:3d} & Epoch {:3d}\".format(self.min_fold_idx, o_epoch))\n",
    "        self.params = self.optimal_epoch_and_params[1]\n",
    "\n",
    "    def draw_params_histogram(self):\n",
    "        f, axarr = plt.subplots(1, (self.hidden_layer_num + 1) * 2, figsize=(10 * (self.hidden_layer_num + 1), 5))\n",
    "\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            w_values = self.layers['affine' + str(idx)].w_value.flatten()\n",
    "            b_values = self.layers['affine' + str(idx)].b_value.flatten()\n",
    "\n",
    "            axarr[idx].hist(w_values, 20)\n",
    "            axarr[idx].set_title(\"W{:d}, mean: {:5.4f}, std: {:5.4f}\".format(idx, np.mean(w_values), np.std(w_values)))\n",
    "\n",
    "            axarr[idx + 3].hist(b_values, 20)\n",
    "            axarr[idx + 3].set_title(\"b{:d}, mean: {:5.4f}, std: {:5.4f}\".format(idx, np.mean(b_values), np.std(b_values)))\n",
    "\n",
    "        f.subplots_adjust(wspace=0.5)\n",
    "        plt.show()\n",
    "\n",
    "    def draw_error_values_and_accuracy(self, figsize=(20, 5)):\n",
    "        # Draw Error Values and Accuracy\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        epoch_list = np.arange(len(self.train_error_list))\n",
    "\n",
    "        plt.subplot(121)\n",
    "        plt.plot(epoch_list, self.train_error_list, 'r', label='Train')\n",
    "        plt.plot(epoch_list, self.validation_error_list, 'g', label='Validation')\n",
    "        plt.ylabel('Error')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.plot(epoch_list, self.test_accuracy_list, 'b', label='Test')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "        plt.show()\n",
    "\n",
    "    def draw_param_description(self, figsize=(20, 5)):\n",
    "        # Draw Error Values and Accuracy\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.subplots_adjust(hspace=.5)\n",
    "\n",
    "        epoch_list = np.arange(len(self.param_mean_list['W'][0]))\n",
    "\n",
    "        color_dic = {\n",
    "            0: 'r',\n",
    "            1: 'b',\n",
    "            2: 'g',\n",
    "        }\n",
    "\n",
    "        plt.subplot(241)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.param_mean_list['W'][idx], color_dic[idx], label='W' + str(idx))\n",
    "        plt.ylabel('Mean')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(242)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.param_variance_list['W'][idx], color_dic[idx], label='W' + str(idx))\n",
    "        plt.ylabel('Variance')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "        \n",
    "        plt.subplot(243)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.param_skewness_list['W'][idx], color_dic[idx], label='W' + str(idx))\n",
    "        plt.ylabel('Skewness')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "        \n",
    "        plt.subplot(244)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.param_kurtosis_list['W'][idx], color_dic[idx], label='W' + str(idx))\n",
    "        plt.ylabel('Kurtosis')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(245)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.param_mean_list['b'][idx], color_dic[idx], label='b' + str(idx))\n",
    "        plt.ylabel('Mean')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(246)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.param_variance_list['b'][idx], color_dic[idx], label='b' + str(idx))\n",
    "        plt.ylabel('Variance')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(247)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.param_skewness_list['b'][idx], color_dic[idx], label='b' + str(idx))\n",
    "        plt.ylabel('Skewness')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(248)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.param_kurtosis_list['b'][idx], color_dic[idx], label='b' + str(idx))\n",
    "        plt.ylabel('Kurtosis')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def draw_output_description(self, figsize=(20, 5)):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.subplots_adjust(hspace=.5)\n",
    "\n",
    "        epoch_list = np.arange(len(self.output_mean_list['affine'][0]))\n",
    "\n",
    "        color_dic = {\n",
    "            0: 'r',\n",
    "            1: 'b',\n",
    "            2: 'g',\n",
    "        }\n",
    "\n",
    "        plt.subplot(241)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.output_mean_list['affine'][idx], color_dic[idx], label='affine' + str(idx))\n",
    "        plt.ylabel('Mean')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(242)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.output_variance_list['affine'][idx], color_dic[idx], label='affine' + str(idx))\n",
    "        plt.ylabel('Variance')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(243)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.output_skewness_list['affine'][idx], color_dic[idx], label='affine' + str(idx))\n",
    "        plt.ylabel('Skewness')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(244)\n",
    "        for idx in range(self.hidden_layer_num + 1):\n",
    "            plt.plot(epoch_list, self.output_kurtosis_list['affine'][idx], color_dic[idx], label='affine' + str(idx))\n",
    "        plt.ylabel('Kurtosis')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(245)\n",
    "        for idx in range(self.hidden_layer_num):\n",
    "            plt.plot(epoch_list, self.output_mean_list['activation'][idx], color_dic[idx], label='activation' + str(idx))\n",
    "        plt.ylabel('Mean')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(246)\n",
    "        for idx in range(self.hidden_layer_num):\n",
    "            plt.plot(epoch_list, self.output_variance_list['activation'][idx], color_dic[idx], label='activation' + str(idx))\n",
    "        plt.ylabel('Variance')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(247)\n",
    "        for idx in range(self.hidden_layer_num):\n",
    "            plt.plot(epoch_list, self.output_skewness_list['activation'][idx], color_dic[idx], label='activation' + str(idx))\n",
    "        plt.ylabel('Skewness')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.subplot(248)\n",
    "        for idx in range(self.hidden_layer_num):\n",
    "            plt.plot(epoch_list, self.output_kurtosis_list['activation'][idx], color_dic[idx], label='activation' + str(idx))\n",
    "        plt.ylabel('Kurtosis')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def draw_false_prediction(self, test_input, test_target, labels, num=5, figsize=(20, 5)):\n",
    "        forward_final_output = self.feed_forward(input_data=test_input, is_numba=False)\n",
    "        y = np.argmax(forward_final_output, axis=1)\n",
    "        if test_target.ndim != 1:\n",
    "            target = np.argmax(test_target, axis=1)\n",
    "        else:\n",
    "            target = test_target\n",
    "\n",
    "        diff_index_list = []\n",
    "        for i in range(len(test_input)):\n",
    "            if y[i] != target[i]:\n",
    "                diff_index_list.append(i)\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        for i in range(num):\n",
    "            j = diff_index_list[i]\n",
    "            print(\"False Prediction Index: {:d}, Prediction: {:s}, Ground Truth: {:s}\".format(j, labels[y[j]], labels[int(target[j])]))\n",
    "            img = np.array(test_input[j])\n",
    "            img.shape = (28, 28)\n",
    "            plt.subplot(150 + (i + 1))\n",
    "            plt.imshow(img, cmap='gray')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def get_param_describe(self, layer_num=0, kind=\"W\"):\n",
    "        assert layer_num <= self.hidden_layer_num\n",
    "\n",
    "        if kind == \"W\":\n",
    "            param_flatten_list = self.params['W' + str(layer_num)].value.flatten()\n",
    "        else:\n",
    "            param_flatten_list = self.params['b' + str(layer_num)].value.flatten()\n",
    "\n",
    "        return stats.describe(np.array(param_flatten_list))\n",
    "\n",
    "    def get_activation_describe(self, layer_num=0, kind=\"affine\"):\n",
    "        assert layer_num <= self.hidden_layer_num\n",
    "\n",
    "        if kind == \"affine\":\n",
    "            output_flatten_list = self.layers['affine' + str(layer_num)].output.flatten()\n",
    "        else:\n",
    "            output_flatten_list = self.layers['activation' + str(layer_num)].output.flatten()\n",
    "\n",
    "        return stats.describe(np.array(output_flatten_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 가장 작은 벨리데이션의 파라미터와 바이어스를 저장하는 코드\n",
    "min_flag = False\n",
    "        if validation_error < self.min_validation_error:\n",
    "            self.min_validation_error = validation_error\n",
    "            self.min_validation_error_epoch = epoch + fold_idx * max_epoch\n",
    "            self.min_fold_idx = fold_idx\n",
    "            self.save_params()\n",
    "            min_flag = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
