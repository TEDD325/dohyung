{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version: 2.2.2 backend: tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import metrics\n",
    "from keras import losses\n",
    "from keras import __version__\n",
    "print('Using Keras version:', __version__, 'backend:', K.backend())\n",
    "# assert(LV(__version__) >= LV(\"2.0.0\"))\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=config)\n",
    "# set_session(sess)\n",
    "# cfg = K.tf.ConfigProto()\n",
    "# cfg.gpu_options.allow_growth = True\n",
    "# K.set_session(K.tf.Session(config=cfg))\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# # The GPU id to use, usually either \"0\" or \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report # https://stackoverflow.com/questions/50065484/getting-precision-recall-and-f1-score-per-class-in-keras\n",
    "\n",
    "from IPython.display import Javascript\n",
    "import numpy as np\n",
    "from distutils.version import LooseVersion as LV\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pprint\n",
    "#import boto3\n",
    "import pickle\n",
    "import time\n",
    "import os.path\n",
    "import pickle\n",
    "sys.path.append(os.getcwd())\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText # simple MSG\n",
    "from email.mime.multipart import MIMEMultipart # complex MSG\n",
    "        \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_all_raw_data(coin_name_list, start_date, end_date, data_files_dir):\n",
    "    trading_files = []\n",
    "    for coin_name in coin_name_list:\n",
    "        for data_file_name in [f for f in listdir(data_files_dir) if isfile(join(data_files_dir, f))]:\n",
    "            if coin_name in data_file_name:\n",
    "                trading_files.append(data_file_name)\n",
    "\n",
    "    start_ms_time = datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\").timestamp() * 1000\n",
    "    end_ms_time = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\").timestamp() * 1000\n",
    "    \n",
    "    raw_data = {} #전체 CSV Raw 데이터\n",
    "    for coin_name in coin_name_list:\n",
    "        raw_data[coin_name] = []\n",
    "    \n",
    "    #KRW 제외한 나머지 CSV Raw 데이터 수집\n",
    "    for coin_name in coin_name_list:\n",
    "        for data_file_name in trading_files:\n",
    "            if coin_name in data_file_name:\n",
    "                file = open(data_files_dir + data_file_name, 'r', encoding='utf-8')\n",
    "                rdr = csv.reader(file)\n",
    "                for line in rdr:\n",
    "                    if start_ms_time <= int(line[0]) and int(line[0]) <= end_ms_time:\n",
    "                        raw_data[coin_name].append(line)\n",
    "                file.close()\n",
    "    \n",
    "    for line in raw_data['BTC']:\n",
    "        raw_data['KRW'].append([line[0], line[1], 1, 1, 1, 1, 1.0, 'normal'])\n",
    "#     print(\"test\")\n",
    "    return raw_data\n",
    "\n",
    "def Make_Dataset(dir_path, coin_list, start_date, end_date, time_unit, window_size, gap, margin_rate):\n",
    "    print(\"Make_Dataset is Started.\")\n",
    "    a = time.time()\n",
    "\n",
    "    X = {}\n",
    "    y = {}\n",
    "    idx = []\n",
    "\n",
    "    key_name_X = \"X_\"\n",
    "    key_name_y = \"y_\"\n",
    "    for idx_time_unit in time_unit:\n",
    "        for idx_window_size in window_size:\n",
    "            for idx_gap in gap:\n",
    "                for idx_margix_rate in margin_rate:\n",
    "                    key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                    key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                    if (os.path.isfile(dir_path+key_name_X+\".pickle\")) is not True:\n",
    "                        print(key_name_X)\n",
    "                        X[key_name_X] = \\\n",
    "                        make_cryptocurrency_dataset(\n",
    "                                                    coin_list, \n",
    "                                                    start_date, \n",
    "                                                    end_date,\n",
    "                                                    idx_time_unit,\n",
    "                                                    idx_window_size,\n",
    "                                                    idx_gap,\n",
    "                                                    idx_margix_rate,\n",
    "                                                    data_files_dir)\n",
    "                        with open(dir_path + key_name_X+\".pickle\", 'wb') as handle:\n",
    "                            pickle.dump(X[key_name_X], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        X = {}\n",
    "                        print(\"X_success.\")\n",
    "                    if (os.path.isfile(dir_path + key_name_y+\".pickle\")) is not True:\n",
    "                        print(key_name_y)\n",
    "                        y[key_name_y] = \\\n",
    "                        make_cryptocurrency_dataset(\n",
    "                                                    coin_list, \n",
    "                                                    start_date, \n",
    "                                                    end_date,\n",
    "                                                    idx_time_unit,\n",
    "                                                    idx_window_size,\n",
    "                                                    idx_gap,\n",
    "                                                    idx_margix_rate,\n",
    "                                                    data_files_dir)\n",
    "                        with open(dir_path + key_name_y+\".pickle\", 'wb') as handle:\n",
    "                            pickle.dump(y[key_name_y], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        y = {}\n",
    "                        print(\"y_success.\")\n",
    "                    key_name_X = \"X_\"\n",
    "                    key_name_y = \"y_\"\n",
    "    b = time.time()\n",
    "    print(\"Make_Dataset is Done.\")\n",
    "    #print(\"time: \", b-a)\n",
    "\n",
    "def make_cryptocurrency_dataset(coin_name_list, start_date, end_date, time_unit, window_size, gap, margin_rate, data_files_dir):\n",
    "    y_trv = []\n",
    "    y_btv = []\n",
    "    num_coins = len(coin_name_list)\n",
    "    #raw_data = get_all_raw_data_from_aws(coin_name_list, start_date, end_date)\n",
    "    raw_data = get_all_raw_data(coin_name_list, start_date, end_date, data_files_dir)    \n",
    "    num_sticks = len(raw_data['BTC'])\n",
    "    \n",
    "    if time_unit % 10 != 0 or num_sticks < (time_unit / 10) * window_size + gap:\n",
    "        return None, None\n",
    "    \n",
    "    num = int(num_sticks - ((time_unit / 10) * window_size + gap) + 1)\n",
    "        \n",
    "    X = []\n",
    "    y = []\n",
    "    # (윈도우 개수, 코인 개수, 윈도우 사이즈, 3)\n",
    "    for idx in range(num):\n",
    "        X.append([])\n",
    "        y.append([])\n",
    "        idx_coin = 0\n",
    "        for coin_name in coin_name_list:\n",
    "            X[idx].append([])\n",
    "            \n",
    "            last_idx_in_window = int(idx + time_unit / 10 * window_size - 1)\n",
    "            close_price_in_last_idx_in_window = float(raw_data[coin_name][last_idx_in_window][3])\n",
    "            \n",
    "            for idx_in_window in range(window_size):\n",
    "                X[idx][idx_coin].append([])\n",
    "                idx_stick = int(idx + time_unit / 10 * (idx_in_window + 1) - 1)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][3]) / close_price_in_last_idx_in_window)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][4]) / close_price_in_last_idx_in_window)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][5]) / close_price_in_last_idx_in_window)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][6]))\n",
    "                \n",
    "            target_idx_for_window = int(idx + time_unit / 10 * window_size - 1 + gap)\n",
    "            target_price = float(raw_data[coin_name][target_idx_for_window][3])\n",
    "            \n",
    "            target = 0\n",
    "            if target_price >= close_price_in_last_idx_in_window * (1.0 + float(margin_rate) / 100.0):\n",
    "                target = 1\n",
    "            y[idx].append(target)\n",
    "            \n",
    "            idx_coin += 1\n",
    "           \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "def make_cryptocurrency_dataset_X(coin_name_list, start_date, end_date, time_unit, window_size, gap, margin_rate, data_files_dir):\n",
    "    num_coins = len(coin_name_list)\n",
    "    #raw_data = get_all_raw_data_from_aws(coin_name_list, start_date, end_date)\n",
    "    raw_data = get_all_raw_data(coin_name_list, start_date, end_date, data_files_dir)    \n",
    "    num_sticks = len(raw_data['BTC'])\n",
    "    \n",
    "    if time_unit % 10 != 0 or num_sticks < (time_unit / 10) * window_size + gap:\n",
    "        return None, None\n",
    "    \n",
    "    num = int(num_sticks - ((time_unit / 10) * window_size + gap) + 1)\n",
    "        \n",
    "    X = []\n",
    "    # (윈도우 개수, 코인 개수, 윈도우 사이즈, 3)\n",
    "    for idx in range(num):\n",
    "        X.append([])\n",
    "        idx_coin = 0\n",
    "        for coin_name in coin_name_list:\n",
    "            X[idx].append([])\n",
    "            \n",
    "            last_idx_in_window = int(idx + time_unit / 10 * window_size - 1)\n",
    "            close_price_in_last_idx_in_window = float(raw_data[coin_name][last_idx_in_window][3])\n",
    "            \n",
    "            for idx_in_window in range(window_size):\n",
    "                X[idx][idx_coin].append([])\n",
    "                idx_stick = int(idx + time_unit / 10 * (idx_in_window + 1) - 1)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][3]) / close_price_in_last_idx_in_window)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][4]) / close_price_in_last_idx_in_window)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][5]) / close_price_in_last_idx_in_window)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][6]))\n",
    "                \n",
    "    X = np.array(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def make_cryptocurrency_dataset_y(coin_name_list, start_date, end_date, time_unit, window_size, gap, margin_rate, data_files_dir):\n",
    "    y_trv = []\n",
    "    y_btv = []\n",
    "    num_coins = len(coin_name_list)\n",
    "    #raw_data = get_all_raw_data_from_aws(coin_name_list, start_date, end_date)\n",
    "    raw_data = get_all_raw_data(coin_name_list, start_date, end_date, data_files_dir)    \n",
    "    num_sticks = len(raw_data['BTC'])\n",
    "    \n",
    "    if time_unit % 10 != 0 or num_sticks < (time_unit / 10) * window_size + gap:\n",
    "        return None, None\n",
    "    \n",
    "    num = int(num_sticks - ((time_unit / 10) * window_size + gap) + 1)\n",
    "        \n",
    "    \n",
    "    y = []\n",
    "    # (윈도우 개수, 코인 개수, 윈도우 사이즈, 3)\n",
    "    for idx in range(num):\n",
    "        \n",
    "        y.append([])\n",
    "        idx_coin = 0\n",
    "        for coin_name in coin_name_list:            \n",
    "            last_idx_in_window = int(idx + time_unit / 10 * window_size - 1)\n",
    "            close_price_in_last_idx_in_window = float(raw_data[coin_name][last_idx_in_window][3])\n",
    "            target_idx_for_window = int(idx + time_unit / 10 * window_size - 1 + gap)\n",
    "            target_price = float(raw_data[coin_name][target_idx_for_window][3])\n",
    "            target = 0\n",
    "            \n",
    "            if target_price >= close_price_in_last_idx_in_window * (1.0 + float(margin_rate) / 100.0):\n",
    "                target = 1\n",
    "            y[idx].append(target)\n",
    "            \n",
    "            idx_coin += 1\n",
    "           \n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    return y\n",
    "\n",
    "#\n",
    "\n",
    "def Load_Dataset_X(dir_path, time_unit, window_size, gap, margin_rate):\n",
    "    key_name_X = \"X_\" + \\\n",
    "                    str(time_unit) + \"_\" + \\\n",
    "                    str(window_size) + \"_\" + \\\n",
    "                    str(gap) + \"_\" + \\\n",
    "                    str(margin_rate)\n",
    "                    \n",
    "\n",
    "    with open(dir_path + key_name_X + \".pickle\", 'rb') as handle:\n",
    "        b_x = pickle.load(handle)\n",
    "    return b_x\n",
    "    \n",
    "def Load_Dataset_y(dir_path, time_unit, window_size, gap, margin_rate):\n",
    "    key_name_y = \"y_\" + \\\n",
    "                    str(time_unit) + \"_\" + \\\n",
    "                    str(window_size) + \"_\" + \\\n",
    "                    str(gap) + \"_\" + \\\n",
    "                    str(margin_rate)\n",
    "                    \n",
    "\n",
    "    with open(dir_path + key_name_y + \".pickle\", 'rb') as handle:\n",
    "        b_y = pickle.load(handle)\n",
    "    return b_y\n",
    "    \n",
    "def Make_Dataset_numpy(dir_path, coin_list, start_date, end_date, time_unit, window_size, gap, margin_rate, data_files_dir):\n",
    "    print(\"Make_Dataset_numpy is Started.\")\n",
    "    a = time.time()\n",
    "\n",
    "    X = {}\n",
    "    y = {}\n",
    "    idx = []\n",
    "\n",
    "    key_name_X = \"X_\"\n",
    "    key_name_y = \"y_\"\n",
    "    for idx_time_unit in time_unit:\n",
    "        for idx_window_size in window_size:\n",
    "            for idx_gap in gap:\n",
    "                for idx_margix_rate in margin_rate:\n",
    "                    key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                    key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                    if (os.path.isfile(dir_path + key_name_X+\".pickle\")) is not True:\n",
    "                        print(key_name_X)\n",
    "                        X[key_name_X] = \\\n",
    "                        make_cryptocurrency_dataset_X(\n",
    "                                                    coin_list, \n",
    "                                                    start_date, \n",
    "                                                    end_date,\n",
    "                                                    idx_time_unit,\n",
    "                                                    idx_window_size,\n",
    "                                                    idx_gap,\n",
    "                                                    idx_margix_rate,\n",
    "                                                    data_files_dir)\n",
    "                        with open(dir_path + key_name_X+\".pickle\", 'wb') as handle:\n",
    "                            pickle.dump(X[key_name_X], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        X = {}\n",
    "                        print(\"X_success.\")\n",
    "                    if (os.path.isfile(dir_path+key_name_y+\".pickle\")) is not True:\n",
    "                        print(key_name_y)\n",
    "                        y[key_name_y] = \\\n",
    "                        make_cryptocurrency_dataset_y(\n",
    "                                                    coin_list, \n",
    "                                                    start_date, \n",
    "                                                    end_date,\n",
    "                                                    idx_time_unit,\n",
    "                                                    idx_window_size,\n",
    "                                                    idx_gap,\n",
    "                                                    idx_margix_rate,\n",
    "                                                    data_files_dir)\n",
    "                        with open(dir_path + key_name_y+\".pickle\", 'wb') as handle:\n",
    "                            pickle.dump(y[key_name_y], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        y = {}\n",
    "                        print(\"y_success.\")\n",
    "                    key_name_X = \"X_\"\n",
    "                    key_name_y = \"y_\"\n",
    "    b = time.time()\n",
    "    print(\"Make_Dataset_numpy is Done.\")\n",
    "    print()\n",
    "    #print(\"time: \", b-a)\n",
    "    \n",
    "    \n",
    "def Make_Dataset_tuple(dir_path, coin_list, start_date, end_date, time_unit, window_size, gap, margin_rate, data_files_dir):\n",
    "    print(\"Make_Dataset_tuple is Started.\")\n",
    "    a = time.time()\n",
    "\n",
    "    X = {}\n",
    "    y = {}\n",
    "    idx = []\n",
    "\n",
    "    key_name_X = \"X_\"\n",
    "    key_name_y = \"y_\"\n",
    "    for idx_time_unit in time_unit:\n",
    "        for idx_window_size in window_size:\n",
    "            for idx_gap in gap:\n",
    "                for idx_margix_rate in margin_rate:\n",
    "                    key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                    key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                    if (os.path.isfile(dir_path + key_name_X+\".pickle\")) is not True:\n",
    "                        print(key_name_X)\n",
    "                        X[key_name_X], _ = \\\n",
    "                        make_cryptocurrency_dataset(\n",
    "                                                    coin_list, \n",
    "                                                    start_date, \n",
    "                                                    end_date,\n",
    "                                                    idx_time_unit,\n",
    "                                                    idx_window_size,\n",
    "                                                    idx_gap,\n",
    "                                                    idx_margix_rate,\n",
    "                                                    data_files_dir)\n",
    "                        with open(dir_path + key_name_X+\".pickle\", 'wb') as handle:\n",
    "                            pickle.dump(X[key_name_X], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        X = {}\n",
    "                        print(\"X_success.\")\n",
    "                    if (os.path.isfile(dir_path+key_name_y+\".pickle\")) is not True:\n",
    "                        print(key_name_y)\n",
    "                        _, y[key_name_y] = \\\n",
    "                        make_cryptocurrency_dataset(\n",
    "                                                    coin_list, \n",
    "                                                    start_date, \n",
    "                                                    end_date,\n",
    "                                                    idx_time_unit,\n",
    "                                                    idx_window_size,\n",
    "                                                    idx_gap,\n",
    "                                                    idx_margix_rate,\n",
    "                                                    data_files_dir)\n",
    "                        with open(dir_path + key_name_y+\".pickle\", 'wb') as handle:\n",
    "                            pickle.dump(y[key_name_y], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        y = {}\n",
    "                        print(\"y_success.\")\n",
    "                    key_name_X = \"X_\"\n",
    "                    key_name_y = \"y_\"\n",
    "    b = time.time()\n",
    "    print(\"Make_Dataset_tuple is Done.\")\n",
    "    print()\n",
    "    #print(\"time: \", b-a)\n",
    "\n",
    "def Check_Dataset(dir_path, coin_list, start_date, end_date, time_unit, window_size, gap, margin_rate, data_files_dir):\n",
    "    print(\"Check_Dataset is Started.\")\n",
    "    a = time.time()\n",
    "\n",
    "    X = {}\n",
    "    y = {}\n",
    "    idx = []\n",
    "\n",
    "    key_name_X = \"X_\"\n",
    "    key_name_y = \"y_\"\n",
    "    for idx_time_unit in time_unit:\n",
    "        for idx_window_size in window_size:\n",
    "            for idx_gap in gap:\n",
    "                for idx_margix_rate in margin_rate:\n",
    "                    key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                    key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                    \n",
    "                    with open(dir_path + key_name_X+\".pickle\", 'rb') as handle:\n",
    "                        data = pickle.load(handle)\n",
    "    \n",
    "                    if type(data) == tuple:\n",
    "#                         print()\n",
    "                        os.system('rm '+dir_path + key_name_X+\".pickle\")\n",
    "                        print(key_name_X,\".pickle is removed.\")\n",
    "                        os.system('rm '+dir_path + key_name_y+\".pickle\")\n",
    "                        print(key_name_y,\".pickle is removed.\")\n",
    "        \n",
    "                    if (os.path.isfile(dir_path+key_name_X+\".pickle\")) is not True:\n",
    "                        print(key_name_X)\n",
    "                        X[key_name_X] = \\\n",
    "                        make_cryptocurrency_dataset_X(\n",
    "                                                    coin_list, \n",
    "                                                    start_date, \n",
    "                                                    end_date,\n",
    "                                                    idx_time_unit,\n",
    "                                                    idx_window_size,\n",
    "                                                    idx_gap,\n",
    "                                                    idx_margix_rate,\n",
    "                                                    data_files_dir)\n",
    "                        with open(dir_path + key_name_X+\".pickle\", 'wb') as handle:\n",
    "                            pickle.dump(X[key_name_X], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        X = {}\n",
    "                        print(\"[SUCCESS] \",key_name_X,\".pickle is created.\")\n",
    "                    if (os.path.isfile(dir_path+key_name_y+\".pickle\")) is not True:\n",
    "                        print(key_name_y)\n",
    "                        y[key_name_y] = \\\n",
    "                        make_cryptocurrency_dataset_y(\n",
    "                                                    coin_list, \n",
    "                                                    start_date, \n",
    "                                                    end_date,\n",
    "                                                    idx_time_unit,\n",
    "                                                    idx_window_size,\n",
    "                                                    idx_gap,\n",
    "                                                    idx_margix_rate,\n",
    "                                                    data_files_dir)\n",
    "                        with open(dir_path + key_name_y+\".pickle\", 'wb') as handle:\n",
    "                            pickle.dump(y[key_name_y], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        y = {}\n",
    "                        print(\"[SUCCESS] \",key_name_y,\".pickle is created.\")\n",
    "                    key_name_X = \"X_\"\n",
    "                    key_name_y = \"y_\"\n",
    "    b = time.time()\n",
    "    print(\"Check_Dataset is Done.\")\n",
    "    #print(\"time: \", b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "data_files_dir = \"/Users/dohyung/OneDrive/2018-RNN/RNN_python/AWS_dataset/\"\n",
    "dataset_dir_path_tuple_type = \"./dataset_pickle_tuple_type/\"\n",
    "dataset_dir_path_numpy_type = \"./dataset_pickle_numpy.ndarray_type)/\"\n",
    "coin_list = [\"KRW\", \"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "start_date = \"2017-08-04 21:40:00\"\n",
    "end_date = \"2018-08-20 23:50:00\"\n",
    "# time_unit = [10,30,60]     # candle stick minutes\n",
    "# window_size = [10,25,50,75,100]  # Unit: num. of candle sticks\n",
    "# gap = [1,2,3]            # Unit: num. of candle sticks\n",
    "# margin_rate = [0.1,0.25,0.5]  # Unit: percent\n",
    "\n",
    "# for slave04\n",
    "time_unit = [10,30,60]     # candle stick minutes\n",
    "window_size = [10,25,50]  # Unit: num. of candle sticks\n",
    "gap = [1,2,3]            # Unit: num. of candle sticks\n",
    "margin_rate = [0.1,0.25,0.5]  # Unit: percent\n",
    "\n",
    "# for slave05\n",
    "# time_unit = [10,30,60]     # candle stick minutes\n",
    "# window_size = [75,100]  # Unit: num. of candle sticks\n",
    "# gap = [1,2,3]            # Unit: num. of candle sticks\n",
    "# margin_rate = [0.1,0.25,0.5]  # Unit: percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make_Dataset_tuple(dataset_dir_path_tuple_type, coin_list, start_date, end_date, time_unit, window_size, gap, margin_rate)\n",
    "#Make_Dataset_numpy(dataset_dir_path_numpy_type, coin_list, start_date, end_date, time_unit, window_size, gap, margin_rate)\n",
    "#Check_Dataset(dataset_dir_path, coin_list, start_date, end_date, time_unit, window_size, gap, margin_rate)\n",
    "# Tuple 형태의 데이터셋이 나오지 않도록."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def f1_score_(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / (c2 + 1e-7)\n",
    "    \n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / (c3 +  + 1e-7)\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / ((precision + recall) + 1e-7)\n",
    "    return f1_score \n",
    "\n",
    "\n",
    "def create_model_RNN(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        RNN(  n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_SimpleRNN(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        SimpleRNN(n_state_units, \n",
    "                  input_shape=(window_size, 32),\n",
    "                  use_bias=True, \n",
    "                  activation='tanh',\n",
    "                  kernel_initializer='glorot_uniform', \n",
    "                  recurrent_initializer='orthogonal', \n",
    "                  bias_initializer='zeros', \n",
    "                  dropout=0.0,\n",
    "                  recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model_LSTM(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        LSTM( n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_GRU(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        GRU(  n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_RNN_non_GPU(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        RNN(  n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_SimpleRNN_non_GPU_test(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        SimpleRNN(n_state_units, \n",
    "                  params['first_neuron'],\n",
    "                  input_dim=x_train.shape[2], # [dataset 크기, 윈도우 사이즈, 32(코인개수*OLHC)]\n",
    "#                   input_shape=(window_size, 32),\n",
    "#                   use_bias=True, \n",
    "                  activation='relu'))\n",
    "#                   kernel_initializer='glorot_uniform', \n",
    "#                   recurrent_initializer='orthogonal', \n",
    "#                   bias_initializer='zeros', \n",
    "#                   dropout=0.0,\n",
    "#                   recurrent_dropout=0.0))\n",
    "    \n",
    "#     model.add(Dense(units=neurons))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "        \n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(y_train.shape[1],\n",
    "                    activation=params['last_activation']))\n",
    "        \n",
    "#     model.add(Dense(units=2))\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], params['optimizer'])),\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['acc'])\n",
    "        \n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=1,\n",
    "                    validation_data=[x_val, y_val],\n",
    "                    callbacks=early_stopper(params['epochs'], mode='strict'))\n",
    "    \n",
    "    return out\n",
    "        \n",
    "def create_model_SimpleRNN_non_GPU(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        SimpleRNN(n_state_units, \n",
    "                  input_shape=(window_size, 32),\n",
    "                  use_bias=True, \n",
    "                  activation='tanh',\n",
    "                  kernel_initializer='glorot_uniform', \n",
    "                  recurrent_initializer='orthogonal', \n",
    "                  bias_initializer='zeros', \n",
    "                  dropout=0.0,\n",
    "                  recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, \n",
    "              validation_data=(X_test_scaled,y_test))\n",
    "    return model\n",
    "\n",
    "def create_model_LSTM_non_GPU(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        LSTM( n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_GRU_non_GPU(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        GRU(  n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def input_reshape(X_train_data, X_test_data, n_steps, n_coins, n_price):\n",
    "    X_train_reshape = X_train_data.reshape(\n",
    "        -1, \n",
    "        n_steps, \n",
    "        n_coins * n_price\n",
    "    )\n",
    "    X_test_reshape = X_test_data.reshape(\n",
    "        -1, \n",
    "        n_steps, \n",
    "        n_coins * n_price\n",
    "    )\n",
    "    return X_train_reshape, X_test_reshape\n",
    "\n",
    "def onehottify(x, n=None, dtype=np.int):\n",
    "    \"\"\"1-hot encode x with the max value n (computed from data if n is None).\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    n = np.max(x) + 1 if n is None else n\n",
    "    return np.eye(n, dtype=dtype)[x]\n",
    "\n",
    "def Start_Model(pickle_load_dir_path, data_files_dir, epochs, pickle_result_dir_path, time_unit, window_size, gap, margin_rate, _TEST, _ENHANCE, _GPU, n_jobs, machine, Internet_connection):\n",
    "    X = {}\n",
    "    y = {}\n",
    "    if (_TEST == True): \n",
    "        MODEL_list = [\"SimpleRNN\"]\n",
    "        time_unit = [10]     # candle stick minutes\n",
    "        window_size = [10]  # Unit: num. of candle sticks\n",
    "        gap = [1]            # Unit: num. of candle sticks\n",
    "        margin_rate = [0.1]  # Unit: percent\n",
    "    elif (_TEST == False):\n",
    "        MODEL_list = [\"SimpleRNN\", \"RNN\", \"LSTM\", \"GRU\"]\n",
    "\n",
    "    key_name_X = \"X_\"\n",
    "    key_name_y = \"y_\"\n",
    "    \n",
    "    for MODEL_idx in MODEL_list:\n",
    "        MODEL = MODEL_idx\n",
    "        for idx_time_unit in time_unit:\n",
    "                for idx_window_size in window_size:\n",
    "                    for idx_gap in gap:\n",
    "                        for idx_margix_rate in margin_rate:\n",
    "                            key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                            key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                            \n",
    "                            X = Load_Dataset_X(pickle_load_dir_path, idx_time_unit, idx_window_size, idx_gap, idx_margix_rate)\n",
    "                            y = Load_Dataset_y(pickle_load_dir_path, idx_time_unit, idx_window_size, idx_gap, idx_margix_rate)\n",
    "\n",
    "                            y_single = {}\n",
    "                            y_single['BTC'] = y[:, 1]\n",
    "                            y_single['ETH'] = y[:, 2]\n",
    "                            y_single['XRP'] = y[:, 3]\n",
    "                            y_single['BCH'] = y[:, 4]\n",
    "                            y_single['LTC'] = y[:, 5]\n",
    "                            y_single['DASH'] = y[:, 6]\n",
    "                            y_single['ETC'] = y[:, 7]\n",
    "\n",
    "                            coin_list2 = [\"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "\n",
    "    #                         for coin in coin_list2:\n",
    "    #                             print(\"y_single[\"+coin+\"]\"+\".shape\")\n",
    "    #                             print(y_single[coin].shape)\n",
    "    #                             print()\n",
    "                            \n",
    "                            \n",
    "                            if (_TEST == False):\n",
    "                                for coin in coin_list2:\n",
    "                                    if (os.path.isfile(pickle_result_dir_path + \\\n",
    "                                                      MODEL + \"_\" + \\\n",
    "                                                      coin + \"_\" + \\\n",
    "                                                      str(idx_time_unit) + \"_\" + \\\n",
    "                                                      str(idx_window_size) + \"_\" + \\\n",
    "                                                      str(idx_gap) + \"_\" + \\\n",
    "                                                      str(idx_margix_rate) + \\\n",
    "                                                      \"_result.pickle\")) is True:\n",
    "                                        print(MODEL + \"_\" + \\\n",
    "                                              coin + \"_\" + \\\n",
    "                                              str(idx_time_unit) + \"_\" + \\\n",
    "                                              str(idx_window_size) + \"_\" + \\\n",
    "                                              str(idx_gap) + \"_\" + \\\n",
    "                                              str(idx_margix_rate) + \\\n",
    "                                              \"_result.pickle FILE ALREADY EXIST.\")\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        y2 = onehottify(y_single[coin], n=2)\n",
    "\n",
    "                                        Evaluate(pickle_load_dir_path, \n",
    "                                                 data_files_dir, \n",
    "                                                 epochs, \n",
    "                                                 pickle_result_dir_path, \n",
    "                                                 time_unit, \n",
    "                                                 window_size, \n",
    "                                                 gap, \n",
    "                                                 margin_rate, \n",
    "                                                 _TEST, \n",
    "                                                 _ENHANCE,\n",
    "                                                 coin,\n",
    "                                                 X, y2,\n",
    "                                                 key_name_X,\n",
    "                                                 key_name_y,\n",
    "                                                 idx_time_unit,\n",
    "                                                 idx_window_size,\n",
    "                                                 idx_gap,\n",
    "                                                 idx_margix_rate, \n",
    "                                                 MODEL,\n",
    "                                                 _GPU,\n",
    "                                                 n_jobs,\n",
    "                                                 machine,\n",
    "                                                 Internet_connection)\n",
    "\n",
    "                                    \n",
    "                            if (_TEST == True):\n",
    "                                # for test                                \n",
    "                                for coin in range(1):\n",
    "                                    if (os.path.isfile(pickle_result_dir_path + \\\n",
    "                                                      \"_test_\" + \\\n",
    "                                                      MODEL + \"_\" + \\\n",
    "                                                      \"BTC\" + \"_\" + \\\n",
    "                                                      str(idx_time_unit) + \"_\" + \\\n",
    "                                                      str(idx_window_size) + \"_\" + \\\n",
    "                                                      str(idx_gap) + \"_\" + \\\n",
    "                                                      str(idx_margix_rate) + \\\n",
    "                                                      \"_result.pickle\")) is True:\n",
    "                                        print(\"_test_\" + \\\n",
    "                                              MODEL + \"_\" + \\\n",
    "                                              \"BTC\" + \"_\" + \\\n",
    "                                              str(idx_time_unit) + \"_\" + \\\n",
    "                                              str(idx_window_size) + \"_\" + \\\n",
    "                                              str(idx_gap) + \"_\" + \\\n",
    "                                              str(idx_margix_rate) + \\\n",
    "                                              \"_result.pickle FILE ALREADY EXIST.\")\n",
    "                                        Javascript('IPython.notebook.kernel.restart()')\n",
    "                                        Javascript('IPython.notebook.execute_all_cells()')\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        y2 = onehottify(y_single['BTC'], n=2)                          \n",
    "\n",
    "                                        Evaluate(pickle_load_dir_path, \n",
    "                                                 data_files_dir, \n",
    "                                                 epochs, \n",
    "                                                 pickle_result_dir_path, \n",
    "                                                 time_unit, \n",
    "                                                 window_size, \n",
    "                                                 gap, \n",
    "                                                 margin_rate, \n",
    "                                                 _TEST, \n",
    "                                                 _ENHANCE,\n",
    "                                                 coin,\n",
    "                                                 X, y2,\n",
    "                                                 key_name_X,\n",
    "                                                 key_name_y,\n",
    "                                                 idx_time_unit,\n",
    "                                                 idx_window_size,\n",
    "                                                 idx_gap,\n",
    "                                                 idx_margix_rate, \n",
    "                                                 MODEL,\n",
    "                                                 _GPU,\n",
    "                                                 n_jobs, \n",
    "                                                 machine,\n",
    "                                                 Internet_connection)\n",
    "                                        Javascript('IPython.notebook.kernel.restart()')\n",
    "                                        Javascript('IPython.notebook.execute_all_cells()')\n",
    "\n",
    "# 저장된 pickle 파일의 데이터 구조\n",
    "# tmp = {}\n",
    "# tmp[\"10_1_1_0.1\"] = {\"grid_result.best_score_\":{}}, {\"grid_result.best_params_\":{}}\n",
    "# type(tmp[\"10_1_1_0.1\"][0])\n",
    "# print(tmp[\"10_1_1_0.1\"])\n",
    "# print(tmp[\"10_1_1_0.1\"])\n",
    "# print(tmp[\"10_1_1_0.1\"][0])\n",
    "# print(tmp[\"10_1_1_0.1\"][0]['grid_result.best_score_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(pickle_load_dir_path, \n",
    "             data_files_dir, \n",
    "             epochs, \n",
    "             pickle_result_dir_path, \n",
    "             time_unit, \n",
    "             window_size, \n",
    "             gap, \n",
    "             margin_rate, \n",
    "             _TEST, \n",
    "             _ENHANCE, \n",
    "             coin, \n",
    "             X, y2, \n",
    "             key_name_X,\n",
    "             key_name_y,\n",
    "             idx_time_unit,\n",
    "             idx_window_size,\n",
    "             idx_gap,\n",
    "             idx_margix_rate, \n",
    "             MODEL,\n",
    "             _GPU,\n",
    "             n_jobs, \n",
    "             machine,\n",
    "             Internet_connection):\n",
    "    \n",
    "    \n",
    "                        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.1, random_state=42)\n",
    "#     print(\"X_train.shape\")\n",
    "#     print(X_train.shape)\n",
    "#     print(\"y_train.shape\")\n",
    "#     print(y_train.shape)\n",
    "#     print()\n",
    "#     print(\"X_test.shape\")\n",
    "#     print(X_test.shape)\n",
    "#     print(\"y_test.shape\")\n",
    "#     print(y_test.shape)\n",
    "#     print()\n",
    "\n",
    "    n_coins = 8\n",
    "    n_price = 4\n",
    "    n_steps = idx_window_size # 원래 100이었음. reshape 문제 때문에 수정함\n",
    "\n",
    "    X_train_2 = X_train.transpose([0, 2, 1, 3])\n",
    "    X_test_2 = X_test.transpose([0, 2, 1, 3])\n",
    "#     print(\"X_train_2.shape\")\n",
    "#     print(X_train_2.shape)\n",
    "#     print(\"X_test_2.shape\")\n",
    "#     print(X_test_2.shape)\n",
    "#     print()\n",
    "\n",
    "    X_train_3 = X_train_2.reshape([X_train.shape[0], n_steps, n_coins * n_price])\n",
    "    X_test_3 = X_test_2.reshape([X_test.shape[0], n_steps, n_coins * n_price])\n",
    "#     print(\"X_train_3.shape\")\n",
    "#     print(X_train_3.shape)\n",
    "#     print(\"X_test_3.shape\")\n",
    "#     print(X_test_3.shape)\n",
    "#     print()\n",
    "\n",
    "    if (_TEST==True and _ENHANCE==False):\n",
    "        param_grid = {'window_size' : [n_steps], \n",
    "                      'n_state_units': [100],\n",
    "                      'activation': ['relu'], \n",
    "                      'optimizer': ['rmsprop'], #sgd 추가\n",
    "                      'init': ['glorot_uniform'], #he 추가\n",
    "                      'batch_size': [2048]}\n",
    "\n",
    "    elif (_TEST==False and _ENHANCE==False):\n",
    "        param_grid = {'window_size' : [n_steps], \n",
    "                      'n_state_units': [40, 80, 160],\n",
    "                      'activation': ['relu', 'softmax'], \n",
    "                      'optimizer': ['rmsprop', 'adam'], #sgd 추가\n",
    "                      'init': ['glorot_uniform', 'uniform', 'he_uniform'], #he 추가\n",
    "                      'batch_size': [64,128,256]}\n",
    "        \n",
    "    elif (_TEST==False and _ENHANCE==True):\n",
    "        param_grid = {'window_size' : [], \n",
    "                      'n_state_units': [],\n",
    "                      'activation': [], \n",
    "                      'optimizer': [], #sgd 추가\n",
    "                      'init': [], #he 추가\n",
    "                      'batch_size': [10, 50],\n",
    "                      'dropout_rate':[0.0, 0.1, 0.2, 0.3, 0.4, 0.5], # after paramter select. when epochs raise..\n",
    "                      'neurons':[2,10,100]}\n",
    "\n",
    "\n",
    "\n",
    "    X_train_reshape = X_train_2.reshape([X_train.shape[0], n_steps*n_coins * n_price])\n",
    "    X_test_reshape = X_test_2.reshape([X_test.shape[0], n_steps*n_coins * n_price])\n",
    "#     print(\"X_train_reshape.shape\")\n",
    "#     print(X_train_reshape.shape)\n",
    "#     print(\"X_test_reshape.shape\")\n",
    "#     print(X_test_reshape.shape)\n",
    "#     print()\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train_reshape)\n",
    "    X_train_scaled = scaler.transform(X_train_reshape)\n",
    "    X_test_scaled = scaler.transform(X_test_reshape)\n",
    "\n",
    "    X_train_scaled = X_train_scaled.reshape(-1, n_steps, n_coins * n_price)\n",
    "\n",
    "    X_test_scaled = X_test_scaled.reshape(-1, n_steps, n_coins * n_price)\n",
    "\n",
    "    \n",
    "    if _GPU == True:\n",
    "        if MODEL == \"SimpleRNN\" :\n",
    "            model = KerasClassifier(build_fn=create_model_SimpleRNN, \n",
    "                                    epochs=epochs, # epochs는 실험을 최종적으로 수행하고자 할 때 높일 것(100~150정도)\n",
    "#                                     batch_size=100, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"LSTM\":\n",
    "            model = KerasClassifier(build_fn=create_model_LSTM, \n",
    "                                    epochs=epochs, # epochs는 실험을 최종적으로 수행하고자 할 때 높일 것(100~150정도)\n",
    "#                                     batch_size=100, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"RNN\":\n",
    "            model = KerasClassifier(build_fn=create_model_RNN, \n",
    "                                    epochs=epochs, # epochs는 실험을 최종적으로 수행하고자 할 때 높일 것(100~150정도)\n",
    "#                                     batch_size=100, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"GRU\":\n",
    "            model = KerasClassifier(build_fn=create_model_GRU, \n",
    "                                    epochs=epochs, # epochs는 실험을 최종적으로 수행하고자 할 때 높일 것(100~150정도)\n",
    "#                                     batch_size=100, \n",
    "                                    verbose=True)\n",
    "    elif _GPU == False:\n",
    "        if MODEL == \"SimpleRNN\" :\n",
    "            model = KerasClassifier(build_fn=create_model_SimpleRNN_non_GPU, \n",
    "                                    epochs=epochs, # epochs는 실험을 최종적으로 수행하고자 할 때 높일 것(100~150정도)\n",
    "                                    batch_size=10, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"LSTM\":\n",
    "            model = KerasClassifier(build_fn=create_model_LSTM_non_GPU, \n",
    "                                    epochs=epochs, # epochs는 실험을 최종적으로 수행하고자 할 때 높일 것(100~150정도)\n",
    "                                    batch_size=10, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"RNN\":\n",
    "            model = KerasClassifier(build_fn=create_model_RNN_non_GPU, \n",
    "                                    epochs=epochs, # epochs는 실험을 최종적으로 수행하고자 할 때 높일 것(100~150정도)\n",
    "                                    batch_size=10, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"GRU\":\n",
    "            model = KerasClassifier(build_fn=create_model_GRU_non_GPU, \n",
    "                                    epochs=epochs, # epochs는 실험을 최종적으로 수행하고자 할 때 높일 것(100~150정도)\n",
    "                                    batch_size=10, \n",
    "                                    verbose=True)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model, \n",
    "        cv=5, \n",
    "        n_jobs=n_jobs, # test\n",
    "        param_grid=param_grid,\n",
    "        verbose=1)\n",
    "\n",
    "    X_train_scaled, X_test_scaled = input_reshape(X_train_scaled, X_test_scaled, n_steps, n_coins, n_price)\n",
    "    \n",
    "    if (_TEST == True): \n",
    "        print()\n",
    "        print()\n",
    "        print(\"TEST!\")\n",
    "        print()\n",
    "        print(\"----------------------\")\n",
    "        print(\"<\"+MODEL+\">\")\n",
    "        print(\"----------------------\")\n",
    "        print(\"__\"+\"BTC\"+\"__\" + \\\n",
    "                \"time unit: \"+str(idx_time_unit) + \"  |  \" + \\\n",
    "                \"window_size :\"+str(idx_window_size) + \"  |  \" + \\\n",
    "                \"gap :\"+str(idx_gap) + \"  |  \" + \\\n",
    "                \"margin_rate :\"+str(idx_margix_rate) + \\\n",
    "                \"  started.\")\n",
    "    elif (_TEST == False):\n",
    "        print()\n",
    "        print()\n",
    "        print(\"----------------------\")\n",
    "        print(\"<\"+MODEL+\">\")\n",
    "        print(\"----------------------\")\n",
    "        print(\"__\"+coin+\"__\" + \\\n",
    "                \"time unit: \"+str(idx_time_unit) + \"  |  \" + \\\n",
    "                \"window_size :\"+str(idx_window_size) + \"  |  \" + \\\n",
    "                \"gap :\"+str(idx_gap) + \"  |  \" + \\\n",
    "                \"margin_rate :\"+str(idx_margix_rate) + \\\n",
    "                \"  started.\")\n",
    "    \n",
    "#     from keras.optimizers import Adam, Nadam\n",
    "#     from keras.activations import softmax\n",
    "#     from keras.losses import categorical_crossentropy, logcosh\n",
    "\n",
    "#     p = {'lr': (2, 10, 30),\n",
    "#          'first_neuron':[4, 8, 16, 32, 64, 128],\n",
    "#          'batch_size': [2, 3, 4],\n",
    "#          'epochs': [500],\n",
    "#          'dropout': (0, 0.40, 10),\n",
    "#          'optimizer': [Adam, Nadam],\n",
    "#          'loss': [categorical_crossentropy, logcosh],\n",
    "#          'last_activation': [softmax],\n",
    "#          'weight_regulizer':[None],\n",
    "#          'emb_output_dims': [None]}\n",
    "\n",
    "#     import hyperio as hy\n",
    "#     h = hy.Hyperio(X_train_scaled, y_train, \n",
    "#                    params=p, \n",
    "#     #                dataset_name='iris', \n",
    "#                    experiment_no='1', \n",
    "#                    model=create_model_SimpleRNN_non_GPU_test,\n",
    "#                    # create_model_SimpleRNN_non_GPU_test(x_train, y_train, x_val, y_val, params)\n",
    "#                    grid_downsample=.01)\n",
    "\n",
    "###########################################################\n",
    "#     grid_result = grid.fit(X_train_scaled, \n",
    "#                            y_train, \n",
    "#                            validation_data=(X_test_scaled,y_test))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"----------------------\")\n",
    "\n",
    "    # \n",
    "#     means = grid_result.cv_results_['mean_test_score']\n",
    "#     stds = grid_result.cv_results_['std_test_score']\n",
    "#     params = grid_result.cv_results_['params']\n",
    "#     print(\"grid_result.cv_results_\",grid_result.cv_results_)\n",
    "#     print(\"grid_result.best_estimator_\",grid_result.best_estimator_)\n",
    "    print(\"grid_result.score(X_test_scaled, y_test): \",grid_result.score(X_test_scaled, y_test))\n",
    "    \n",
    "    \n",
    "            \n",
    "    evaluate_result = {}\n",
    "    \n",
    "    if (_TEST == True): \n",
    "        test_score = grid_result.score(X_test_scaled, y_test)\n",
    "        evaluate_result[MODEL + \"_\" + \\\n",
    "                      \"BTC\" + \"_\" + \\\n",
    "                      str(idx_time_unit) + \"_\" + \\\n",
    "                      str(idx_window_size) + \"_\" + \\\n",
    "                      str(idx_gap) + \"_\" + \\\n",
    "                      str(idx_margix_rate)] = {\"MODEL: \":MODEL,\\\n",
    "                                        \"Cryptocurrency: \":\"BTC\",\\\n",
    "#                                         \"grid_result.cv_results_\":grid_result.cv_results_, \\\n",
    "#                                         \"grid_result.best_estimator_\":grid_result.best_estimator_, \\\n",
    "                                        \"grid_result.cv_results_['mean_test_score']\":grid_result.cv_results_['mean_test_score'], \\\n",
    "                                        \"grid_result.cv_results_['params']\":grid_result.cv_results_['params'],\\\n",
    "                                        \"grid_result.test_score\":test_score}     \n",
    "                                        \n",
    "\n",
    "    elif (_TEST == False): \n",
    "        test_score = grid_result.score(X_test_scaled, y_test)\n",
    "        evaluate_result[MODEL + \"_\" + \\\n",
    "                      coin + \"_\" + \\\n",
    "                      str(idx_time_unit) + \"_\" + \\\n",
    "                      str(idx_window_size) + \"_\" + \\\n",
    "                      str(idx_gap) + \"_\" + \\\n",
    "                      str(idx_margix_rate)] = {\"MODEL: \":MODEL,\\\n",
    "                                        \"Cryptocurrency: \":coin, \\\n",
    "                                        \"grid_result.cv_results_['mean_test_score']\":grid_result.cv_results_['mean_test_score'], \\\n",
    "                                        \"grid_result.cv_results_['params']\":grid_result.cv_results_['params'],\\\n",
    "                                        \"grid_result.test_score\":test_score}\n",
    "#     print()\n",
    "#     print(\"evaluate result dict: \", evaluate_result)\n",
    "#     print()\n",
    "\n",
    "    # summarize results\n",
    "    print()\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    print()\n",
    "    # for checking pickle file exist\n",
    "    print(\"---pickle saving..\")\n",
    "    if (_TEST == True):\n",
    "        X = {}\n",
    "        y = {}\n",
    "        key_name_X = \"X_\"\n",
    "        key_name_y = \"y_\"\n",
    "        for idx_time_unit in time_unit:\n",
    "            for idx_window_size in window_size:\n",
    "                for idx_gap in gap:\n",
    "                    for idx_margix_rate in margin_rate:\n",
    "                        key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                        key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                        if (os.path.isfile(pickle_result_dir_path + \\\n",
    "                                          \"_test_\" + \\\n",
    "                                          MODEL + \"_\" + \\\n",
    "                                          \"BTC\" + \"_\" + \\\n",
    "                                          str(idx_time_unit) + \"_\" + \\\n",
    "                                          str(idx_window_size) + \"_\" + \\\n",
    "                                          str(idx_gap) + \"_\" + \\\n",
    "                                          str(idx_margix_rate) + \\\n",
    "                                          \"_result.pickle\")) is not True:\n",
    "                            with open(pickle_result_dir_path + \\\n",
    "                                      \"_test_\" + \\\n",
    "                                      MODEL + \"_\" + \\\n",
    "                                      \"BTC\" + \"_\" + \\\n",
    "                                      str(idx_time_unit) + \"_\" + \\\n",
    "                                      str(idx_window_size) + \"_\" + \\\n",
    "                                      str(idx_gap) + \"_\" + \\\n",
    "                                      str(idx_margix_rate) + \\\n",
    "                                      \"_result.pickle\", 'wb') as handle:\n",
    "                                pickle.dump(evaluate_result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                                \n",
    "                                # Sending Email\n",
    "                                if Internet_connection == True:\n",
    "                                    smtp = smtplib.SMTP('smtp.naver.com', 587)\n",
    "                                    smtp.ehlo()      # say Hello\n",
    "                                    smtp.starttls()  # TLS 사용시 필요\n",
    "                                    smtp.login('dhgdohk@naver.com', '30892793@dohk')\n",
    "\n",
    "                                    msg = MIMEText(pickle_result_dir_path + \\\n",
    "                                                   \"_test_\" + \\\n",
    "                                                   MODEL + \"_\" + \\\n",
    "                                                   \"BTC\" + \"_\" + \\\n",
    "                                                   str(idx_time_unit) + \"_\" + \\\n",
    "                                                   str(idx_window_size) + \"_\" + \\\n",
    "                                                   str(idx_gap) + \"_\" + \\\n",
    "                                                   str(idx_margix_rate) + \\\n",
    "                                                   \"_result.pickle\")\n",
    "                                    msg['Subject'] =   pickle_result_dir_path + \\\n",
    "                                                       MODEL + \"_\" + \\\n",
    "                                                       \"BTC\" + \"_\" + \\\n",
    "                                                       str(idx_time_unit) + \"_\" + \\\n",
    "                                                       str(idx_window_size) + \"_\" + \\\n",
    "                                                       str(idx_gap) + \"_\" + \\\n",
    "                                                       str(idx_margix_rate) + \\\n",
    "                                                       \"_result.pickle\"\n",
    "                                    msg['To'] = 'dhgdohk@naver.com'\n",
    "                                    smtp.sendmail('dhgdohk@naver.com', 'dhgdohk@naver.com', msg.as_string())\n",
    "\n",
    "                                    smtp.quit()\n",
    "                        else:\n",
    "                            print(\"Already exist the file: \", pickle_result_dir_path + \\\n",
    "                                                              \"_test_\" + \\\n",
    "                                                              MODEL + \"_\" + \\\n",
    "                                                              \"BTC\" + \"_\" + \\\n",
    "                                                              str(idx_time_unit) + \"_\" + \\\n",
    "                                                              str(idx_window_size) + \"_\" + \\\n",
    "                                                              str(idx_gap) + \"_\" + \\\n",
    "                                                              str(idx_margix_rate) + \\\n",
    "                                                              \"_result.pickle\")\n",
    "\n",
    "    elif (_TEST == False): \n",
    "        X = {}\n",
    "        y = {}\n",
    "        key_name_X = \"X_\"\n",
    "        key_name_y = \"y_\"\n",
    "        for idx_time_unit in time_unit:\n",
    "            for idx_window_size in window_size:\n",
    "                for idx_gap in gap:\n",
    "                    for idx_margix_rate in margin_rate:\n",
    "                        key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                        key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "                        if (os.path.isfile(pickle_result_dir_path + \\\n",
    "                                          MODEL + \"_\" + \\\n",
    "                                          coin + \"_\" + \\\n",
    "                                          str(idx_time_unit) + \"_\" + \\\n",
    "                                          str(idx_window_size) + \"_\" + \\\n",
    "                                          str(idx_gap) + \"_\" + \\\n",
    "                                          str(idx_margix_rate) + \\\n",
    "                                          \"_result.pickle\")) is not True:\n",
    "                            with open(pickle_result_dir_path + \\\n",
    "                                      MODEL + \"_\" + \\\n",
    "                                      coin + \"_\" + \\\n",
    "                                      str(idx_time_unit) + \"_\" + \\\n",
    "                                      str(idx_window_size) + \"_\" + \\\n",
    "                                      str(idx_gap) + \"_\" + \\\n",
    "                                      str(idx_margix_rate) + \\\n",
    "                                      \"_result.pickle\", 'wb') as handle:\n",
    "                                pickle.dump(evaluate_result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                                \n",
    "                                # Sending Email\n",
    "                                if Internet_connection == True:\n",
    "                                    smtp = smtplib.SMTP('smtp.naver.com', 587)\n",
    "                                    smtp.ehlo()      # say Hello\n",
    "                                    smtp.starttls()  # TLS 사용시 필요\n",
    "                                    smtp.login('dhgdohk@naver.com', '30892793@dohk')\n",
    "\n",
    "                                    msg = MIMEText(machine + \\\n",
    "                                                   pickle_result_dir_path + \\\n",
    "                                                   MODEL + \"_\" + \\\n",
    "                                                   coin + \"_\" + \\\n",
    "                                                   str(idx_time_unit) + \"_\" + \\\n",
    "                                                   str(idx_window_size) + \"_\" + \\\n",
    "                                                   str(idx_gap) + \"_\" + \\\n",
    "                                                   str(idx_margix_rate) + \\\n",
    "                                                   \"_result.pickle\")\n",
    "                                    msg['Subject'] =   machine + \\\n",
    "                                                       pickle_result_dir_path + \\\n",
    "                                                       MODEL + \"_\" + \\\n",
    "                                                       coin + \"_\" + \\\n",
    "                                                       str(idx_time_unit) + \"_\" + \\\n",
    "                                                       str(idx_window_size) + \"_\" + \\\n",
    "                                                       str(idx_gap) + \"_\" + \\\n",
    "                                                       str(idx_margix_rate) + \\\n",
    "                                                       \"_result.pickle\"\n",
    "                                    msg['To'] = 'dhgdohk@naver.com'\n",
    "                                    smtp.sendmail('dhgdohk@naver.com', 'dhgdohk@naver.com', msg.as_string())\n",
    "\n",
    "                                    smtp.quit()\n",
    "                        else:\n",
    "                            print(\"Already exist the file: \", pickle_result_dir_path + \\\n",
    "                                                              \"_test_\" + \\\n",
    "                                                              MODEL + \"_\" + \\\n",
    "                                                              \"BTC\" + \"_\" + \\\n",
    "                                                              str(idx_time_unit) + \"_\" + \\\n",
    "                                                              str(idx_window_size) + \"_\" + \\\n",
    "                                                              str(idx_gap) + \"_\" + \\\n",
    "                                                              str(idx_margix_rate) + \\\n",
    "                                                              \"_result.pickle\")\n",
    "                        Javascript('IPython.notebook.kernel.restart()')\n",
    "                        Javascript('IPython.notebook.execute_all_cells()')\n",
    "    print()\n",
    "\n",
    "\n",
    "#     for mean, stdev, param in zip(means, stds, params):\n",
    "#         print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "#     print()\n",
    "\n",
    "\n",
    "    key_name_X = \"X_\"\n",
    "    key_name_y = \"y_\"\n",
    "    \n",
    "    \n",
    "#     return eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(machine, Internet_connection):\n",
    "    '''\n",
    "        [ATTENTION] In create_model METHOD part, need to set appropriate about GPU\n",
    "        \n",
    "        LINK01 -> GPU OFF\n",
    "        MSI -> GPU OFF\n",
    "        SLAVE04 -> GPU ON\n",
    "        SLAVE05 -> GPU ON\n",
    "    ''' \n",
    "    # \n",
    "    if machine==\"slave05-1\":\n",
    "        time_unit = [10,30,60]     # candle stick minutes\n",
    "        window_size = [25]  # Unit: num. of candle sticks\n",
    "        gap = [1]            # Unit: num. of candle sticks\n",
    "        margin_rate = [0.1]  # Unit: percent\n",
    "\n",
    "        start_time = time.time()\n",
    "        Start_Model( pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                     data_files_dir = dataset_dir_path_tuple_type, \n",
    "                     epochs=1, \n",
    "                     pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                     time_unit = time_unit, \n",
    "                     window_size = window_size, \n",
    "                     gap = gap, \n",
    "                     margin_rate = margin_rate, \n",
    "                     _TEST=False, \n",
    "                     _ENHANCE=False,\n",
    "                     _GPU=True,\n",
    "                     n_jobs=2,\n",
    "                     machine=\"slave05\", \n",
    "                     Internet_connection=Internet_connection)\n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')\n",
    "\n",
    "    elif machine==\"slave05-2\":\n",
    "        time_unit = [10]     # candle stick minutes\n",
    "        window_size = [10,25,50]  # Unit: num. of candle sticks\n",
    "        gap = [1]            # Unit: num. of candle sticks\n",
    "        margin_rate = [0.1]  # Unit: percent\n",
    "\n",
    "        Start_Model( pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                     data_files_dir = dataset_dir_path_tuple_type, \n",
    "                     epochs=1, \n",
    "                     pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                     time_unit = time_unit, \n",
    "                     window_size = window_size, \n",
    "                     gap = gap, \n",
    "                     margin_rate = margin_rate, \n",
    "                     _TEST=False, \n",
    "                     _ENHANCE=False,\n",
    "                     _GPU=False,\n",
    "                     n_jobs=1,\n",
    "                     machine=\"slave05\", \n",
    "                     Internet_connection=Internet_connection)\n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')\n",
    "\n",
    "    elif machine==\"slave04\":\n",
    "        time_unit = [10]     # candle stick minutes\n",
    "        window_size = [75]  # Unit: num. of candle sticks\n",
    "        gap = [1]            # Unit: num. of candle sticks\n",
    "        margin_rate = [0.1]  # Unit: percent\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        Start_Model(pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                 data_files_dir = dataset_dir_path_tuple_type, \n",
    "                 epochs=1, \n",
    "                 pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                 time_unit = time_unit, \n",
    "                 window_size = window_size, \n",
    "                 gap = gap, \n",
    "                 margin_rate = margin_rate, \n",
    "                 _TEST=False, \n",
    "                 _ENHANCE=False,\n",
    "                 _GPU=True,\n",
    "                 n_jobs=2,\n",
    "                 machine=\"slave04\",\n",
    "                 Internet_connection=Internet_connection)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')\n",
    "\n",
    "    elif machine==\"link01\":\n",
    "        time_unit = [10]     # candle stick minutes\n",
    "        window_size = [10]  # Unit: num. of candle sticks\n",
    "        gap = [1,2,3]            # Unit: num. of candle sticks\n",
    "        margin_rate = [0.1]  # Unit: percent\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        Start_Model(pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                 data_files_dir = dataset_dir_path_tuple_type, \n",
    "                 epochs=1, \n",
    "                 pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                 time_unit = time_unit, \n",
    "                 window_size = window_size, \n",
    "                 gap = gap, \n",
    "                 margin_rate = margin_rate, \n",
    "                 _TEST=False,\n",
    "                 _ENHANCE=False,\n",
    "                 _GPU=False,\n",
    "                 n_jobs=1,\n",
    "                 machine=\"link01\", \n",
    "                 Internet_connection=Internet_connection)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')\n",
    "\n",
    "    elif machine==\"MSI\":\n",
    "        time_unit = [10]     # candle stick minutes\n",
    "        window_size = [10]  # Unit: num. of candle sticks\n",
    "        gap = [1]            # Unit: num. of candle sticks\n",
    "        margin_rate = [0.1,0.25,0.5]  # Unit: percent\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        Start_Model(pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                 data_files_dir = dataset_dir_path_tuple_type, \n",
    "                 epochs=1, \n",
    "                 pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                 time_unit = time_unit, \n",
    "                 window_size = window_size, \n",
    "                 gap = gap, \n",
    "                 margin_rate = margin_rate, \n",
    "                 _TEST=False, \n",
    "                 _ENHANCE=False,\n",
    "                 _GPU=False,\n",
    "                 n_jobs=1,\n",
    "                 machine=\"MSI\", \n",
    "                 Internet_connection=Internet_connection)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')\n",
    "    elif machine==\"MacBook\":\n",
    "        time_unit = [10]     # candle stick minutes\n",
    "        window_size = [10]  # Unit: num. of candle sticks\n",
    "        gap = [1]            # Unit: num. of candle sticks\n",
    "        margin_rate = [0.1,0.25,0.5]  # Unit: percent\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        Start_Model(pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                 data_files_dir = dataset_dir_path_tuple_type, \n",
    "                 epochs=1, \n",
    "                 pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                 time_unit = time_unit, \n",
    "                 window_size = window_size, \n",
    "                 gap = gap, \n",
    "                 margin_rate = margin_rate, \n",
    "                 _TEST=False, \n",
    "                 _ENHANCE=False,\n",
    "                 _GPU=False,\n",
    "                 n_jobs=1,\n",
    "                 machine=\"MSI\", \n",
    "                 Internet_connection=Internet_connection)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start(machine=\"MacBook\", Internet_connection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate model using test data\n",
    "# score = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load pickle file \n",
    "# import pickle\n",
    "# b_x = pickle.load(open(\"./evaluate_result/_test_SimpleRNN_BTC_10_10_1_0.1_result.pickle\", \"rb\"))\n",
    "# b_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Boost-up Acc, F1\n",
    "# evaluate_result_dir_path = \"./evaluate_result/acc_f1/\"\n",
    "# dataset_dir_path = dataset_dir_path_tuple_type \n",
    "# # dataset_dir_path = dataset_dir_path_numpy_type\n",
    "# epochs = 100\n",
    "# Evaluate(dataset_dir_path, data_files_dir, epochs, evaluate_result_dir_path, time_unit, window_size, gap, margin_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "def create_model_SimpleRNN_non_GPU_test(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        SimpleRNN(\n",
    "#             n_state_units, \n",
    "                  params['first_neuron'],\n",
    "                  input_dim=x_train.shape[2], # [dataset 크기, 윈도우 사이즈, 32(코인개수*OLHC)]\n",
    "#                   input_shape=(window_size, 32),\n",
    "#                   use_bias=True, \n",
    "                  #activation='relu'\n",
    "        ))\n",
    "#                   kernel_initializer='glorot_uniform', \n",
    "#                   recurrent_initializer='orthogonal', \n",
    "#                   bias_initializer='zeros', \n",
    "#                   dropout=0.0,\n",
    "#                   recurrent_dropout=0.0))\n",
    "    \n",
    "#     model.add(Dense(units=neurons))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "        \n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(y_train.shape[1],\n",
    "                    activation=params['last_activation']))\n",
    "        \n",
    "#     model.add(Dense(units=2))\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "#     model.compile(optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], params['optimizer'])),\n",
    "#                   loss=params['loss'],\n",
    "#                   metrics=['acc'])\n",
    "    model.compile(optimizer=params['optimizer'](),\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['acc', f1_score])\n",
    "        \n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=1,\n",
    "                    validation_data=[x_val, y_val])\n",
    "#                     callbacks=early_stopper(params['epochs'], mode='strict'))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(32, input_shape=(None, 32))`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32843 samples, validate on 14076 samples\n",
      "Epoch 1/100\n",
      "32843/32843 [==============================] - 2s 57us/step - loss: 0.6459 - acc: 0.6573 - f1_score: 0.6573 - val_loss: 0.6273 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 2/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6335 - acc: 0.6671 - f1_score: 0.6671 - val_loss: 0.6257 - val_acc: 0.6736 - val_f1_score: 0.6736\n",
      "Epoch 3/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6323 - acc: 0.6675 - f1_score: 0.6675 - val_loss: 0.6267 - val_acc: 0.6734 - val_f1_score: 0.6734\n",
      "Epoch 4/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6311 - acc: 0.6678 - f1_score: 0.6678 - val_loss: 0.6269 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 5/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6300 - acc: 0.6674 - f1_score: 0.6674 - val_loss: 0.6255 - val_acc: 0.6737 - val_f1_score: 0.6737\n",
      "Epoch 6/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6299 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6243 - val_acc: 0.6721 - val_f1_score: 0.6721\n",
      "Epoch 7/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6300 - acc: 0.6674 - f1_score: 0.6674 - val_loss: 0.6248 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 8/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6290 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6236 - val_acc: 0.6740 - val_f1_score: 0.6740\n",
      "Epoch 9/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6288 - acc: 0.6673 - f1_score: 0.6673 - val_loss: 0.6235 - val_acc: 0.6734 - val_f1_score: 0.6734\n",
      "Epoch 10/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6284 - acc: 0.6676 - f1_score: 0.6676 - val_loss: 0.6248 - val_acc: 0.6738 - val_f1_score: 0.6738\n",
      "Epoch 11/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6278 - acc: 0.6688 - f1_score: 0.6688 - val_loss: 0.6237 - val_acc: 0.6736 - val_f1_score: 0.6736\n",
      "Epoch 12/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6277 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6228 - val_acc: 0.6726 - val_f1_score: 0.6726\n",
      "Epoch 13/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6273 - acc: 0.6680 - f1_score: 0.6680 - val_loss: 0.6239 - val_acc: 0.6731 - val_f1_score: 0.6731\n",
      "Epoch 14/100\n",
      "32843/32843 [==============================] - 1s 46us/step - loss: 0.6264 - acc: 0.6690 - f1_score: 0.6690 - val_loss: 0.6223 - val_acc: 0.6721 - val_f1_score: 0.6721\n",
      "Epoch 15/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6268 - acc: 0.6677 - f1_score: 0.6677 - val_loss: 0.6245 - val_acc: 0.6717 - val_f1_score: 0.6717\n",
      "Epoch 16/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6265 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6226 - val_acc: 0.6721 - val_f1_score: 0.6721\n",
      "Epoch 17/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6261 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6221 - val_acc: 0.6712 - val_f1_score: 0.6712\n",
      "Epoch 18/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6259 - acc: 0.6692 - f1_score: 0.6692 - val_loss: 0.6215 - val_acc: 0.6732 - val_f1_score: 0.6732\n",
      "Epoch 19/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6262 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6218 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 20/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6251 - acc: 0.6679 - f1_score: 0.6679 - val_loss: 0.6214 - val_acc: 0.6729 - val_f1_score: 0.6729\n",
      "Epoch 21/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6255 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6211 - val_acc: 0.6721 - val_f1_score: 0.6721\n",
      "Epoch 22/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6253 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6213 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 23/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6252 - acc: 0.6679 - f1_score: 0.6679 - val_loss: 0.6216 - val_acc: 0.6722 - val_f1_score: 0.6722\n",
      "Epoch 24/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6250 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6257 - val_acc: 0.6731 - val_f1_score: 0.6731\n",
      "Epoch 25/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6249 - acc: 0.6680 - f1_score: 0.6680 - val_loss: 0.6230 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 26/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6248 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6225 - val_acc: 0.6721 - val_f1_score: 0.6721\n",
      "Epoch 27/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6248 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6216 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 28/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6245 - acc: 0.6683 - f1_score: 0.6683 - val_loss: 0.6223 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 29/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6242 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6227 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 30/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6241 - acc: 0.6688 - f1_score: 0.6688 - val_loss: 0.6220 - val_acc: 0.6715 - val_f1_score: 0.6715\n",
      "Epoch 31/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6243 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6214 - val_acc: 0.6727 - val_f1_score: 0.6727\n",
      "Epoch 32/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6246 - acc: 0.6694 - f1_score: 0.6694 - val_loss: 0.6211 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 33/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6241 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6219 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 34/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6243 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6234 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 35/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6239 - acc: 0.6689 - f1_score: 0.6689 - val_loss: 0.6215 - val_acc: 0.6717 - val_f1_score: 0.6717\n",
      "Epoch 36/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6239 - acc: 0.6697 - f1_score: 0.6697 - val_loss: 0.6209 - val_acc: 0.6723 - val_f1_score: 0.6723\n",
      "Epoch 37/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6236 - acc: 0.6684 - f1_score: 0.6684 - val_loss: 0.6220 - val_acc: 0.6716 - val_f1_score: 0.6716\n",
      "Epoch 38/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6243 - acc: 0.6693 - f1_score: 0.6693 - val_loss: 0.6212 - val_acc: 0.6731 - val_f1_score: 0.6731\n",
      "Epoch 39/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6232 - acc: 0.6688 - f1_score: 0.6688 - val_loss: 0.6230 - val_acc: 0.6707 - val_f1_score: 0.6707\n",
      "Epoch 40/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6236 - acc: 0.6683 - f1_score: 0.6683 - val_loss: 0.6234 - val_acc: 0.6744 - val_f1_score: 0.6744\n",
      "Epoch 41/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6243 - acc: 0.6689 - f1_score: 0.6689 - val_loss: 0.6213 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 42/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6234 - acc: 0.6683 - f1_score: 0.6683 - val_loss: 0.6224 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 43/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6238 - acc: 0.6691 - f1_score: 0.6691 - val_loss: 0.6215 - val_acc: 0.6712 - val_f1_score: 0.6712\n",
      "Epoch 44/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6236 - acc: 0.6693 - f1_score: 0.6693 - val_loss: 0.6218 - val_acc: 0.6722 - val_f1_score: 0.6722\n",
      "Epoch 45/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6234 - acc: 0.6692 - f1_score: 0.6692 - val_loss: 0.6222 - val_acc: 0.6717 - val_f1_score: 0.6717\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6237 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6219 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 47/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6236 - acc: 0.6683 - f1_score: 0.6683 - val_loss: 0.6208 - val_acc: 0.6721 - val_f1_score: 0.6721\n",
      "Epoch 48/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6235 - acc: 0.6692 - f1_score: 0.6692 - val_loss: 0.6211 - val_acc: 0.6735 - val_f1_score: 0.6735\n",
      "Epoch 49/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6231 - acc: 0.6703 - f1_score: 0.6703 - val_loss: 0.6223 - val_acc: 0.6718 - val_f1_score: 0.6718\n",
      "Epoch 50/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6236 - acc: 0.6683 - f1_score: 0.6683 - val_loss: 0.6241 - val_acc: 0.6716 - val_f1_score: 0.6716\n",
      "Epoch 51/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6233 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6218 - val_acc: 0.6726 - val_f1_score: 0.6726\n",
      "Epoch 52/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6237 - acc: 0.6695 - f1_score: 0.6695 - val_loss: 0.6214 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 53/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6231 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6217 - val_acc: 0.6746 - val_f1_score: 0.6746\n",
      "Epoch 54/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6234 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6211 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 55/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6229 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6208 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 56/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6232 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6266 - val_acc: 0.6672 - val_f1_score: 0.6672\n",
      "Epoch 57/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6231 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6211 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 58/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6228 - acc: 0.6694 - f1_score: 0.6694 - val_loss: 0.6215 - val_acc: 0.6721 - val_f1_score: 0.6721\n",
      "Epoch 59/100\n",
      "32843/32843 [==============================] - 1s 40us/step - loss: 0.6228 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6212 - val_acc: 0.6722 - val_f1_score: 0.6722\n",
      "Epoch 60/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6231 - acc: 0.6683 - f1_score: 0.6683 - val_loss: 0.6223 - val_acc: 0.6705 - val_f1_score: 0.6705\n",
      "Epoch 61/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6234 - acc: 0.6688 - f1_score: 0.6688 - val_loss: 0.6219 - val_acc: 0.6721 - val_f1_score: 0.6721\n",
      "Epoch 62/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6235 - acc: 0.6690 - f1_score: 0.6690 - val_loss: 0.6249 - val_acc: 0.6714 - val_f1_score: 0.6714\n",
      "Epoch 63/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6230 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6207 - val_acc: 0.6730 - val_f1_score: 0.6730\n",
      "Epoch 64/100\n",
      "32843/32843 [==============================] - 1s 40us/step - loss: 0.6230 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6232 - val_acc: 0.6727 - val_f1_score: 0.6727\n",
      "Epoch 65/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6236 - acc: 0.6691 - f1_score: 0.6691 - val_loss: 0.6224 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 66/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6229 - acc: 0.6694 - f1_score: 0.6694 - val_loss: 0.6213 - val_acc: 0.6734 - val_f1_score: 0.6734\n",
      "Epoch 67/100\n",
      "32843/32843 [==============================] - 1s 40us/step - loss: 0.6235 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6214 - val_acc: 0.6727 - val_f1_score: 0.6727\n",
      "Epoch 68/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6231 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6239 - val_acc: 0.6722 - val_f1_score: 0.6722\n",
      "Epoch 69/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6234 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6215 - val_acc: 0.6720 - val_f1_score: 0.6720\n",
      "Epoch 70/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6232 - acc: 0.6692 - f1_score: 0.6692 - val_loss: 0.6209 - val_acc: 0.6723 - val_f1_score: 0.6723\n",
      "Epoch 71/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6226 - acc: 0.6691 - f1_score: 0.6691 - val_loss: 0.6206 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 72/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6228 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6208 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 73/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6225 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6218 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 74/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6227 - acc: 0.6680 - f1_score: 0.6680 - val_loss: 0.6212 - val_acc: 0.6729 - val_f1_score: 0.6729\n",
      "Epoch 75/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6229 - acc: 0.6689 - f1_score: 0.6689 - val_loss: 0.6218 - val_acc: 0.6720 - val_f1_score: 0.6720\n",
      "Epoch 76/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6231 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6218 - val_acc: 0.6715 - val_f1_score: 0.6715\n",
      "Epoch 77/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6228 - acc: 0.6692 - f1_score: 0.6692 - val_loss: 0.6211 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 78/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6227 - acc: 0.6699 - f1_score: 0.6699 - val_loss: 0.6210 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 79/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6225 - acc: 0.6689 - f1_score: 0.6689 - val_loss: 0.6210 - val_acc: 0.6717 - val_f1_score: 0.6717\n",
      "Epoch 80/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6225 - acc: 0.6692 - f1_score: 0.6692 - val_loss: 0.6216 - val_acc: 0.6716 - val_f1_score: 0.6716\n",
      "Epoch 81/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6224 - acc: 0.6678 - f1_score: 0.6678 - val_loss: 0.6222 - val_acc: 0.6731 - val_f1_score: 0.6731\n",
      "Epoch 82/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6226 - acc: 0.6700 - f1_score: 0.6700 - val_loss: 0.6210 - val_acc: 0.6722 - val_f1_score: 0.6722\n",
      "Epoch 83/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6226 - acc: 0.6676 - f1_score: 0.6676 - val_loss: 0.6215 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 84/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6227 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6212 - val_acc: 0.6737 - val_f1_score: 0.6737\n",
      "Epoch 85/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6228 - acc: 0.6688 - f1_score: 0.6688 - val_loss: 0.6206 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 86/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6226 - acc: 0.6692 - f1_score: 0.6692 - val_loss: 0.6217 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 87/100\n",
      "32843/32843 [==============================] - 1s 40us/step - loss: 0.6224 - acc: 0.6692 - f1_score: 0.6692 - val_loss: 0.6207 - val_acc: 0.6736 - val_f1_score: 0.6736\n",
      "Epoch 88/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6225 - acc: 0.6690 - f1_score: 0.6690 - val_loss: 0.6208 - val_acc: 0.6731 - val_f1_score: 0.6731\n",
      "Epoch 89/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6223 - acc: 0.6698 - f1_score: 0.6698 - val_loss: 0.6222 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 90/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6225 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6217 - val_acc: 0.6714 - val_f1_score: 0.6714\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6223 - acc: 0.6688 - f1_score: 0.6688 - val_loss: 0.6211 - val_acc: 0.6709 - val_f1_score: 0.6709\n",
      "Epoch 92/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6225 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6218 - val_acc: 0.6721 - val_f1_score: 0.6721\n",
      "Epoch 93/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6222 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6228 - val_acc: 0.6715 - val_f1_score: 0.6715\n",
      "Epoch 94/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6224 - acc: 0.6688 - f1_score: 0.6688 - val_loss: 0.6213 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 95/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6226 - acc: 0.6680 - f1_score: 0.6680 - val_loss: 0.6207 - val_acc: 0.6736 - val_f1_score: 0.6736\n",
      "Epoch 96/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6228 - acc: 0.6690 - f1_score: 0.6690 - val_loss: 0.6213 - val_acc: 0.6721 - val_f1_score: 0.6721\n",
      "Epoch 97/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6232 - acc: 0.6679 - f1_score: 0.6679 - val_loss: 0.6215 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 98/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6220 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6214 - val_acc: 0.6714 - val_f1_score: 0.6714\n",
      "Epoch 99/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6223 - acc: 0.6697 - f1_score: 0.6697 - val_loss: 0.6209 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 100/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6220 - acc: 0.6692 - f1_score: 0.6692 - val_loss: 0.6220 - val_acc: 0.6720 - val_f1_score: 0.6720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(32, input_shape=(None, 32))`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32843 samples, validate on 14076 samples\n",
      "Epoch 1/100\n",
      "32843/32843 [==============================] - 2s 58us/step - loss: 0.6427 - acc: 0.6634 - f1_score: 0.6634 - val_loss: 0.6270 - val_acc: 0.6731 - val_f1_score: 0.6731\n",
      "Epoch 2/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6326 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6254 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 3/100\n",
      "32843/32843 [==============================] - 1s 40us/step - loss: 0.6324 - acc: 0.6679 - f1_score: 0.6679 - val_loss: 0.6256 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 4/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6307 - acc: 0.6678 - f1_score: 0.6678 - val_loss: 0.6244 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 5/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6296 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6280 - val_acc: 0.6738 - val_f1_score: 0.6738\n",
      "Epoch 6/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6287 - acc: 0.6679 - f1_score: 0.6679 - val_loss: 0.6252 - val_acc: 0.6741 - val_f1_score: 0.6741\n",
      "Epoch 7/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6287 - acc: 0.6683 - f1_score: 0.6683 - val_loss: 0.6242 - val_acc: 0.6735 - val_f1_score: 0.6735\n",
      "Epoch 8/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6281 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6235 - val_acc: 0.6739 - val_f1_score: 0.6739\n",
      "Epoch 9/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6275 - acc: 0.6683 - f1_score: 0.6683 - val_loss: 0.6266 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 10/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6270 - acc: 0.6677 - f1_score: 0.6677 - val_loss: 0.6235 - val_acc: 0.6715 - val_f1_score: 0.6715\n",
      "Epoch 11/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6269 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6225 - val_acc: 0.6740 - val_f1_score: 0.6740\n",
      "Epoch 12/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6264 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6228 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 13/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6263 - acc: 0.6678 - f1_score: 0.6678 - val_loss: 0.6255 - val_acc: 0.6718 - val_f1_score: 0.6718\n",
      "Epoch 14/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6260 - acc: 0.6678 - f1_score: 0.6678 - val_loss: 0.6237 - val_acc: 0.6739 - val_f1_score: 0.6739\n",
      "Epoch 15/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6260 - acc: 0.6683 - f1_score: 0.6683 - val_loss: 0.6222 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 16/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6258 - acc: 0.6676 - f1_score: 0.6676 - val_loss: 0.6220 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 17/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6256 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6252 - val_acc: 0.6718 - val_f1_score: 0.6718\n",
      "Epoch 18/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6253 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6217 - val_acc: 0.6730 - val_f1_score: 0.6730\n",
      "Epoch 19/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6246 - acc: 0.6688 - f1_score: 0.6688 - val_loss: 0.6234 - val_acc: 0.6743 - val_f1_score: 0.6743\n",
      "Epoch 20/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6249 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6262 - val_acc: 0.6726 - val_f1_score: 0.6726\n",
      "Epoch 21/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6250 - acc: 0.6677 - f1_score: 0.6677 - val_loss: 0.6229 - val_acc: 0.6731 - val_f1_score: 0.6731\n",
      "Epoch 22/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6246 - acc: 0.6676 - f1_score: 0.6676 - val_loss: 0.6234 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 23/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6251 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6230 - val_acc: 0.6729 - val_f1_score: 0.6729\n",
      "Epoch 24/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6244 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6217 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 25/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6246 - acc: 0.6680 - f1_score: 0.6680 - val_loss: 0.6227 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 26/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6240 - acc: 0.6689 - f1_score: 0.6689 - val_loss: 0.6222 - val_acc: 0.6726 - val_f1_score: 0.6726\n",
      "Epoch 27/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6243 - acc: 0.6677 - f1_score: 0.6677 - val_loss: 0.6214 - val_acc: 0.6735 - val_f1_score: 0.6735\n",
      "Epoch 28/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6243 - acc: 0.6693 - f1_score: 0.6693 - val_loss: 0.6215 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 29/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6241 - acc: 0.6684 - f1_score: 0.6684 - val_loss: 0.6217 - val_acc: 0.6726 - val_f1_score: 0.6726\n",
      "Epoch 30/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6242 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6212 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 31/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6240 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6214 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 32/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6242 - acc: 0.6689 - f1_score: 0.6689 - val_loss: 0.6213 - val_acc: 0.6734 - val_f1_score: 0.6734\n",
      "Epoch 33/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6238 - acc: 0.6691 - f1_score: 0.6691 - val_loss: 0.6215 - val_acc: 0.6730 - val_f1_score: 0.6730\n",
      "Epoch 34/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6240 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6223 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 35/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6240 - acc: 0.6680 - f1_score: 0.6680 - val_loss: 0.6218 - val_acc: 0.6732 - val_f1_score: 0.6732\n",
      "Epoch 36/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6238 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6217 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 37/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6240 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6214 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 38/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6235 - acc: 0.6697 - f1_score: 0.6697 - val_loss: 0.6214 - val_acc: 0.6736 - val_f1_score: 0.6736\n",
      "Epoch 39/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6239 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6219 - val_acc: 0.6718 - val_f1_score: 0.6718\n",
      "Epoch 40/100\n",
      "32843/32843 [==============================] - 1s 40us/step - loss: 0.6240 - acc: 0.6691 - f1_score: 0.6691 - val_loss: 0.6219 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 41/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6235 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6225 - val_acc: 0.6732 - val_f1_score: 0.6732\n",
      "Epoch 42/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6239 - acc: 0.6684 - f1_score: 0.6684 - val_loss: 0.6212 - val_acc: 0.6720 - val_f1_score: 0.6720\n",
      "Epoch 43/100\n",
      "32843/32843 [==============================] - 2s 46us/step - loss: 0.6236 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6217 - val_acc: 0.6729 - val_f1_score: 0.6729\n",
      "Epoch 44/100\n",
      "32843/32843 [==============================] - 2s 47us/step - loss: 0.6235 - acc: 0.6680 - f1_score: 0.6680 - val_loss: 0.6209 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 45/100\n",
      "32843/32843 [==============================] - 2s 59us/step - loss: 0.6234 - acc: 0.6678 - f1_score: 0.6678 - val_loss: 0.6225 - val_acc: 0.6726 - val_f1_score: 0.6726\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32843/32843 [==============================] - 2s 64us/step - loss: 0.6235 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6228 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 47/100\n",
      "32843/32843 [==============================] - 2s 49us/step - loss: 0.6236 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6242 - val_acc: 0.6729 - val_f1_score: 0.6729\n",
      "Epoch 48/100\n",
      "32843/32843 [==============================] - 2s 47us/step - loss: 0.6237 - acc: 0.6689 - f1_score: 0.6689 - val_loss: 0.6212 - val_acc: 0.6730 - val_f1_score: 0.6730\n",
      "Epoch 49/100\n",
      "32843/32843 [==============================] - 2s 46us/step - loss: 0.6236 - acc: 0.6694 - f1_score: 0.6694 - val_loss: 0.6228 - val_acc: 0.6721 - val_f1_score: 0.6721\n",
      "Epoch 50/100\n",
      "32843/32843 [==============================] - 2s 47us/step - loss: 0.6231 - acc: 0.6701 - f1_score: 0.6701 - val_loss: 0.6218 - val_acc: 0.6730 - val_f1_score: 0.6730\n",
      "Epoch 51/100\n",
      "32843/32843 [==============================] - 2s 51us/step - loss: 0.6229 - acc: 0.6679 - f1_score: 0.6679 - val_loss: 0.6228 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 52/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6237 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6213 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 53/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6230 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6223 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 54/100\n",
      "32843/32843 [==============================] - 2s 48us/step - loss: 0.6238 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6224 - val_acc: 0.6726 - val_f1_score: 0.6726\n",
      "Epoch 55/100\n",
      "32843/32843 [==============================] - 2s 51us/step - loss: 0.6233 - acc: 0.6677 - f1_score: 0.6677 - val_loss: 0.6222 - val_acc: 0.6722 - val_f1_score: 0.6722\n",
      "Epoch 56/100\n",
      "32843/32843 [==============================] - 1s 46us/step - loss: 0.6229 - acc: 0.6688 - f1_score: 0.6688 - val_loss: 0.6225 - val_acc: 0.6727 - val_f1_score: 0.6727\n",
      "Epoch 57/100\n",
      "32843/32843 [==============================] - 2s 50us/step - loss: 0.6234 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6225 - val_acc: 0.6727 - val_f1_score: 0.6727\n",
      "Epoch 58/100\n",
      "32843/32843 [==============================] - 2s 53us/step - loss: 0.6231 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6223 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 59/100\n",
      "32843/32843 [==============================] - 2s 57us/step - loss: 0.6233 - acc: 0.6678 - f1_score: 0.6678 - val_loss: 0.6222 - val_acc: 0.6716 - val_f1_score: 0.6716\n",
      "Epoch 60/100\n",
      "32843/32843 [==============================] - 2s 66us/step - loss: 0.6230 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.6217 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 61/100\n",
      "32843/32843 [==============================] - 2s 70us/step - loss: 0.6232 - acc: 0.6693 - f1_score: 0.6693 - val_loss: 0.6222 - val_acc: 0.6714 - val_f1_score: 0.6714\n",
      "Epoch 62/100\n",
      "32843/32843 [==============================] - 2s 64us/step - loss: 0.6232 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6217 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 63/100\n",
      "32843/32843 [==============================] - 2s 46us/step - loss: 0.6236 - acc: 0.6690 - f1_score: 0.6690 - val_loss: 0.6317 - val_acc: 0.6742 - val_f1_score: 0.6742\n",
      "Epoch 64/100\n",
      "32843/32843 [==============================] - 2s 57us/step - loss: 0.6232 - acc: 0.6684 - f1_score: 0.6684 - val_loss: 0.6220 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 65/100\n",
      "32843/32843 [==============================] - 2s 51us/step - loss: 0.6228 - acc: 0.6684 - f1_score: 0.6684 - val_loss: 0.6222 - val_acc: 0.6736 - val_f1_score: 0.6736\n",
      "Epoch 66/100\n",
      "32843/32843 [==============================] - 2s 47us/step - loss: 0.6235 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6212 - val_acc: 0.6731 - val_f1_score: 0.6731\n",
      "Epoch 67/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6231 - acc: 0.6683 - f1_score: 0.6683 - val_loss: 0.6219 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 68/100\n",
      "32843/32843 [==============================] - 2s 50us/step - loss: 0.6225 - acc: 0.6694 - f1_score: 0.6694 - val_loss: 0.6218 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 69/100\n",
      "32843/32843 [==============================] - 2s 51us/step - loss: 0.6233 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6215 - val_acc: 0.6718 - val_f1_score: 0.6718\n",
      "Epoch 70/100\n",
      "32843/32843 [==============================] - 2s 58us/step - loss: 0.6232 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6213 - val_acc: 0.6726 - val_f1_score: 0.6726\n",
      "Epoch 71/100\n",
      "32843/32843 [==============================] - 2s 64us/step - loss: 0.6227 - acc: 0.6678 - f1_score: 0.6678 - val_loss: 0.6216 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 72/100\n",
      "32843/32843 [==============================] - 2s 54us/step - loss: 0.6228 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6219 - val_acc: 0.6729 - val_f1_score: 0.6729\n",
      "Epoch 73/100\n",
      "32843/32843 [==============================] - 2s 49us/step - loss: 0.6226 - acc: 0.6692 - f1_score: 0.6692 - val_loss: 0.6228 - val_acc: 0.6700 - val_f1_score: 0.6700\n",
      "Epoch 74/100\n",
      "32843/32843 [==============================] - 2s 46us/step - loss: 0.6228 - acc: 0.6693 - f1_score: 0.6693 - val_loss: 0.6237 - val_acc: 0.6720 - val_f1_score: 0.6720\n",
      "Epoch 75/100\n",
      "32843/32843 [==============================] - 2s 49us/step - loss: 0.6223 - acc: 0.6696 - f1_score: 0.6696 - val_loss: 0.6262 - val_acc: 0.6719 - val_f1_score: 0.6719\n",
      "Epoch 76/100\n",
      "32843/32843 [==============================] - 2s 50us/step - loss: 0.6230 - acc: 0.6689 - f1_score: 0.6689 - val_loss: 0.6210 - val_acc: 0.6736 - val_f1_score: 0.6736\n",
      "Epoch 77/100\n",
      "32843/32843 [==============================] - 2s 50us/step - loss: 0.6224 - acc: 0.6690 - f1_score: 0.6690 - val_loss: 0.6215 - val_acc: 0.6718 - val_f1_score: 0.6718\n",
      "Epoch 78/100\n",
      "32843/32843 [==============================] - 1s 44us/step - loss: 0.6227 - acc: 0.6688 - f1_score: 0.6688 - val_loss: 0.6214 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 79/100\n",
      "32843/32843 [==============================] - 2s 50us/step - loss: 0.6226 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6217 - val_acc: 0.6712 - val_f1_score: 0.6712\n",
      "Epoch 80/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6232 - acc: 0.6691 - f1_score: 0.6691 - val_loss: 0.6210 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 81/100\n",
      "32843/32843 [==============================] - 2s 46us/step - loss: 0.6224 - acc: 0.6683 - f1_score: 0.6683 - val_loss: 0.6214 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 82/100\n",
      "32843/32843 [==============================] - 2s 58us/step - loss: 0.6224 - acc: 0.6699 - f1_score: 0.6699 - val_loss: 0.6224 - val_acc: 0.6728 - val_f1_score: 0.6728\n",
      "Epoch 83/100\n",
      "32843/32843 [==============================] - 2s 61us/step - loss: 0.6224 - acc: 0.6693 - f1_score: 0.6693 - val_loss: 0.6221 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 84/100\n",
      "32843/32843 [==============================] - 1s 39us/step - loss: 0.6223 - acc: 0.6694 - f1_score: 0.6694 - val_loss: 0.6211 - val_acc: 0.6731 - val_f1_score: 0.6731\n",
      "Epoch 85/100\n",
      "32843/32843 [==============================] - 1s 38us/step - loss: 0.6227 - acc: 0.6676 - f1_score: 0.6676 - val_loss: 0.6218 - val_acc: 0.6740 - val_f1_score: 0.6740\n",
      "Epoch 86/100\n",
      "32843/32843 [==============================] - 1s 39us/step - loss: 0.6228 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6217 - val_acc: 0.6726 - val_f1_score: 0.6726\n",
      "Epoch 87/100\n",
      "32843/32843 [==============================] - 1s 41us/step - loss: 0.6226 - acc: 0.6681 - f1_score: 0.6681 - val_loss: 0.6216 - val_acc: 0.6734 - val_f1_score: 0.6734\n",
      "Epoch 88/100\n",
      "32843/32843 [==============================] - 2s 51us/step - loss: 0.6229 - acc: 0.6685 - f1_score: 0.6685 - val_loss: 0.6234 - val_acc: 0.6736 - val_f1_score: 0.6736\n",
      "Epoch 89/100\n",
      "32843/32843 [==============================] - 1s 43us/step - loss: 0.6225 - acc: 0.6694 - f1_score: 0.6694 - val_loss: 0.6215 - val_acc: 0.6726 - val_f1_score: 0.6726\n",
      "Epoch 90/100\n",
      "32843/32843 [==============================] - 1s 40us/step - loss: 0.6225 - acc: 0.6678 - f1_score: 0.6678 - val_loss: 0.6210 - val_acc: 0.6731 - val_f1_score: 0.6731\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32843/32843 [==============================] - 1s 39us/step - loss: 0.6229 - acc: 0.6684 - f1_score: 0.6684 - val_loss: 0.6207 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 92/100\n",
      "32843/32843 [==============================] - 1s 37us/step - loss: 0.6223 - acc: 0.6695 - f1_score: 0.6695 - val_loss: 0.6222 - val_acc: 0.6716 - val_f1_score: 0.6716\n",
      "Epoch 93/100\n",
      "32843/32843 [==============================] - 1s 39us/step - loss: 0.6224 - acc: 0.6686 - f1_score: 0.6686 - val_loss: 0.6215 - val_acc: 0.6718 - val_f1_score: 0.6718\n",
      "Epoch 94/100\n",
      "32843/32843 [==============================] - 1s 42us/step - loss: 0.6223 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.6226 - val_acc: 0.6724 - val_f1_score: 0.6724\n",
      "Epoch 95/100\n",
      "32843/32843 [==============================] - 1s 38us/step - loss: 0.6230 - acc: 0.6678 - f1_score: 0.6678 - val_loss: 0.6208 - val_acc: 0.6729 - val_f1_score: 0.6729\n",
      "Epoch 96/100\n",
      "32843/32843 [==============================] - 1s 37us/step - loss: 0.6221 - acc: 0.6689 - f1_score: 0.6689 - val_loss: 0.6207 - val_acc: 0.6733 - val_f1_score: 0.6733\n",
      "Epoch 97/100\n",
      "32843/32843 [==============================] - 1s 35us/step - loss: 0.6223 - acc: 0.6702 - f1_score: 0.6702 - val_loss: 0.6215 - val_acc: 0.6725 - val_f1_score: 0.6725\n",
      "Epoch 98/100\n",
      "32843/32843 [==============================] - 1s 40us/step - loss: 0.6225 - acc: 0.6689 - f1_score: 0.6689 - val_loss: 0.6227 - val_acc: 0.6726 - val_f1_score: 0.6726\n",
      "Epoch 99/100\n",
      "32843/32843 [==============================] - 1s 45us/step - loss: 0.6223 - acc: 0.6697 - f1_score: 0.6697 - val_loss: 0.6219 - val_acc: 0.6710 - val_f1_score: 0.6710\n",
      "Epoch 100/100\n",
      "32843/32843 [==============================] - 2s 53us/step - loss: 0.6220 - acc: 0.6692 - f1_score: 0.6692 - val_loss: 0.6231 - val_acc: 0.6709 - val_f1_score: 0.6709\n",
      "21 scans will take roughly 3192 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(32, input_shape=(None, 32))`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32843 samples, validate on 14076 samples\n",
      "Epoch 1/100\n",
      "32843/32843 [==============================] - 3s 104us/step - loss: 0.1061 - acc: 0.6653 - f1_score: 0.6653 - val_loss: 0.1031 - val_acc: 0.6735 - val_f1_score: 0.6735\n",
      "Epoch 2/100\n",
      "32843/32843 [==============================] - 3s 77us/step - loss: 0.1044 - acc: 0.6682 - f1_score: 0.6682 - val_loss: 0.1038 - val_acc: 0.6720 - val_f1_score: 0.6720\n",
      "Epoch 3/100\n",
      "32843/32843 [==============================] - 3s 81us/step - loss: 0.1040 - acc: 0.6687 - f1_score: 0.6687 - val_loss: 0.1036 - val_acc: 0.6699 - val_f1_score: 0.6699\n",
      "Epoch 4/100\n",
      "32512/32843 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.6678 - f1_score: 0.6678"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ed6b86bb5b53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m                \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model_SimpleRNN_non_GPU_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;31m# create_model_SimpleRNN_non_GPU_test(x_train, y_train, x_val, y_val, params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                grid_downsample=.01)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperio/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, params, dataset_name, experiment_no, model, val_split, shuffle, search_method, reduction_method, reduction_interval, reduction_window, grid_downsample, hyperio_log_name, debug)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_log\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_null\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyper_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# get the results ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperio/main.py\u001b[0m in \u001b[0;36m_hyper_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_round_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# this creates the params round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0m_hr_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0m_hr_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_round_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_hr_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_write_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperio/main.py\u001b[0m in \u001b[0;36m_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                           self.params)\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_val_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7792b545f044>\u001b[0m in \u001b[0;36mcreate_model_SimpleRNN_non_GPU_test\u001b[0;34m(x_train, y_train, x_val, y_val, params)\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                     validation_data=[x_val, y_val])\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;31m#                     callbacks=early_stopper(params['epochs'], mode='strict'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.activations import softmax\n",
    "from keras.losses import categorical_crossentropy, logcosh\n",
    "\n",
    "pickle_load_dir_path = \"./dataset_pickle_tuple_type/\"\n",
    "X = {}\n",
    "y = {}\n",
    "\n",
    "\n",
    "MODEL = [\"SimpleRNN\"]\n",
    "idx_time_unit = 10     # candle stick minutes\n",
    "idx_window_size = 25  # Unit: num. of candle sticks\n",
    "idx_gap = 1            # Unit: num. of candle sticks\n",
    "idx_margix_rate = 0.1  # Unit: percent\n",
    "\n",
    "key_name_X = \"X_\"\n",
    "key_name_y = \"y_\"\n",
    "\n",
    "\n",
    "key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "\n",
    "X = Load_Dataset_X(pickle_load_dir_path, idx_time_unit, idx_window_size, idx_gap, idx_margix_rate)\n",
    "y = Load_Dataset_y(pickle_load_dir_path, idx_time_unit, idx_window_size, idx_gap, idx_margix_rate)\n",
    "\n",
    "y_single = {}\n",
    "y_single['BTC'] = y[:, 1]\n",
    "y_single['ETH'] = y[:, 2]\n",
    "y_single['XRP'] = y[:, 3]\n",
    "y_single['BCH'] = y[:, 4]\n",
    "y_single['LTC'] = y[:, 5]\n",
    "y_single['DASH'] = y[:, 6]\n",
    "y_single['ETC'] = y[:, 7]\n",
    "\n",
    "coin_list2 = [\"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "\n",
    "y2 = onehottify(y_single['BTC'], n=2) \n",
    "#                         for coin in coin_list2:\n",
    "#                             print(\"y_single[\"+coin+\"]\"+\".shape\")\n",
    "#                             print(y_single[coin].shape)\n",
    "#                             print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.1, random_state=42)\n",
    "#     print(\"X_train.shape\")\n",
    "#     print(X_train.shape)\n",
    "#     print(\"y_train.shape\")\n",
    "#     print(y_train.shape)\n",
    "#     print()\n",
    "#     print(\"X_test.shape\")\n",
    "#     print(X_test.shape)\n",
    "#     print(\"y_test.shape\")\n",
    "#     print(y_test.shape)\n",
    "#     print()\n",
    "\n",
    "n_coins = 8\n",
    "n_price = 4\n",
    "n_steps = idx_window_size # 원래 100이었음. reshape 문제 때문에 수정함\n",
    "\n",
    "X_train_2 = X_train.transpose([0, 2, 1, 3])\n",
    "X_test_2 = X_test.transpose([0, 2, 1, 3])\n",
    "#     print(\"X_train_2.shape\")\n",
    "#     print(X_train_2.shape)\n",
    "#     print(\"X_test_2.shape\")\n",
    "#     print(X_test_2.shape)\n",
    "#     print()\n",
    "\n",
    "X_train_3 = X_train_2.reshape([X_train.shape[0], n_steps, n_coins * n_price])\n",
    "X_test_3 = X_test_2.reshape([X_test.shape[0], n_steps, n_coins * n_price])\n",
    "#     print(\"X_train_3.shape\")\n",
    "#     print(X_train_3.shape)\n",
    "#     print(\"X_test_3.shape\")\n",
    "#     print(X_test_3.shape)\n",
    "#     print()\n",
    "\n",
    "X_train_reshape = X_train_2.reshape([X_train.shape[0], n_steps*n_coins * n_price])\n",
    "X_test_reshape = X_test_2.reshape([X_test.shape[0], n_steps*n_coins * n_price])\n",
    "#     print(\"X_train_reshape.shape\")\n",
    "#     print(X_train_reshape.shape)\n",
    "#     print(\"X_test_reshape.shape\")\n",
    "#     print(X_test_reshape.shape)\n",
    "#     print()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train_reshape)\n",
    "X_train_scaled = scaler.transform(X_train_reshape)\n",
    "X_test_scaled = scaler.transform(X_test_reshape)\n",
    "\n",
    "X_train_scaled = X_train_scaled.reshape(-1, n_steps, n_coins * n_price)\n",
    "\n",
    "X_test_scaled = X_test_scaled.reshape(-1, n_steps, n_coins * n_price)\n",
    "\n",
    "X_train_scaled, X_test_scaled = input_reshape(X_train_scaled, X_test_scaled, n_steps, n_coins, n_price)\n",
    "\n",
    "                        \n",
    "p = {'lr': (0.1, 0.01, 0.001),\n",
    "     'first_neuron':[4, 8, 16, 32, 64, 128],\n",
    "     'batch_size': [64,128,256],\n",
    "     'epochs': [100],\n",
    "     'activation':['relu'],\n",
    "     'dropout': (0, 0.40, 10),\n",
    "     'optimizer': [Adam, Nadam],\n",
    "     'kernel_initializer':['glorot_uniform', 'uniform', 'he_uniform'],\n",
    "     'recurrent_initializer':['orthogonal'], \n",
    "     'bias_initializer':['zeros'],\n",
    "     'loss': ['categorical_crossentropy', 'logcosh'],\n",
    "     'last_activation': ['softmax'],\n",
    "     'weight_regulizer':[None],\n",
    "     'emb_output_dims': [None]}\n",
    "\n",
    "import hyperio as hy\n",
    "h = hy.Hyperio(X_train_scaled, y_train, \n",
    "               params=p, \n",
    "               dataset_name='coin', \n",
    "               experiment_no='1', \n",
    "               model=create_model_SimpleRNN_non_GPU_test,\n",
    "               # create_model_SimpleRNN_non_GPU_test(x_train, y_train, x_val, y_val, params)\n",
    "               grid_downsample=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
