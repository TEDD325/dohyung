{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "from pyspark.sql.functions import lit,unix_timestamp\n",
    "from pyspark import SQLContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load .csv file from Local**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = sc.textFile(\"trade_20171214_20171215.csv\").persist()\n",
    "# #tmp = spark.read.csv(\n",
    "# #     \"trade_20171214_20171215.csv\", header=True\n",
    "# # ).persist()\n",
    "\n",
    "# type(df)\n",
    "# output[]: pyspark.rdd.RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pyspark.sql.dataframe.DataFrame형태로 load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.csv(\"trade_20171214_20171215.csv\", header=True)\n",
    "#df\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- exchange_rate: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- price2: string (nullable = true)\n",
      " |-- amount: string (nullable = true)\n",
      " |-- total: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- exchange: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- trade_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.take(1)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**from MySql**    \n",
    "    \n",
    "    [Row(id=1, date=datetime.datetime(2017, 12, 14, 1, 19, 58), exchange_rate=1.0, price=18468000.0, price2=18468000.0, amount=0.0144, \n",
    "    total=265939.0, type='buy', exchange='bithumb', count=1, trade_id='ed2dc46f02629d03d98c411a64858b3a37a1b0a42349529c27fe9416')\n",
    "    \n",
    "    root\n",
    "     |-- id: integer (nullable = false)\n",
    "     |-- date: timestamp (nullable = false)\n",
    "     |-- exchange_rate: double (nullable = false)\n",
    "     |-- price: double (nullable = false)\n",
    "     |-- price2: double (nullable = false)\n",
    "     |-- amount: double (nullable = false)\n",
    "     |-- total: double (nullable = false)\n",
    "     |-- type: string (nullable = false)\n",
    "     |-- exchange: string (nullable = false)\n",
    "     |-- count: integer (nullable = false)\n",
    "     |-- trade_id: string (nullable = true)\n",
    "    \n",
    "**from HDFS**\n",
    "\n",
    "    [Row(id='1', date='2017.12.14 1:19', exchange_rate='1', price='18468000', price2='18468000', amount='0.0144', \n",
    "    total='265939', type='buy', exchange='bithumb', count='1', trade_id='ed2dc46f02629d03d98c411a64858b3a37a1b0a42349529c27fe9416')]\n",
    "    \n",
    "    root\n",
    "     |-- id: string (nullable = true)\n",
    "     |-- date: string (nullable = true)\n",
    "     |-- exchange_rate: string (nullable = true)\n",
    "     |-- price: string (nullable = true)\n",
    "     |-- price2: string (nullable = true)\n",
    "     |-- amount: string (nullable = true)\n",
    "     |-- total: string (nullable = true)\n",
    "     |-- type: string (nullable = true)\n",
    "     |-- exchange: string (nullable = true)\n",
    "     |-- count: string (nullable = true)\n",
    "     |-- trade_id: string (nullable = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the type appropriately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- exchange_rate: double (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- price2: double (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- total: double (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- exchange: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- trade_id: string (nullable = true)\n",
      "\n",
      "+---+-------------------+-------------+--------+--------+------+---------+----+--------+-----+--------------------+\n",
      "| id|               date|exchange_rate|   price|  price2|amount|    total|type|exchange|count|            trade_id|\n",
      "+---+-------------------+-------------+--------+--------+------+---------+----+--------+-----+--------------------+\n",
      "|  1|0017-12-14 01:19:00|          1.0|1.8468E7|1.8468E7|   0.0| 265939.0| buy| bithumb|    1|ed2dc46f02629d03d...|\n",
      "|  2|0017-12-14 01:19:00|          1.0|1.8477E7|1.8477E7|   0.0| 822227.0| buy| bithumb|    1|08a225db9a33d7b96...|\n",
      "|  3|0017-12-14 01:20:00|          1.0|1.8477E7|1.8477E7|   0.2|3067180.0| buy| bithumb|    1|257257e970e9a6f96...|\n",
      "|  4|0017-12-14 01:20:00|          1.0|1.8492E7|1.8492E7|   0.0|  55476.0|sell| bithumb|    1|e00932da7ef83226e...|\n",
      "|  5|0017-12-14 01:20:00|          1.0|1.8491E7|1.8491E7|   0.0| 229288.0|sell| bithumb|    1|c74910b20f237b8ab...|\n",
      "|  6|0017-12-14 01:20:00|          1.0|1.8491E7|1.8491E7|   0.1| 924550.0|sell| bithumb|    1|dbf7bb708ca5cfd4d...|\n",
      "|  7|0017-12-14 01:20:00|          1.0|1.8491E7|1.8491E7|   0.1|2544360.0|sell| bithumb|    1|a9d8e087f5e6cf925...|\n",
      "|  8|0017-12-14 01:20:00|          1.0|1.8492E7|1.8492E7|   0.1|2453300.0|sell| bithumb|    1|f6f0dd3c7eef6ad12...|\n",
      "|  9|0017-12-14 01:20:00|          1.0|1.8492E7|1.8492E7|   0.0| 554760.0|sell| bithumb|    1|2c2ef34c2048ae9e6...|\n",
      "| 10|0017-12-14 01:20:00|          1.0|1.8492E7|1.8492E7|   0.1|1849200.0|sell| bithumb|    1|56a0e1779c29d30bd...|\n",
      "| 11|0017-12-14 01:20:00|          1.0|1.8478E7|1.8478E7|   0.0| 164454.0| buy| bithumb|    1|6ab5155b89843ac07...|\n",
      "| 12|0017-12-14 01:20:00|          1.0|1.8478E7|1.8478E7|   0.1|2586920.0| buy| bithumb|    1|74e8ed44df66b894a...|\n",
      "| 13|0017-12-14 01:20:00|          1.0|1.8478E7|1.8478E7|   0.0| 356625.0| buy| bithumb|    1|9635f4ce3a256b477...|\n",
      "| 14|0017-12-14 01:20:00|          1.0|1.8491E7|1.8491E7|   0.0| 582467.0|sell| bithumb|    1|b5c147faa6f11747a...|\n",
      "| 15|0017-12-14 01:20:00|          1.0|1.8491E7|1.8491E7|   0.0|  99851.0|sell| bithumb|    1|0bc16f6dac50ca972...|\n",
      "| 16|0017-12-14 01:20:00|          1.0|1.8478E7|1.8478E7|   0.0| 587600.0| buy| bithumb|    1|65409d637251f23bc...|\n",
      "| 17|0017-12-14 01:20:00|          1.0|1.8478E7|1.8478E7|   0.0| 236518.0| buy| bithumb|    1|b62daf846a198e53e...|\n",
      "| 18|0017-12-14 01:20:00|          1.0|1.8491E7|1.8491E7|   0.0| 199703.0|sell| bithumb|    1|ebdaac4f2f40ff734...|\n",
      "| 19|0017-12-14 01:20:00|          1.0|1.8491E7|1.8491E7|   0.0| 199703.0|sell| bithumb|    2|ebdaac4f2f40ff734...|\n",
      "| 20|0017-12-14 01:20:00|          1.0|1.8491E7|1.8491E7|   0.0|  88794.0|sell| bithumb|    1|8fb946c0ce6f17351...|\n",
      "+---+-------------------+-------------+--------+--------+------+---------+----+--------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.csv(\"trade_20171214_20171215.csv\", header=True, nullValue=nullValueList)\n",
    "#df\n",
    "type(df)\n",
    "output_df = df.withColumn(\"id\",df[\"id\"].cast('int'))\n",
    "output_df = output_df.withColumn('date',unix_timestamp(df['date'],'yyyy-MM-dd HH:mm').cast(\"timestamp\"))\n",
    "# output_df = output_df.withColumn(\"date\",df[\"date\"].cast('timestamp'))\n",
    "output_df = output_df.withColumn(\"exchange_rate\",df[\"exchange_rate\"].cast('double'))\n",
    "output_df = output_df.withColumn(\"price\",df[\"price\"].cast('double'))\n",
    "output_df = output_df.withColumn(\"price2\",df[\"price2\"].cast('double'))\n",
    "output_df = output_df.withColumn(\"amount\",df[\"amount\"].cast('double'))\n",
    "output_df = output_df.withColumn(\"total\",df[\"total\"].cast('double'))\n",
    "output_df = output_df.withColumn(\"type\",df[\"type\"].cast('string'))\n",
    "output_df = output_df.withColumn(\"exchange\",df[\"exchange\"].cast('string'))\n",
    "output_df = output_df.withColumn(\"count\",df[\"count\"].cast('int'))\n",
    "output_df = output_df.withColumn(\"trade_id\",df[\"trade_id\"].cast('string'))\n",
    "output_df.printSchema()\n",
    "# https://stackoverflow.com/questions/45453294/change-the-datatype-of-columns-in-pyspark-dataframe\n",
    "output_df.take(1)\n",
    "output_df.show(truncate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**define class which is Pre-precessing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing_Trading_Data():\n",
    "    def __init__(self, df, start_time, end_time, time_interval, exchange):\n",
    "        self.start_time = start_time #'2017-12-14 01:20:00'\n",
    "        self.end_time = end_time #'2017-12-14 01:20:20'\n",
    "        self.date_time = start_time\n",
    "        self.date_time_list = []\n",
    "        self.date_time_list.append(self.date_time)\n",
    "        self.time_interval = time_interval\n",
    "        self.exchange = exchange\n",
    "        self.df = df\n",
    "        \n",
    "    def is_finished(self):\n",
    "        current_time = datetime.datetime.strptime(self.date_time, '%Y-%m-%d %H:%M:%S')\n",
    "        end_time = datetime.datetime.strptime(self.end_time, '%Y-%m-%d %H:%M:%S')\n",
    "        if current_time >= end_time:\n",
    "            return True\n",
    "    #- datetime.timedelta(minutes = 1)\n",
    "    def change_datetime(self, date_time, time_interval):\n",
    "        date_time = datetime.datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S')\n",
    "        changed_datetime = date_time + datetime.timedelta(minutes = time_interval)\n",
    "        self.date_time = changed_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        self.date_time_list.append(self.date_time)\n",
    "        return changed_datetime\n",
    "    \n",
    "    def df_divided_by_time_interval(self, date_time, time_interval):\n",
    "        df_divided = self.df.filter(df.date.between(datetime.datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S'), self.change_datetime(date_time, time_interval)))\n",
    "        return df_divided\n",
    "    \n",
    "    def get_prices_from_df_divided(self, is_fisrt = False):\n",
    "        df = self.df_divided_by_time_interval(self.date_time, self.time_interval)\n",
    "        df = df.filter(df.exchange == self.exchange)\n",
    "        df_open = df.filter(df.id == df.first().id).rdd.map(lambda x: x.price)\n",
    "        df_max = df.filter(df.id == df.orderBy('price', ascending=False).first().id).rdd.map(lambda x: x.price)\n",
    "        df_min = df.filter(df.id == df.orderBy('price', ascending=True).first().id).rdd.map(lambda x: x.price)\n",
    "        df_close = df.filter(df.id == df.orderBy('id', ascending=False).first().id).rdd.map(lambda x: x.price)\n",
    "        \n",
    "        df_union = df_open.union(df_max).union(df_min).union(df_close)\n",
    "        return df_union\n",
    "    \n",
    "    def get_date_time_list(self):\n",
    "        return self.date_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**main function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbtable_arg =\"TRADE_BTC\"\n",
    "start_time_arg =  '2017-12-14 02:00:00'\n",
    "end_time_arg =  '2017-12-15 00:00:00'\n",
    "exchange_arg =  'bithumb'\n",
    "time_interval_arg = 1\n",
    "Spark_app_name = dbtable_arg + '|' + start_time_arg + '|' + end_time_arg + '|'  + exchange_arg + '|' + str(time_interval_arg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-f28a7d906454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdate_time_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_date_time_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prices_from_df_divided\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-58651337f66a>\u001b[0m in \u001b[0;36mget_prices_from_df_divided\u001b[0;34m(self, is_fisrt)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_divided_by_time_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexchange\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mdf_open\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mdf_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdf_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    df = output_df\n",
    "    start_time = start_time_arg\n",
    "    end_time = end_time_arg\n",
    "    time_interval = time_interval_arg\n",
    "    exchange = exchange_arg\n",
    "    result = []\n",
    "    data = {}\n",
    "    data['open'] = []\n",
    "    data['high'] =  []\n",
    "    data['low'] =  []\n",
    "    data['close'] =  []\n",
    "\n",
    "    \n",
    "    pickle_file_name = dbtable_arg + '|' + start_time_arg + '|' + end_time_arg + '|'  +exchange_arg + '|' + str(time_interval_arg) + '.pickle'\n",
    "    \n",
    "    # file의 존재 유무 확인\n",
    "    # 중복 수행 방지\n",
    "    if (os.getcwd() +  '/' +  pickle_file_name in glob.glob(os.getcwd()+\"/*.pickle\")):\n",
    "        print(\"[WARNING] The file Already exist.\")\n",
    "    else:\n",
    "        trading = Preprocessing_Trading_Data(df, start_time, end_time, time_interval, exchange)\n",
    "        date_time_list = trading.get_date_time_list()\n",
    "        while not(trading.is_finished()):\n",
    "            data_list = trading.get_prices_from_df_divided()\n",
    "            result.append(list(data_list.collect()))\n",
    "            \n",
    "        print(end='\\n\\n\\n\\n\\n')    \n",
    "        print(\"[WARNING] Following result are not same the content of pickle file.\")\n",
    "        print('------------------------------------------------------------------------------')\n",
    "        print(result)\n",
    "        date_time_list = date_time_list[:-1]\n",
    "        print(date_time_list)\n",
    "        print(len(result))\n",
    "        print(len(date_time_list))\n",
    "        print('------------------------------------------------------------------------------')\n",
    "        print(\"generating pickle file....\",end=\"\\n\\n\")\n",
    "        \n",
    "\n",
    "        data['meta'] = [dbtable_arg, start_time_arg, end_time_arg, exchange_arg, time_interval_arg]\n",
    "        data['date'] = date_time_list\n",
    "        for row in result:\n",
    "            data['open'].append(row[0])\n",
    "            data['high'].append(row[1])\n",
    "            data['low'].append(row[2])\n",
    "            data['close'].append(row[3])\n",
    "#         data['price'] = result\n",
    "    \n",
    "    \n",
    "        f = open(pickle_file_name, 'wb')\n",
    "        pickle.dump(data, f)\n",
    "        f.close()\n",
    "        print(\"finished. pickle file is saved at {:s}/\".format(os.getcwd()))\n",
    "        \n",
    "        \n",
    "    # f = open(pickle_file_name, 'rb')\n",
    "    # a = pickle.load(f)\n",
    "    # print(a)\n",
    "    print(end='\\n\\n\\n\\n\\n')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18468000.0]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_open = output_df.filter(output_df.id == output_df.first().id).rdd.map(lambda x: x.price)\n",
    "df_open.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_datetime(date_time, time_interval):\n",
    "        date_time = datetime.datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S')\n",
    "        changed_datetime = date_time + datetime.timedelta(minutes = time_interval)\n",
    "        date_time = changed_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        date_time_list.append(date_time)\n",
    "        return changed_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_divided_by_time_interval(date_time, time_interval):\n",
    "    df_divided = output_df.filter(output_df.date.between(datetime.datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S'), \\\n",
    "                                           change_datetime(date_time, time_interval)))\n",
    "    return df_divided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, date: timestamp, exchange_rate: double, price: double, price2: double, amount: double, total: double, type: string, exchange: string, count: int, trade_id: string]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_time = '2017-12-14 01:19:58'\n",
    "time_interval = 1\n",
    "df_1 = df_divided_by_time_interval(date_time, time_interval)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://goo.gl/6EGe5V\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 12, 14, 1, 20, 58)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_time = '2017-12-14 01:19:58'\n",
    "time_interval = 1\n",
    "change_datetime(date_time, time_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 12, 14, 1, 19, 58)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b\"((date >= TIMESTAMP('2017-12-14 01:19:58.0')) AND (date <= TIMESTAMP('2017-12-14 01:20:58.0')))\">"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.date.between(datetime.datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S'), \\\n",
    "                                           change_datetime(date_time, time_interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
