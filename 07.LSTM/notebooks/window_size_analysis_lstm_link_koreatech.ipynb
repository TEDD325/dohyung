{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/link/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version: 2.2.2 backend: tensorflow\n"
     ]
    }
   ],
   "source": [
    "from userFunction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {}\n",
    "model_info[\"test\"] = {\"MODEL_list\":[\"LSTM\"],\n",
    "                     \"time_unit\":[10], \n",
    "                     \"window_size\":[10], # static value 50\n",
    "                     \"gap\":[1], \n",
    "                     \"margin_rate\":[0.1]}\n",
    "\n",
    "model_info[\"window_size_standard\"] = {\"MODEL_list\":[\"LSTM\"],\n",
    "                                      \"time_unit\":[10], \n",
    "                                      \"window_size\":[10, 50, 75, 100],\n",
    "                                      \"gap\":[1], \n",
    "                                      \"margin_rate\":[0.1],\n",
    "                                      \"lr\":[0.01, 0.001]}\n",
    "Machine = \"window_size_standard\"\n",
    "# If Machine is \"test\" then, _TEST argument must be True\n",
    "test = False\n",
    "_GPU = False\n",
    "n_jobs = 1\n",
    "epochs = 300\n",
    "cv = 5 # at least 2\n",
    "dataset_scale = -1\n",
    "test_list = []\n",
    "coin_list = [\"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "search_param = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_train.shape : (47294, 8, 10, 4)\n",
      "[INFO] y_train.shape : (47294, 2)\n",
      "[INFO] X_test.shape : (5255, 8, 10, 4)\n",
      "[INFO] y_test.shape : (5255, 2)\n",
      "\n",
      "[INFO] X_train_2.shape: (47294, 10, 8, 4)\n",
      "[INFO] X_test_2.shape: (5255, 10, 8, 4)\n",
      "\n",
      "[INFO] X_train_3.shape: (47294, 10, 32)\n",
      "[INFO] X_test_3.shape: (5255, 10, 32)\n",
      "\n",
      "[INFO] X_train_reshape.shape: (47294, 320)\n",
      "[INFO] X_test_reshape.shape: (5255, 320)\n",
      "\n",
      "\n",
      "\n",
      "----------------------\n",
      "<LSTM>\n",
      "----------------------\n",
      "__BTC__time unit: 10  |  window_size :10  |  gap :1  |  margin_rate :0.1  started.\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 161us/step - loss: 0.6435 - _f1_score: 0.6715 - acc: 0.6715 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 123us/step - loss: 0.6316 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 123us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 123us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 35us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid, score=0.6717411981776824, total=  21.8s\n",
      "[CV] window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 147us/step - loss: 0.6444 - _f1_score: 0.6663 - acc: 0.6663 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid, score=0.6752299398911631, total=  21.1s\n",
      "[CV] window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   45.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 146us/step - loss: 0.6423 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6323 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6323 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid, score=0.6755470986131357, total=  21.1s\n",
      "[CV] window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 151us/step - loss: 0.6429 - _f1_score: 0.6728 - acc: 0.6728 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 36us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid, score=0.6683581822177348, total=  21.3s\n",
      "[CV] window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 6s 151us/step - loss: 0.6423 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 5s 122us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 5s 122us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 5s 123us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid, score=0.6751956036615684, total=  21.3s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 138us/step - loss: 0.6379 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu, score=0.6717411981776824, total=  19.9s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 138us/step - loss: 0.6390 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 117us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 117us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 117us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu, score=0.6752299398911631, total=  20.1s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 138us/step - loss: 0.6405 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 117us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 117us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 117us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu, score=0.6755470986131357, total=  20.0s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 138us/step - loss: 0.6390 - _f1_score: 0.6729 - acc: 0.6729 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 117us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 117us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu, score=0.6683581822177348, total=  20.1s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 138us/step - loss: 0.6411 - _f1_score: 0.6720 - acc: 0.6720 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 116us/step - loss: 0.6322 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 116us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 115us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu, score=0.6751956036615684, total=  20.0s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 138us/step - loss: 0.6456 - _f1_score: 0.6541 - acc: 0.6541 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid, score=0.6717411981776824, total=  20.0s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 137us/step - loss: 0.6462 - _f1_score: 0.6492 - acc: 0.6492 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6324 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid, score=0.6752299398911631, total=  19.9s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 137us/step - loss: 0.6376 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 117us/step - loss: 0.6323 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6323 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid, score=0.6755470986131357, total=  20.0s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 140us/step - loss: 0.6427 - _f1_score: 0.6613 - acc: 0.6613 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid, score=0.6683581822177348, total=  20.0s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 137us/step - loss: 0.6431 - _f1_score: 0.6582 - acc: 0.6582 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 116us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 116us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 116us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 36us/step\n",
      "37836/37836 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid, score=0.6751956036615684, total=  19.9s\n",
      "[CV] window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6326 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6335 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 115us/step - loss: 0.6325 - _f1_score: 0.6739 - acc: 0.6736 - val_loss: 0.6333 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6323 - _f1_score: 0.6737 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6324 - _f1_score: 0.6731 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6321 - _f1_score: 0.6742 - acc: 0.6736 - val_loss: 0.6331 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6322 - _f1_score: 0.6737 - acc: 0.6736 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 7/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6321 - _f1_score: 0.6738 - acc: 0.6736 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00007: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6717411981776824, total=  32.6s\n",
      "[CV] window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6335 - _f1_score: 0.6721 - acc: 0.6727 - val_loss: 0.6338 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6332 - _f1_score: 0.6715 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6330 - _f1_score: 0.6709 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.6711 - acc: 0.6727 - val_loss: 0.6340 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6718 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6326 - _f1_score: 0.6720 - acc: 0.6727 - val_loss: 0.6324 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00006: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6752299398911631, total=  28.2s\n",
      "[CV] window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 137us/step - loss: 0.6344 - _f1_score: 0.6659 - acc: 0.6709 - val_loss: 0.6333 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6332 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6330 - _f1_score: 0.6728 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6329 - _f1_score: 0.6723 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6755470986131357, total=  19.6s\n",
      "[CV] window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 138us/step - loss: 0.6329 - _f1_score: 0.4405 - acc: 0.6735 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6320 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6317 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6317 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6683581822177348, total=  19.6s\n",
      "[CV] window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 135us/step - loss: 0.6337 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6335 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6330 - _f1_score: 0.6728 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.6714 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6716 - acc: 0.6727 - val_loss: 0.6339 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6326 - _f1_score: 0.6718 - acc: 0.6727 - val_loss: 0.6351 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6713 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 7/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6326 - _f1_score: 0.6719 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 8/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6323 - _f1_score: 0.6724 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 9/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6325 - _f1_score: 0.6729 - acc: 0.6727 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00009: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6751956036615684, total=  41.0s\n",
      "[CV] window_size=10, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 138us/step - loss: 0.6414 - _f1_score: 0.6729 - acc: 0.6729 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 116us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu, score=0.6717411981776824, total=  20.0s\n",
      "[CV] window_size=10, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 137us/step - loss: 0.6407 - _f1_score: 0.6709 - acc: 0.6709 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 115us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 115us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 115us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu, score=0.6752299398911631, total=  19.8s\n",
      "[CV] window_size=10, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 136us/step - loss: 0.6413 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 115us/step - loss: 0.6323 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 115us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 115us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu, score=0.6755470986131357, total=  19.9s\n",
      "[CV] window_size=10, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 137us/step - loss: 0.6399 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 115us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 115us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 115us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu, score=0.6683581822177348, total=  19.8s\n",
      "[CV] window_size=10, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 138us/step - loss: 0.6410 - _f1_score: 0.6719 - acc: 0.6719 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 116us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 116us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 116us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu, score=0.6751956036615684, total=  20.0s\n",
      "[CV] window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 144us/step - loss: 0.6327 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6322 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6327 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6319 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6320 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid, score=0.6717411981776824, total=  20.7s\n",
      "[CV] window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 144us/step - loss: 0.6335 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6326 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6327 - _f1_score: 0.6735 - acc: 0.6727 - val_loss: 0.6328 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6327 - _f1_score: 0.6731 - acc: 0.6727 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6328 - _f1_score: 0.6732 - acc: 0.6727 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid, score=0.6752299398911631, total=  20.7s\n",
      "[CV] window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 145us/step - loss: 0.6337 - _f1_score: 0.6723 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6328 - _f1_score: 0.6722 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6329 - _f1_score: 0.6725 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6329 - _f1_score: 0.6712 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6326 - _f1_score: 0.6719 - acc: 0.6726 - val_loss: 0.6341 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37835/37835 [==============================] - 5s 119us/step - loss: 0.6327 - _f1_score: 0.6714 - acc: 0.6726 - val_loss: 0.6333 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 7/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6330 - _f1_score: 0.6702 - acc: 0.6726 - val_loss: 0.6330 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 8/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6329 - _f1_score: 0.6702 - acc: 0.6726 - val_loss: 0.6323 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 9/300\n",
      "37835/37835 [==============================] - 5s 119us/step - loss: 0.6327 - _f1_score: 0.6713 - acc: 0.6726 - val_loss: 0.6327 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 10/300\n",
      "37835/37835 [==============================] - 5s 119us/step - loss: 0.6328 - _f1_score: 0.6714 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00010: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid, score=0.6755470986131357, total=  48.0s\n",
      "[CV] window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 148us/step - loss: 0.6319 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6335 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6315 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6330 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6317 - _f1_score: 0.6743 - acc: 0.6744 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 119us/step - loss: 0.6315 - _f1_score: 0.6740 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 5s 119us/step - loss: 0.6317 - _f1_score: 0.6720 - acc: 0.6744 - val_loss: 0.6360 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6315 - _f1_score: 0.6733 - acc: 0.6744 - val_loss: 0.6333 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 7/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6315 - _f1_score: 0.6725 - acc: 0.6744 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 8/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6313 - _f1_score: 0.6723 - acc: 0.6744 - val_loss: 0.6325 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00008: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid, score=0.6683581822177348, total=  39.1s\n",
      "[CV] window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 6s 147us/step - loss: 0.6356 - _f1_score: 0.6713 - acc: 0.6658 - val_loss: 0.6325 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 118us/step - loss: 0.6331 - _f1_score: 0.6720 - acc: 0.6727 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 118us/step - loss: 0.6327 - _f1_score: 0.6718 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 118us/step - loss: 0.6326 - _f1_score: 0.6738 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 35us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid, score=0.6751956036615684, total=  20.6s\n",
      "[CV] window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 148us/step - loss: 0.6406 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh, score=0.6717411981776824, total=  21.2s\n",
      "[CV] window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 151us/step - loss: 0.6424 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh, score=0.6752299398911631, total=  21.3s\n",
      "[CV] window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 151us/step - loss: 0.6435 - _f1_score: 0.6705 - acc: 0.6705 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6323 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh, score=0.6755470986131357, total=  21.2s\n",
      "[CV] window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 150us/step - loss: 0.6429 - _f1_score: 0.6729 - acc: 0.6729 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6310 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh, score=0.6683581822177348, total=  21.1s\n",
      "[CV] window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 6s 152us/step - loss: 0.6437 - _f1_score: 0.6719 - acc: 0.6719 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 5s 123us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 5s 122us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 5s 122us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 35us/step\n",
      "37836/37836 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh, score=0.6751956036615684, total=  21.3s\n",
      "[CV] window_size=10, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 149us/step - loss: 0.6513 - _f1_score: 1.4961e-04 - acc: 0.3291 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6321 - _f1_score: 0.0000e+00 - acc: 0.3264 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6319 - _f1_score: 0.0000e+00 - acc: 0.3264 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6320 - _f1_score: 0.0000e+00 - acc: 0.3264 - val_loss: 0.6321 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6319 - _f1_score: 0.0000e+00 - acc: 0.3264 - val_loss: 0.6322 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 00005: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid, score=0.3282588024808106, total=  25.5s\n",
      "[CV] window_size=10, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 147us/step - loss: 0.6523 - _f1_score: 0.0000e+00 - acc: 0.3280 - val_loss: 0.6322 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6332 - _f1_score: 0.0000e+00 - acc: 0.3273 - val_loss: 0.6321 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6328 - _f1_score: 0.0000e+00 - acc: 0.3273 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6326 - _f1_score: 0.0000e+00 - acc: 0.3273 - val_loss: 0.6321 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid, score=0.32477006310198697, total=  20.7s\n",
      "[CV] window_size=10, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 147us/step - loss: 0.6715 - _f1_score: 0.6678 - acc: 0.6703 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6328 - _f1_score: 0.6712 - acc: 0.6726 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6328 - _f1_score: 0.6694 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6326 - _f1_score: 0.6692 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid, score=0.6755470986131357, total=  20.6s\n",
      "[CV] window_size=10, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 146us/step - loss: 0.6472 - _f1_score: 0.0000e+00 - acc: 0.3259 - val_loss: 0.6340 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6314 - _f1_score: 0.0000e+00 - acc: 0.3256 - val_loss: 0.6330 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6314 - _f1_score: 0.0000e+00 - acc: 0.3256 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6315 - _f1_score: 0.0000e+00 - acc: 0.3256 - val_loss: 0.6321 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid, score=0.3316418242695241, total=  20.7s\n",
      "[CV] window_size=10, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 6s 149us/step - loss: 0.6493 - _f1_score: 0.6660 - acc: 0.6702 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6328 - _f1_score: 0.6698 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6327 - _f1_score: 0.6691 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6326 - _f1_score: 0.6718 - acc: 0.6727 - val_loss: 0.6336 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid, score=0.6751956036615684, total=  20.9s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 134us/step - loss: 0.6320 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6320 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6319 - _f1_score: 0.6735 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6320 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6327 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6319 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6319 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00006: early stopping\n",
      "9459/9459 [==============================] - 0s 33us/step\n",
      "37835/37835 [==============================] - 1s 32us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid, score=0.6717411981776824, total=  27.9s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6558 - _f1_score: 0.6501 - acc: 0.6306 - val_loss: 0.6324 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6328 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6328 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6327 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid, score=0.6752299398911631, total=  19.6s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 134us/step - loss: 0.6347 - _f1_score: 0.6604 - acc: 0.6695 - val_loss: 0.6328 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6327 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6327 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid, score=0.6755470986131357, total=  19.5s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 134us/step - loss: 0.6321 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6315 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6328 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6315 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6315 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid, score=0.6683581822177348, total=  19.6s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 135us/step - loss: 0.6330 - _f1_score: 0.6667 - acc: 0.6727 - val_loss: 0.6341 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6326 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6325 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 33us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid, score=0.6751956036615684, total=  19.6s\n",
      "[CV] window_size=10, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 124us/step - loss: 0.6721 - _f1_score: 0.6653 - acc: 0.6602 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6355 - _f1_score: 0.6692 - acc: 0.6736 - val_loss: 0.6341 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 106us/step - loss: 0.6346 - _f1_score: 0.6690 - acc: 0.6736 - val_loss: 0.6322 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 106us/step - loss: 0.6338 - _f1_score: 0.6693 - acc: 0.6736 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 33us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid, score=0.6717411981776824, total=  18.1s\n",
      "[CV] window_size=10, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 124us/step - loss: 0.6471 - _f1_score: 0.6651 - acc: 0.6623 - val_loss: 0.6327 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6347 - _f1_score: 0.6689 - acc: 0.6727 - val_loss: 0.6324 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6339 - _f1_score: 0.6703 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6339 - _f1_score: 0.6690 - acc: 0.6727 - val_loss: 0.6334 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid, score=0.6752299398911631, total=  18.1s\n",
      "[CV] window_size=10, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 124us/step - loss: 0.6584 - _f1_score: 2.5172e-04 - acc: 0.3285 - val_loss: 0.6322 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 106us/step - loss: 0.6338 - _f1_score: 0.0000e+00 - acc: 0.3274 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6329 - _f1_score: 0.0000e+00 - acc: 0.3274 - val_loss: 0.6324 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6328 - _f1_score: 0.0000e+00 - acc: 0.3274 - val_loss: 0.6321 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 106us/step - loss: 0.6327 - _f1_score: 0.0000e+00 - acc: 0.3274 - val_loss: 0.6321 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 00005: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid, score=0.3244529040365898, total=  22.1s\n",
      "[CV] window_size=10, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 126us/step - loss: 0.6537 - _f1_score: 0.6670 - acc: 0.6741 - val_loss: 0.6358 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6339 - _f1_score: 0.6696 - acc: 0.6744 - val_loss: 0.6346 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6331 - _f1_score: 0.6705 - acc: 0.6744 - val_loss: 0.6327 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6325 - _f1_score: 0.6702 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid, score=0.6683581822177348, total=  18.1s\n",
      "[CV] window_size=10, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 124us/step - loss: 0.6604 - _f1_score: 3.5240e-04 - acc: 0.3276 - val_loss: 0.6341 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 105us/step - loss: 0.6362 - _f1_score: 0.0000e+00 - acc: 0.3273 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 106us/step - loss: 0.6344 - _f1_score: 0.0000e+00 - acc: 0.3273 - val_loss: 0.6321 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 105us/step - loss: 0.6340 - _f1_score: 0.0000e+00 - acc: 0.3273 - val_loss: 0.6321 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 5/300\n",
      "37836/37836 [==============================] - 4s 105us/step - loss: 0.6338 - _f1_score: 0.0000e+00 - acc: 0.3273 - val_loss: 0.6322 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 00005: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid, score=0.3248043987016946, total=  22.0s\n",
      "[CV] window_size=10, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 124us/step - loss: 0.6415 - _f1_score: 0.6724 - acc: 0.6594 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6318 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 106us/step - loss: 0.6318 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 106us/step - loss: 0.6318 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu, score=0.6717411981776824, total=  18.1s\n",
      "[CV] window_size=10, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 127us/step - loss: 0.6354 - _f1_score: 0.6728 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6325 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6324 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6326 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6324 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00005: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu, score=0.6752299398911631, total=  22.1s\n",
      "[CV] window_size=10, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 123us/step - loss: 0.6394 - _f1_score: 0.6254 - acc: 0.6650 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6327 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 104us/step - loss: 0.6326 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6328 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu, score=0.6755470986131357, total=  17.9s\n",
      "[CV] window_size=10, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 124us/step - loss: 0.6396 - _f1_score: 0.6563 - acc: 0.6625 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6314 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6315 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 105us/step - loss: 0.6313 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu, score=0.6683581822177348, total=  18.1s\n",
      "[CV] window_size=10, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 126us/step - loss: 0.6385 - _f1_score: 0.2979 - acc: 0.6609 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 105us/step - loss: 0.6327 - _f1_score: 0.4365 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 106us/step - loss: 0.6326 - _f1_score: 0.4537 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 105us/step - loss: 0.6324 - _f1_score: 0.4908 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu, score=0.6751956036615684, total=  18.1s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 147us/step - loss: 0.6412 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 121us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6717411981776824, total=  21.1s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 147us/step - loss: 0.6476 - _f1_score: 0.6468 - acc: 0.6468 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6324 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6752299398911631, total=  21.2s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 152us/step - loss: 0.6534 - _f1_score: 0.6288 - acc: 0.6288 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6324 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6755470986131357, total=  21.4s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 151us/step - loss: 0.6343 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6310 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6311 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 122us/step - loss: 0.6310 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6683581822177348, total=  21.3s\n",
      "[CV] window_size=10, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 6s 151us/step - loss: 0.6401 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 5s 121us/step - loss: 0.6322 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 5s 122us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 5s 121us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 35us/step\n",
      "37836/37836 [==============================] - 1s 34us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6751956036615684, total=  21.2s\n",
      "[CV] window_size=10, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6326 - _f1_score: 0.6734 - acc: 0.6736 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6322 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6333 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6321 - _f1_score: 0.6735 - acc: 0.6736 - val_loss: 0.6325 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6320 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6328 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh, score=0.6717411981776824, total=  19.5s\n",
      "[CV] window_size=10, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6395 - _f1_score: 5.1321e-05 - acc: 0.6641 - val_loss: 0.6352 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6336 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 0.6380 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6335 - _f1_score: 0.0426 - acc: 0.6727 - val_loss: 0.6322 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.4069 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6326 - _f1_score: 0.6256 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00005: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 32us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh, score=0.6752299398911631, total=  24.0s\n",
      "[CV] window_size=10, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6344 - _f1_score: 0.5341 - acc: 0.6704 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.6725 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh, score=0.6755470986131357, total=  19.6s\n",
      "[CV] window_size=10, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6317 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6316 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6312 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6329 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6312 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh, score=0.6683581822177348, total=  19.6s\n",
      "[CV] window_size=10, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 135us/step - loss: 0.6340 - _f1_score: 0.1776 - acc: 0.6707 - val_loss: 0.6330 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.6726 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6326 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6325 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6328 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh, score=0.6751956036615684, total=  19.6s\n",
      "[CV] window_size=10, units_2=32, units_1=128, optimizer=Adam, n_state_units=128, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 151us/step - loss: 0.6347 - _f1_score: 0.6729 - acc: 0.6678 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6319 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6321 - _f1_score: 0.6738 - acc: 0.6736 - val_loss: 0.6326 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6318 - _f1_score: 0.6737 - acc: 0.6736 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 33us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=128, optimizer=Adam, n_state_units=128, activation_2=sigmoid, activation_1=tanh, score=0.6717411981776824, total=  21.1s\n",
      "[CV] window_size=10, units_2=32, units_1=128, optimizer=Adam, n_state_units=128, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 143us/step - loss: 0.6335 - _f1_score: 0.6726 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6328 - _f1_score: 0.6725 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6326 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6325 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6326 - _f1_score: 0.6729 - acc: 0.6727 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6325 - _f1_score: 0.6729 - acc: 0.6727 - val_loss: 0.6325 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00005: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=128, optimizer=Adam, n_state_units=128, activation_2=sigmoid, activation_1=tanh, score=0.6752299398911631, total=  25.0s\n",
      "[CV] window_size=10, units_2=32, units_1=128, optimizer=Adam, n_state_units=128, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 149us/step - loss: 0.6333 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6328 - _f1_score: 0.6723 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6329 - _f1_score: 0.6720 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6327 - _f1_score: 0.6723 - acc: 0.6726 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6326 - _f1_score: 0.6720 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37835/37835 [==============================] - 5s 119us/step - loss: 0.6325 - _f1_score: 0.6723 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00006: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=128, optimizer=Adam, n_state_units=128, activation_2=sigmoid, activation_1=tanh, score=0.6755470986131357, total=  30.0s\n",
      "[CV] window_size=10, units_2=32, units_1=128, optimizer=Adam, n_state_units=128, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 149us/step - loss: 0.6347 - _f1_score: 0.6559 - acc: 0.6696 - val_loss: 0.6324 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6316 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6314 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6315 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6326 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=128, optimizer=Adam, n_state_units=128, activation_2=sigmoid, activation_1=tanh, score=0.6683581822177348, total=  20.9s\n",
      "[CV] window_size=10, units_2=32, units_1=128, optimizer=Adam, n_state_units=128, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 6s 149us/step - loss: 0.6334 - _f1_score: 0.6728 - acc: 0.6727 - val_loss: 0.6330 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6330 - _f1_score: 0.6714 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 5s 119us/step - loss: 0.6330 - _f1_score: 0.6712 - acc: 0.6727 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6326 - _f1_score: 0.6724 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37836/37836 [==============================] - 5s 119us/step - loss: 0.6327 - _f1_score: 0.6716 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6327 - _f1_score: 0.6723 - acc: 0.6727 - val_loss: 0.6330 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 00006: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=128, optimizer=Adam, n_state_units=128, activation_2=sigmoid, activation_1=tanh, score=0.6751956036615684, total=  30.0s\n",
      "[CV] window_size=10, units_2=64, units_1=128, optimizer=rmsprop, n_state_units=64, activation_2=relu, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 134us/step - loss: 0.0596 - _f1_score: 0.0000e+00 - acc: 0.6717 - val_loss: 1.1921e-07 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.0643 - _f1_score: 0.0000e+00 - acc: 0.6717 - val_loss: 1.1921e-07 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.0635 - _f1_score: 0.0000e+00 - acc: 0.6715 - val_loss: 1.1921e-07 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.0562 - _f1_score: 0.0000e+00 - acc: 0.6719 - val_loss: 1.1921e-07 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=128, optimizer=rmsprop, n_state_units=64, activation_2=relu, activation_1=tanh, score=0.6717411981776824, total=  19.5s\n",
      "[CV] window_size=10, units_2=64, units_1=128, optimizer=rmsprop, n_state_units=64, activation_2=relu, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6440 - _f1_score: 0.6644 - acc: 0.6720 - val_loss: 0.6343 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6330 - _f1_score: 0.6667 - acc: 0.6727 - val_loss: 0.6324 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.6667 - acc: 0.6727 - val_loss: 0.6322 - val__f1_score: 0.6667 - val_acc: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6667 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=128, optimizer=rmsprop, n_state_units=64, activation_2=relu, activation_1=tanh, score=0.6752299398911631, total=  19.6s\n",
      "[CV] window_size=10, units_2=64, units_1=128, optimizer=rmsprop, n_state_units=64, activation_2=relu, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 134us/step - loss: 5.2796 - _f1_score: 0.0000e+00 - acc: 0.6718 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 5.2766 - _f1_score: 0.0000e+00 - acc: 0.6726 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 5.2766 - _f1_score: 0.0000e+00 - acc: 0.6726 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 5.2766 - _f1_score: 0.0000e+00 - acc: 0.6726 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=128, optimizer=rmsprop, n_state_units=64, activation_2=relu, activation_1=tanh, score=0.6755470986131357, total=  19.5s\n",
      "[CV] window_size=10, units_2=64, units_1=128, optimizer=rmsprop, n_state_units=64, activation_2=relu, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6419 - _f1_score: 0.5971 - acc: 0.6738 - val_loss: 0.6355 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6316 - _f1_score: 0.6667 - acc: 0.6744 - val_loss: 0.6327 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6315 - _f1_score: 0.6667 - acc: 0.6744 - val_loss: 0.6323 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6314 - _f1_score: 0.6667 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=128, optimizer=rmsprop, n_state_units=64, activation_2=relu, activation_1=tanh, score=0.6683581822177348, total=  19.6s\n",
      "[CV] window_size=10, units_2=64, units_1=128, optimizer=rmsprop, n_state_units=64, activation_2=relu, activation_1=tanh \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 135us/step - loss: 5.2728 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 5.2743 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 5.2739 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 115us/step - loss: 5.2747 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=128, optimizer=rmsprop, n_state_units=64, activation_2=relu, activation_1=tanh, score=0.6751956036615684, total=  19.6s\n",
      "[CV] window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=32, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6328 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6324 - _f1_score: 0.6733 - acc: 0.6736 - val_loss: 0.6324 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6320 - _f1_score: 0.6733 - acc: 0.6736 - val_loss: 0.6324 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6322 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6322 - _f1_score: 0.6738 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00005: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=32, activation_2=sigmoid, activation_1=tanh, score=0.6717411981776824, total=  23.9s\n",
      "[CV] window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=32, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 138us/step - loss: 0.6338 - _f1_score: 0.6711 - acc: 0.6726 - val_loss: 0.6337 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6333 - _f1_score: 0.6728 - acc: 0.6727 - val_loss: 0.6351 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6328 - _f1_score: 0.6728 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.6726 - acc: 0.6727 - val_loss: 0.6347 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=32, activation_2=sigmoid, activation_1=tanh, score=0.6752299398911631, total=  19.7s\n",
      "[CV] window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=32, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6336 - _f1_score: 0.6725 - acc: 0.6726 - val_loss: 0.6344 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6332 - _f1_score: 0.6723 - acc: 0.6726 - val_loss: 0.6326 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6328 - _f1_score: 0.6729 - acc: 0.6726 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6723 - acc: 0.6726 - val_loss: 0.6337 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6718 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6727 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 7/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6725 - acc: 0.6726 - val_loss: 0.6336 - val__f1_score: 0.6667 - val_acc: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6327 - _f1_score: 0.6727 - acc: 0.6726 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00008: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=32, activation_2=sigmoid, activation_1=tanh, score=0.6755470986131357, total=  36.8s\n",
      "[CV] window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=32, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6319 - _f1_score: 0.6741 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6317 - _f1_score: 0.6739 - acc: 0.6744 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6315 - _f1_score: 0.6741 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6315 - _f1_score: 0.6734 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6312 - _f1_score: 0.6735 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6314 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 7/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6314 - _f1_score: 0.6742 - acc: 0.6744 - val_loss: 0.6325 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00007: early stopping\n",
      "9459/9459 [==============================] - 0s 33us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=32, activation_2=sigmoid, activation_1=tanh, score=0.6683581822177348, total=  32.6s\n",
      "[CV] window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=32, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 137us/step - loss: 0.6351 - _f1_score: 0.6688 - acc: 0.6699 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6330 - _f1_score: 0.6725 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.6724 - acc: 0.6727 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6330 - _f1_score: 0.6726 - acc: 0.6727 - val_loss: 0.6330 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=32, activation_2=sigmoid, activation_1=tanh, score=0.6751956036615684, total=  19.7s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=128, activation_2=relu, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6609 - _f1_score: 8.1310e-04 - acc: 0.6725 - val_loss: 0.6321 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6328 - _f1_score: 0.3407 - acc: 0.6736 - val_loss: 0.6334 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6322 - _f1_score: 0.6682 - acc: 0.6736 - val_loss: 0.6328 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 113us/step - loss: 0.6321 - _f1_score: 0.6667 - acc: 0.6736 - val_loss: 0.6321 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=128, activation_2=relu, activation_1=tanh, score=0.6717411981776824, total=  19.4s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=128, activation_2=relu, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 5.2238 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 5.2323 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 5.2199 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 5.2233 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=128, activation_2=relu, activation_1=tanh, score=0.6752299398911631, total=  19.7s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=128, activation_2=relu, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.6823 - _f1_score: 0.0000e+00 - acc: 0.6681 - val_loss: 0.6356 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6337 - _f1_score: 0.0000e+00 - acc: 0.6726 - val_loss: 0.6327 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6331 - _f1_score: 0.0000e+00 - acc: 0.6726 - val_loss: 0.6324 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.0000e+00 - acc: 0.6726 - val_loss: 0.6325 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=128, activation_2=relu, activation_1=tanh, score=0.6755470986131357, total=  19.6s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=128, activation_2=relu, activation_1=tanh \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 135us/step - loss: 0.7027 - _f1_score: 0.0000e+00 - acc: 0.6701 - val_loss: 0.6332 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6319 - _f1_score: 0.0000e+00 - acc: 0.6744 - val_loss: 0.6346 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6318 - _f1_score: 0.2466 - acc: 0.6744 - val_loss: 0.6374 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 114us/step - loss: 0.6319 - _f1_score: 0.3385 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=128, activation_2=relu, activation_1=tanh, score=0.6683581822177348, total=  19.6s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=128, activation_2=relu, activation_1=tanh \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 135us/step - loss: 0.8028 - _f1_score: 0.0000e+00 - acc: 0.6708 - val_loss: 0.6325 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 0.6327 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6328 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 0.6341 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 114us/step - loss: 0.6329 - _f1_score: 8.1473e-04 - acc: 0.6727 - val_loss: 0.6322 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=128, activation_2=relu, activation_1=tanh, score=0.6751956036615684, total=  19.7s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=Adam, n_state_units=64, activation_2=relu, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 148us/step - loss: 0.6406 - _f1_score: 0.0000e+00 - acc: 0.6723 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6322 - _f1_score: 0.0000e+00 - acc: 0.6736 - val_loss: 0.6328 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6322 - _f1_score: 0.0000e+00 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6323 - _f1_score: 0.0000e+00 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=Adam, n_state_units=64, activation_2=relu, activation_1=relu, score=0.6717411981776824, total=  20.9s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=Adam, n_state_units=64, activation_2=relu, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 143us/step - loss: 0.6478 - _f1_score: 0.0000e+00 - acc: 0.6687 - val_loss: 0.6324 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6330 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 0.6327 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6328 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6328 - _f1_score: 0.0000e+00 - acc: 0.6727 - val_loss: 0.6325 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=Adam, n_state_units=64, activation_2=relu, activation_1=relu, score=0.6752299398911631, total=  20.5s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=Adam, n_state_units=64, activation_2=relu, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 144us/step - loss: 5.2708 - _f1_score: 0.0000e+00 - acc: 0.6724 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 119us/step - loss: 5.2740 - _f1_score: 0.0000e+00 - acc: 0.6726 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 119us/step - loss: 5.2761 - _f1_score: 0.0000e+00 - acc: 0.6726 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 119us/step - loss: 5.2749 - _f1_score: 0.0000e+00 - acc: 0.6726 - val_loss: 5.2694 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=Adam, n_state_units=64, activation_2=relu, activation_1=relu, score=0.6755470986131357, total=  20.7s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=Adam, n_state_units=64, activation_2=relu, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 145us/step - loss: 0.6813 - _f1_score: 0.0000e+00 - acc: 0.6725 - val_loss: 0.6321 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6314 - _f1_score: 0.0000e+00 - acc: 0.6744 - val_loss: 0.6323 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 5s 120us/step - loss: 0.6315 - _f1_score: 0.0000e+00 - acc: 0.6744 - val_loss: 0.6325 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 5s 119us/step - loss: 0.6316 - _f1_score: 0.0000e+00 - acc: 0.6744 - val_loss: 0.6345 - val__f1_score: 0.0000e+00 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=Adam, n_state_units=64, activation_2=relu, activation_1=relu, score=0.6683581822177348, total=  20.8s\n",
      "[CV] window_size=10, units_2=32, units_1=16, optimizer=Adam, n_state_units=64, activation_2=relu, activation_1=relu \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 145us/step - loss: 2.5624 - _f1_score: 0.0000e+00 - acc: 0.6714 - val_loss: 10.8487 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 10.8310 - _f1_score: 0.0000e+00 - acc: 0.3274 - val_loss: 10.8487 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 10.8212 - _f1_score: 0.0000e+00 - acc: 0.3280 - val_loss: 10.8487 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 10.8285 - _f1_score: 0.0000e+00 - acc: 0.3276 - val_loss: 10.8487 - val__f1_score: 0.0000e+00 - val_acc: 0.3269\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=32, units_1=16, optimizer=Adam, n_state_units=64, activation_2=relu, activation_1=relu, score=0.3248043987016946, total=  20.9s\n",
      "[CV] window_size=10, units_2=64, units_1=32, optimizer=SGD, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 127us/step - loss: 0.6500 - _f1_score: 0.6618 - acc: 0.6618 - val_loss: 0.6337 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 108us/step - loss: 0.6321 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37835/37835 [==============================] - 4s 108us/step - loss: 0.6317 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 107us/step - loss: 0.6316 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=32, optimizer=SGD, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6717411981776824, total=  18.6s\n",
      "[CV] window_size=10, units_2=64, units_1=32, optimizer=SGD, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 127us/step - loss: 0.6462 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6334 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 108us/step - loss: 0.6327 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 108us/step - loss: 0.6322 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 108us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=32, optimizer=SGD, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6752299398911631, total=  18.5s\n",
      "[CV] window_size=10, units_2=64, units_1=32, optimizer=SGD, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 126us/step - loss: 0.6500 - _f1_score: 0.6629 - acc: 0.6629 - val_loss: 0.6338 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 107us/step - loss: 0.6328 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 108us/step - loss: 0.6323 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 108us/step - loss: 0.6323 - _f1_score: 0.6726 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=32, optimizer=SGD, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6755470986131357, total=  18.5s\n",
      "[CV] window_size=10, units_2=64, units_1=32, optimizer=SGD, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 127us/step - loss: 0.6466 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6335 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 108us/step - loss: 0.6315 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 108us/step - loss: 0.6310 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 108us/step - loss: 0.6310 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=32, optimizer=SGD, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6683581822177348, total=  18.6s\n",
      "[CV] window_size=10, units_2=64, units_1=32, optimizer=SGD, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 130us/step - loss: 0.6501 - _f1_score: 0.6628 - acc: 0.6628 - val_loss: 0.6338 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 4s 108us/step - loss: 0.6328 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 4s 108us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 4s 108us/step - loss: 0.6323 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9458/9458 [==============================] - 0s 35us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=64, units_1=32, optimizer=SGD, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6751956036615684, total=  18.7s\n",
      "[CV] window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 6s 146us/step - loss: 0.6388 - _f1_score: 0.6536 - acc: 0.6635 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6321 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6329 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6324 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6323 - _f1_score: 0.6736 - acc: 0.6736 - val_loss: 0.6341 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6717411981776824, total=  20.6s\n",
      "[CV] window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 143us/step - loss: 0.6380 - _f1_score: 0.6650 - acc: 0.6635 - val_loss: 0.6336 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6329 - _f1_score: 0.6727 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6330 - _f1_score: 0.6726 - acc: 0.6727 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6329 - _f1_score: 0.6722 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6752299398911631, total=  20.6s\n",
      "[CV] window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 144us/step - loss: 0.6369 - _f1_score: 0.6719 - acc: 0.6630 - val_loss: 0.6324 - val__f1_score: 0.6731 - val_acc: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6330 - _f1_score: 0.6722 - acc: 0.6726 - val_loss: 0.6327 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6329 - _f1_score: 0.6716 - acc: 0.6726 - val_loss: 0.6324 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6329 - _f1_score: 0.6718 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6330 - _f1_score: 0.6711 - acc: 0.6726 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6333 - _f1_score: 0.6699 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 7/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6329 - _f1_score: 0.6698 - acc: 0.6726 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 8/300\n",
      "37835/37835 [==============================] - 4s 119us/step - loss: 0.6327 - _f1_score: 0.6720 - acc: 0.6726 - val_loss: 0.6323 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 9/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6328 - _f1_score: 0.6717 - acc: 0.6726 - val_loss: 0.6328 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 10/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6327 - _f1_score: 0.6704 - acc: 0.6726 - val_loss: 0.6327 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 00010: early stopping\n",
      "9459/9459 [==============================] - 0s 35us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6755470986131357, total=  47.4s\n",
      "[CV] window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37835 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37835/37835 [==============================] - 5s 143us/step - loss: 0.6322 - _f1_score: 0.6747 - acc: 0.6738 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6319 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6326 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37835/37835 [==============================] - 4s 119us/step - loss: 0.6316 - _f1_score: 0.6742 - acc: 0.6744 - val_loss: 0.6323 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6314 - _f1_score: 0.6744 - acc: 0.6744 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6314 - _f1_score: 0.6743 - acc: 0.6744 - val_loss: 0.6327 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6315 - _f1_score: 0.6739 - acc: 0.6744 - val_loss: 0.6345 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 7/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6315 - _f1_score: 0.6735 - acc: 0.6744 - val_loss: 0.6322 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 8/300\n",
      "37835/37835 [==============================] - 4s 119us/step - loss: 0.6315 - _f1_score: 0.6722 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 9/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6314 - _f1_score: 0.6722 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 10/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6313 - _f1_score: 0.6715 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 11/300\n",
      "37835/37835 [==============================] - 5s 119us/step - loss: 0.6315 - _f1_score: 0.6742 - acc: 0.6744 - val_loss: 0.6335 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 12/300\n",
      "37835/37835 [==============================] - 4s 118us/step - loss: 0.6315 - _f1_score: 0.6727 - acc: 0.6744 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 13/300\n",
      "37835/37835 [==============================] - 4s 119us/step - loss: 0.6314 - _f1_score: 0.6721 - acc: 0.6744 - val_loss: 0.6333 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00013: early stopping\n",
      "9459/9459 [==============================] - 0s 34us/step\n",
      "37835/37835 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6683581822177348, total= 1.0min\n",
      "[CV] window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37836 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "37836/37836 [==============================] - 5s 145us/step - loss: 0.6344 - _f1_score: 0.6718 - acc: 0.6712 - val_loss: 0.6325 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6328 - _f1_score: 0.6723 - acc: 0.6727 - val_loss: 0.6325 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6326 - _f1_score: 0.6736 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6328 - _f1_score: 0.6712 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 5/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6327 - _f1_score: 0.6703 - acc: 0.6727 - val_loss: 0.6324 - val__f1_score: 0.6667 - val_acc: 0.6731\n",
      "Epoch 6/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6326 - _f1_score: 0.6723 - acc: 0.6727 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 7/300\n",
      "37836/37836 [==============================] - 5s 119us/step - loss: 0.6327 - _f1_score: 0.6720 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 8/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6328 - _f1_score: 0.6697 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 9/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6328 - _f1_score: 0.6706 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 10/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6329 - _f1_score: 0.6690 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 11/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6326 - _f1_score: 0.6692 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 12/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6326 - _f1_score: 0.6716 - acc: 0.6727 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 13/300\n",
      "37836/37836 [==============================] - 5s 120us/step - loss: 0.6327 - _f1_score: 0.6695 - acc: 0.6727 - val_loss: 0.6339 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00013: early stopping\n",
      "9458/9458 [==============================] - 0s 34us/step\n",
      "37836/37836 [==============================] - 1s 33us/step\n",
      "[CV]  window_size=10, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6751956036615684, total= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 40.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47294 samples, validate on 5255 samples\n",
      "Epoch 1/300\n",
      "47294/47294 [==============================] - 7s 141us/step - loss: 0.6425 - _f1_score: 0.6695 - acc: 0.6695 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 2/300\n",
      "47294/47294 [==============================] - 6s 120us/step - loss: 0.6319 - _f1_score: 0.6732 - acc: 0.6732 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 3/300\n",
      "47294/47294 [==============================] - 6s 120us/step - loss: 0.6319 - _f1_score: 0.6732 - acc: 0.6732 - val_loss: 0.6321 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 4/300\n",
      "47294/47294 [==============================] - 6s 120us/step - loss: 0.6320 - _f1_score: 0.6732 - acc: 0.6732 - val_loss: 0.6320 - val__f1_score: 0.6731 - val_acc: 0.6731\n",
      "Epoch 00004: early stopping\n",
      "----------------------\n",
      "5255/5255 [==============================] - 0s 37us/step\n",
      "grid_result.score(X_test_scaled, y_test):  0.6730732631955568\n",
      "5255/5255 [==============================] - 0s 35us/step\n",
      "\n",
      "Best: 0.673214 using {'window_size': 10, 'units_2': 128, 'units_1': 32, 'optimizer': 'Adam', 'n_state_units': 32, 'activation_2': 'softmax', 'activation_1': 'sigmoid'}\n",
      "\n",
      "---pickle saving..\n",
      "\n",
      "TIME:  2433.7157311439514\n",
      "[INFO] X_train.shape : (47258, 8, 50, 4)\n",
      "[INFO] y_train.shape : (47258, 2)\n",
      "[INFO] X_test.shape : (5251, 8, 50, 4)\n",
      "[INFO] y_test.shape : (5251, 2)\n",
      "\n",
      "[INFO] X_train_2.shape: (47258, 50, 8, 4)\n",
      "[INFO] X_test_2.shape: (5251, 50, 8, 4)\n",
      "\n",
      "[INFO] X_train_3.shape: (47258, 50, 32)\n",
      "[INFO] X_test_3.shape: (5251, 50, 32)\n",
      "\n",
      "[INFO] X_train_reshape.shape: (47258, 1600)\n",
      "[INFO] X_test_reshape.shape: (5251, 1600)\n",
      "\n",
      "\n",
      "\n",
      "----------------------\n",
      "<LSTM>\n",
      "----------------------\n",
      "__BTC__time unit: 10  |  window_size :50  |  gap :1  |  margin_rate :0.1  started.\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 17s 438us/step - loss: 0.6450 - _f1_score: 0.6652 - acc: 0.6652 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 16s 412us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 16s 411us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 16s 411us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 129us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid, score=0.6732966614586794, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 17s 438us/step - loss: 0.6434 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 16s 412us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 16s 412us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 16s 412us/step - loss: 0.6317 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 129us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid, score=0.6692763443877018, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 434us/step - loss: 0.6424 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 409us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 409us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 408us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 130us/step\n",
      "37806/37806 [==============================] - 5s 128us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid, score=0.6672661862936354, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 436us/step - loss: 0.6459 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6290 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 410us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 16s 410us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6290 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 15s 409us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 129us/step\n",
      "37807/37807 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid, score=0.6863823961976999, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 17s 443us/step - loss: 0.6432 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 16s 414us/step - loss: 0.6314 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 16s 413us/step - loss: 0.6313 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 16s 413us/step - loss: 0.6314 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 129us/step\n",
      "37807/37807 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=sigmoid, score=0.6668077460887785, total= 1.1min\n",
      "[CV] window_size=50, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 427us/step - loss: 0.6428 - _f1_score: 0.6666 - acc: 0.6666 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 405us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 404us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 405us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 129us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu, score=0.6732966614586794, total= 1.1min\n",
      "[CV] window_size=50, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 429us/step - loss: 0.6407 - _f1_score: 0.6704 - acc: 0.6704 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 407us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 407us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 406us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 128us/step\n",
      "37806/37806 [==============================] - 5s 128us/step\n",
      "[CV]  window_size=50, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu, score=0.6692763443877018, total= 1.1min\n",
      "[CV] window_size=50, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 428us/step - loss: 0.6369 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 406us/step - loss: 0.6315 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 406us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 406us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 129us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu, score=0.6672661862936354, total= 1.1min\n",
      "[CV] window_size=50, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 429us/step - loss: 0.6402 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 406us/step - loss: 0.6349 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 406us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 15s 406us/step - loss: 0.6349 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 128us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37807/37807 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu, score=0.6863823961976999, total= 1.1min\n",
      "[CV] window_size=50, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 433us/step - loss: 0.6397 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 406us/step - loss: 0.6314 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 407us/step - loss: 0.6313 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 15s 406us/step - loss: 0.6313 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 128us/step\n",
      "37807/37807 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=32, units_1=16, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=relu, score=0.6668077460887785, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 426us/step - loss: 0.6368 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 405us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 405us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 405us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 128us/step\n",
      "37806/37806 [==============================] - ETA:  - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid, score=0.6732966614586794, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 427us/step - loss: 0.6369 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 406us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 405us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 405us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 128us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid, score=0.6692763443877018, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 427us/step - loss: 0.6365 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 406us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 407us/step - loss: 0.6315 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 406us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 129us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid, score=0.6672661862936354, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 428us/step - loss: 0.6468 - _f1_score: 0.6581 - acc: 0.6581 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 406us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 407us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 15s 407us/step - loss: 0.6349 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 129us/step\n",
      "37807/37807 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid, score=0.6863823961976999, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 433us/step - loss: 0.6404 - _f1_score: 0.6689 - acc: 0.6689 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 407us/step - loss: 0.6314 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 407us/step - loss: 0.6313 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 15s 407us/step - loss: 0.6314 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 128us/step\n",
      "37807/37807 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=64, activation_2=softmax, activation_1=sigmoid, score=0.6668077460887785, total= 1.1min\n",
      "[CV] window_size=50, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 424us/step - loss: 0.6338 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6388 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 403us/step - loss: 0.6331 - _f1_score: 0.6725 - acc: 0.6724 - val_loss: 0.6293 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37806/37806 [==============================] - 15s 404us/step - loss: 0.6332 - _f1_score: 0.6723 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 402us/step - loss: 0.6330 - _f1_score: 0.6727 - acc: 0.6724 - val_loss: 0.6305 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 5/300\n",
      "37806/37806 [==============================] - 15s 402us/step - loss: 0.6329 - _f1_score: 0.6726 - acc: 0.6724 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 6/300\n",
      "37806/37806 [==============================] - 15s 402us/step - loss: 0.6330 - _f1_score: 0.6720 - acc: 0.6724 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 7/300\n",
      "37806/37806 [==============================] - 15s 403us/step - loss: 0.6330 - _f1_score: 0.6721 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 8/300\n",
      "37806/37806 [==============================] - 15s 403us/step - loss: 0.6328 - _f1_score: 0.6720 - acc: 0.6724 - val_loss: 0.6291 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 9/300\n",
      "37806/37806 [==============================] - 15s 403us/step - loss: 0.6328 - _f1_score: 0.6722 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 10/300\n",
      "37806/37806 [==============================] - 15s 403us/step - loss: 0.6329 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6292 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 11/300\n",
      "37806/37806 [==============================] - 15s 404us/step - loss: 0.6328 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6295 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00011: early stopping\n",
      "9452/9452 [==============================] - 1s 128us/step\n",
      "37806/37806 [==============================] - 5s 126us/step\n",
      "[CV]  window_size=50, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6732966614586794, total= 2.8min\n",
      "[CV] window_size=50, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 425us/step - loss: 0.6331 - _f1_score: 0.6735 - acc: 0.6734 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 403us/step - loss: 0.6324 - _f1_score: 0.6732 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 405us/step - loss: 0.6325 - _f1_score: 0.6728 - acc: 0.6734 - val_loss: 0.6318 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 403us/step - loss: 0.6322 - _f1_score: 0.6719 - acc: 0.6734 - val_loss: 0.6292 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 5/300\n",
      "37806/37806 [==============================] - 15s 404us/step - loss: 0.6323 - _f1_score: 0.6721 - acc: 0.6734 - val_loss: 0.6306 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 6/300\n",
      "37806/37806 [==============================] - 15s 405us/step - loss: 0.6321 - _f1_score: 0.6730 - acc: 0.6734 - val_loss: 0.6311 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 7/300\n",
      "37806/37806 [==============================] - 15s 403us/step - loss: 0.6322 - _f1_score: 0.6728 - acc: 0.6734 - val_loss: 0.6297 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00007: early stopping\n",
      "9452/9452 [==============================] - 1s 127us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6692763443877018, total= 1.8min\n",
      "[CV] window_size=50, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 424us/step - loss: 0.6328 - _f1_score: 0.6724 - acc: 0.6739 - val_loss: 0.6291 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 404us/step - loss: 0.6321 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 403us/step - loss: 0.6321 - _f1_score: 0.6737 - acc: 0.6739 - val_loss: 0.6291 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 404us/step - loss: 0.6320 - _f1_score: 0.6733 - acc: 0.6739 - val_loss: 0.6302 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 128us/step\n",
      "37806/37806 [==============================] - 5s 126us/step\n",
      "[CV]  window_size=50, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6672661862936354, total= 1.1min\n",
      "[CV] window_size=50, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 426us/step - loss: 0.6362 - _f1_score: 0.6692 - acc: 0.6683 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 405us/step - loss: 0.6356 - _f1_score: 0.6683 - acc: 0.6692 - val_loss: 0.6295 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 404us/step - loss: 0.6356 - _f1_score: 0.6675 - acc: 0.6692 - val_loss: 0.6295 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 15s 405us/step - loss: 0.6354 - _f1_score: 0.6682 - acc: 0.6692 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 5/300\n",
      "37807/37807 [==============================] - 15s 405us/step - loss: 0.6353 - _f1_score: 0.6665 - acc: 0.6692 - val_loss: 0.6341 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 6/300\n",
      "37807/37807 [==============================] - 15s 405us/step - loss: 0.6354 - _f1_score: 0.6671 - acc: 0.6692 - val_loss: 0.6290 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 7/300\n",
      "37807/37807 [==============================] - 15s 406us/step - loss: 0.6353 - _f1_score: 0.6684 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 8/300\n",
      "37807/37807 [==============================] - 15s 404us/step - loss: 0.6351 - _f1_score: 0.6682 - acc: 0.6692 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00008: early stopping\n",
      "9451/9451 [==============================] - 1s 129us/step\n",
      "37807/37807 [==============================] - 5s 126us/step\n",
      "[CV]  window_size=50, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6863823961976999, total= 2.1min\n",
      "[CV] window_size=50, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 426us/step - loss: 0.6326 - _f1_score: 0.6740 - acc: 0.6741 - val_loss: 0.6311 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 405us/step - loss: 0.6321 - _f1_score: 0.6736 - acc: 0.6741 - val_loss: 0.6330 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 405us/step - loss: 0.6320 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6293 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 15s 405us/step - loss: 0.6317 - _f1_score: 0.6750 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 5/300\n",
      "37807/37807 [==============================] - 15s 405us/step - loss: 0.6317 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00005: early stopping\n",
      "9451/9451 [==============================] - 1s 129us/step\n",
      "37807/37807 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=64, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=relu, score=0.6668077460887785, total= 1.3min\n",
      "[CV] window_size=50, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 429us/step - loss: 0.6424 - _f1_score: 0.6702 - acc: 0.6702 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 407us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 407us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 406us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 129us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu, score=0.6732966614586794, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 428us/step - loss: 0.6393 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 405us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 406us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 407us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 129us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu, score=0.6692763443877018, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 429us/step - loss: 0.6402 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 407us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 407us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 407us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 128us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu, score=0.6672661862936354, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 428us/step - loss: 0.6428 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6290 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 407us/step - loss: 0.6349 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 407us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6295 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 15s 407us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 128us/step\n",
      "37807/37807 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu, score=0.6863823961976999, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 429us/step - loss: 0.6397 - _f1_score: 0.6728 - acc: 0.6728 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 406us/step - loss: 0.6313 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 406us/step - loss: 0.6313 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 15s 406us/step - loss: 0.6313 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6290 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 128us/step\n",
      "37807/37807 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=128, optimizer=rmsprop, n_state_units=128, activation_2=softmax, activation_1=relu, score=0.6668077460887785, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 434us/step - loss: 0.6345 - _f1_score: 0.6728 - acc: 0.6696 - val_loss: 0.6293 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 409us/step - loss: 0.6331 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 408us/step - loss: 0.6331 - _f1_score: 0.6714 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 409us/step - loss: 0.6329 - _f1_score: 0.6712 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 5/300\n",
      "37806/37806 [==============================] - 15s 410us/step - loss: 0.6329 - _f1_score: 0.6722 - acc: 0.6724 - val_loss: 0.6304 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 6/300\n",
      "37806/37806 [==============================] - 15s 408us/step - loss: 0.6327 - _f1_score: 0.6733 - acc: 0.6724 - val_loss: 0.6291 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 7/300\n",
      "37806/37806 [==============================] - 15s 409us/step - loss: 0.6328 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00007: early stopping\n",
      "9452/9452 [==============================] - 1s 128us/step\n",
      "37806/37806 [==============================] - 5s 126us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid, score=0.6732966614586794, total= 1.9min\n",
      "[CV] window_size=50, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 436us/step - loss: 0.6324 - _f1_score: 0.6735 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37806/37806 [==============================] - 15s 410us/step - loss: 0.6322 - _f1_score: 0.6735 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 410us/step - loss: 0.6320 - _f1_score: 0.6735 - acc: 0.6734 - val_loss: 0.6306 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 410us/step - loss: 0.6322 - _f1_score: 0.6709 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 5/300\n",
      "37806/37806 [==============================] - 16s 410us/step - loss: 0.6323 - _f1_score: 0.6716 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 6/300\n",
      "37806/37806 [==============================] - 16s 410us/step - loss: 0.6320 - _f1_score: 0.6716 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 7/300\n",
      "37806/37806 [==============================] - 15s 410us/step - loss: 0.6322 - _f1_score: 0.6724 - acc: 0.6734 - val_loss: 0.6290 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00007: early stopping\n",
      "9452/9452 [==============================] - 1s 127us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid, score=0.6692763443877018, total= 1.9min\n",
      "[CV] window_size=50, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 434us/step - loss: 0.6333 - _f1_score: 0.6682 - acc: 0.6714 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 409us/step - loss: 0.6320 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 15s 409us/step - loss: 0.6319 - _f1_score: 0.6741 - acc: 0.6739 - val_loss: 0.6298 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 408us/step - loss: 0.6319 - _f1_score: 0.6736 - acc: 0.6739 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 145us/step\n",
      "37806/37806 [==============================] - 5s 128us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid, score=0.6672661862936354, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 436us/step - loss: 0.6360 - _f1_score: 0.6686 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 16s 411us/step - loss: 0.6353 - _f1_score: 0.6697 - acc: 0.6692 - val_loss: 0.6298 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 16s 411us/step - loss: 0.6354 - _f1_score: 0.6675 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 16s 411us/step - loss: 0.6351 - _f1_score: 0.6691 - acc: 0.6692 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 5/300\n",
      "37807/37807 [==============================] - 16s 411us/step - loss: 0.6354 - _f1_score: 0.6681 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 6/300\n",
      "37807/37807 [==============================] - 15s 409us/step - loss: 0.6353 - _f1_score: 0.6671 - acc: 0.6692 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 7/300\n",
      "37807/37807 [==============================] - 15s 410us/step - loss: 0.6352 - _f1_score: 0.6678 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 8/300\n",
      "37807/37807 [==============================] - 16s 411us/step - loss: 0.6352 - _f1_score: 0.6674 - acc: 0.6692 - val_loss: 0.6298 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 9/300\n",
      "37807/37807 [==============================] - 16s 410us/step - loss: 0.6352 - _f1_score: 0.6699 - acc: 0.6692 - val_loss: 0.6302 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 00009: early stopping\n",
      "9451/9451 [==============================] - 1s 128us/step\n",
      "37807/37807 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid, score=0.6863823961976999, total= 2.4min\n",
      "[CV] window_size=50, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 17s 441us/step - loss: 0.6321 - _f1_score: 0.6737 - acc: 0.6741 - val_loss: 0.6305 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 16s 411us/step - loss: 0.6320 - _f1_score: 0.6738 - acc: 0.6741 - val_loss: 0.6291 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 16s 411us/step - loss: 0.6317 - _f1_score: 0.6735 - acc: 0.6741 - val_loss: 0.6297 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 16s 411us/step - loss: 0.6319 - _f1_score: 0.6716 - acc: 0.6741 - val_loss: 0.6295 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 5/300\n",
      "37807/37807 [==============================] - 16s 412us/step - loss: 0.6319 - _f1_score: 0.6705 - acc: 0.6741 - val_loss: 0.6301 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 6/300\n",
      "37807/37807 [==============================] - 16s 411us/step - loss: 0.6318 - _f1_score: 0.6711 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 7/300\n",
      "37807/37807 [==============================] - 16s 411us/step - loss: 0.6317 - _f1_score: 0.6718 - acc: 0.6741 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 8/300\n",
      "37807/37807 [==============================] - 16s 411us/step - loss: 0.6317 - _f1_score: 0.6715 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00008: early stopping\n",
      "9451/9451 [==============================] - 1s 128us/step\n",
      "37807/37807 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=16, optimizer=Adam, n_state_units=64, activation_2=sigmoid, activation_1=sigmoid, score=0.6668077460887785, total= 2.1min\n",
      "[CV] window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 436us/step - loss: 0.6443 - _f1_score: 0.6666 - acc: 0.6666 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 16s 410us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 16s 410us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 410us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 129us/step\n",
      "37806/37806 [==============================] - 5s 128us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh, score=0.6732966614586794, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37806/37806 [==============================] - 18s 482us/step - loss: 0.6415 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 17s 449us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 17s 441us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 16s 416us/step - loss: 0.6317 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 125us/step\n",
      "37806/37806 [==============================] - 5s 124us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh, score=0.6692763443877018, total= 1.2min\n",
      "[CV] window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 17s 439us/step - loss: 0.6429 - _f1_score: 0.6721 - acc: 0.6721 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 16s 436us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 17s 460us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 16s 430us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 125us/step\n",
      "37806/37806 [==============================] - 5s 125us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh, score=0.6672661862936354, total= 1.2min\n",
      "[CV] window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 17s 442us/step - loss: 0.6459 - _f1_score: 0.6691 - acc: 0.6691 - val_loss: 0.6292 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 16s 429us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 16s 426us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 16s 422us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 130us/step\n",
      "37807/37807 [==============================] - 5s 128us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh, score=0.6863823961976999, total= 1.1min\n",
      "[CV] window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 17s 441us/step - loss: 0.6437 - _f1_score: 0.6723 - acc: 0.6723 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 404us/step - loss: 0.6313 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 404us/step - loss: 0.6313 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 16s 412us/step - loss: 0.6313 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 131us/step\n",
      "37807/37807 [==============================] - 5s 134us/step\n",
      "[CV]  window_size=50, units_2=128, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=tanh, score=0.6668077460887785, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 18s 465us/step - loss: 0.6455 - _f1_score: 0.6674 - acc: 0.6666 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 31s 814us/step - loss: 0.6329 - _f1_score: 0.6704 - acc: 0.6724 - val_loss: 0.6297 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 33s 879us/step - loss: 0.6327 - _f1_score: 0.6720 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 27s 719us/step - loss: 0.6328 - _f1_score: 0.6702 - acc: 0.6724 - val_loss: 0.6293 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 2s 216us/step\n",
      "37806/37806 [==============================] - 6s 150us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid, score=0.6732966614586794, total= 1.9min\n",
      "[CV] window_size=50, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 22s 585us/step - loss: 0.6573 - _f1_score: 3.3833e-04 - acc: 0.3273 - val_loss: 0.6318 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 16s 416us/step - loss: 0.6330 - _f1_score: 0.0000e+00 - acc: 0.3266 - val_loss: 0.6290 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 17s 448us/step - loss: 0.6322 - _f1_score: 0.0000e+00 - acc: 0.3266 - val_loss: 0.6287 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 20s 519us/step - loss: 0.6322 - _f1_score: 0.0000e+00 - acc: 0.3266 - val_loss: 0.6293 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 5/300\n",
      "37806/37806 [==============================] - 19s 495us/step - loss: 0.6323 - _f1_score: 0.0000e+00 - acc: 0.3266 - val_loss: 0.6289 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 00005: early stopping\n",
      "9452/9452 [==============================] - 1s 133us/step\n",
      "37806/37806 [==============================] - 5s 133us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid, score=0.3307236557699491, total= 1.6min\n",
      "[CV] window_size=50, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 19s 498us/step - loss: 0.6479 - _f1_score: 0.0000e+00 - acc: 0.3272 - val_loss: 0.6287 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 17s 446us/step - loss: 0.6322 - _f1_score: 0.0000e+00 - acc: 0.3261 - val_loss: 0.6303 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 16s 422us/step - loss: 0.6318 - _f1_score: 0.0000e+00 - acc: 0.3261 - val_loss: 0.6287 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 4/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37806/37806 [==============================] - 16s 417us/step - loss: 0.6318 - _f1_score: 0.0000e+00 - acc: 0.3261 - val_loss: 0.6289 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 128us/step\n",
      "37806/37806 [==============================] - 5s 130us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid, score=0.3327338146585758, total= 1.2min\n",
      "[CV] window_size=50, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 17s 447us/step - loss: 0.6544 - _f1_score: 0.0000e+00 - acc: 0.3575 - val_loss: 0.6289 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 16s 422us/step - loss: 0.6353 - _f1_score: 0.0000e+00 - acc: 0.3308 - val_loss: 0.6292 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 16s 423us/step - loss: 0.6352 - _f1_score: 0.0000e+00 - acc: 0.3308 - val_loss: 0.6290 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 16s 427us/step - loss: 0.6351 - _f1_score: 0.0000e+00 - acc: 0.3308 - val_loss: 0.6289 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 130us/step\n",
      "37807/37807 [==============================] - 5s 129us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid, score=0.3136176082974022, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 17s 456us/step - loss: 0.6370 - _f1_score: 0.6695 - acc: 0.6735 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 16s 415us/step - loss: 0.6318 - _f1_score: 0.6726 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 17s 443us/step - loss: 0.6319 - _f1_score: 0.6696 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 19s 504us/step - loss: 0.6316 - _f1_score: 0.6711 - acc: 0.6741 - val_loss: 0.6292 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 151us/step\n",
      "37807/37807 [==============================] - 6s 148us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=128, optimizer=Adam, n_state_units=128, activation_2=tanh, activation_1=sigmoid, score=0.6668077460887785, total= 1.2min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 18s 480us/step - loss: 0.6331 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 18s 467us/step - loss: 0.6329 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 18s 465us/step - loss: 0.6327 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6290 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 18s 466us/step - loss: 0.6329 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 133us/step\n",
      "37806/37806 [==============================] - 5s 128us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid, score=0.6732966614586794, total= 1.2min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 17s 440us/step - loss: 0.6393 - _f1_score: 0.1952 - acc: 0.6592 - val_loss: 0.6299 - val__f1_score: 0.0000e+00 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 16s 428us/step - loss: 0.6323 - _f1_score: 0.6193 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 17s 459us/step - loss: 0.6322 - _f1_score: 0.6719 - acc: 0.6734 - val_loss: 0.6292 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 17s 458us/step - loss: 0.6321 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 131us/step\n",
      "37806/37806 [==============================] - 5s 129us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid, score=0.6692763443877018, total= 1.2min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 17s 445us/step - loss: 0.6409 - _f1_score: 0.6028 - acc: 0.6572 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 17s 454us/step - loss: 0.6319 - _f1_score: 0.6740 - acc: 0.6739 - val_loss: 0.6316 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 21s 553us/step - loss: 0.6319 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 18s 485us/step - loss: 0.6318 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 144us/step\n",
      "37806/37806 [==============================] - 6s 149us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid, score=0.6672661862936354, total= 1.3min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 19s 492us/step - loss: 0.6356 - _f1_score: 0.6641 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 17s 438us/step - loss: 0.6354 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6295 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 16s 423us/step - loss: 0.6351 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6302 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 16s 433us/step - loss: 0.6351 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 132us/step\n",
      "37807/37807 [==============================] - 5s 131us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid, score=0.6863823961976999, total= 1.2min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 17s 447us/step - loss: 0.6319 - _f1_score: 0.2957 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 16s 417us/step - loss: 0.6320 - _f1_score: 0.6159 - acc: 0.6741 - val_loss: 0.6293 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 16s 425us/step - loss: 0.6316 - _f1_score: 0.6691 - acc: 0.6741 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 16s 412us/step - loss: 0.6315 - _f1_score: 0.6717 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 138us/step\n",
      "37807/37807 [==============================] - 5s 128us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=rmsprop, n_state_units=128, activation_2=sigmoid, activation_1=sigmoid, score=0.6668077460887785, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 433us/step - loss: 0.6466 - _f1_score: 0.6672 - acc: 0.6716 - val_loss: 0.6303 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 16s 423us/step - loss: 0.6344 - _f1_score: 0.6695 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 16s 433us/step - loss: 0.6340 - _f1_score: 0.6684 - acc: 0.6724 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 407us/step - loss: 0.6334 - _f1_score: 0.6703 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 129us/step\n",
      "37806/37806 [==============================] - 5s 131us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid, score=0.6732966614586794, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 18s 476us/step - loss: 0.6789 - _f1_score: 0.6670 - acc: 0.6727 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 16s 412us/step - loss: 0.6345 - _f1_score: 0.6681 - acc: 0.6734 - val_loss: 0.6307 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 16s 414us/step - loss: 0.6341 - _f1_score: 0.6683 - acc: 0.6734 - val_loss: 0.6293 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 16s 411us/step - loss: 0.6327 - _f1_score: 0.6724 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 127us/step\n",
      "37806/37806 [==============================] - 5s 143us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid, score=0.6692763443877018, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 431us/step - loss: 0.6618 - _f1_score: 0.0000e+00 - acc: 0.3278 - val_loss: 0.6350 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 16s 413us/step - loss: 0.6348 - _f1_score: 0.0000e+00 - acc: 0.3261 - val_loss: 0.6288 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 16s 412us/step - loss: 0.6340 - _f1_score: 0.0000e+00 - acc: 0.3261 - val_loss: 0.6296 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 16s 412us/step - loss: 0.6329 - _f1_score: 0.0000e+00 - acc: 0.3261 - val_loss: 0.6342 - val__f1_score: 0.0000e+00 - val_acc: 0.3224\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 127us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid, score=0.3327338146585758, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 435us/step - loss: 0.7109 - _f1_score: 0.6651 - acc: 0.3342 - val_loss: 0.6936 - val__f1_score: 0.6667 - val_acc: 0.3224\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 16s 416us/step - loss: 0.6933 - _f1_score: 0.6667 - acc: 0.4575 - val_loss: 0.6929 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 405us/step - loss: 0.6928 - _f1_score: 0.6667 - acc: 0.6399 - val_loss: 0.6925 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 16s 419us/step - loss: 0.6923 - _f1_score: 0.6667 - acc: 0.6684 - val_loss: 0.6920 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 127us/step\n",
      "37807/37807 [==============================] - 6s 147us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid, score=0.6863823961976999, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 19s 513us/step - loss: 0.8976 - _f1_score: 0.6585 - acc: 0.6632 - val_loss: 0.6370 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 397us/step - loss: 0.6349 - _f1_score: 0.6694 - acc: 0.6741 - val_loss: 0.6382 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 396us/step - loss: 0.6340 - _f1_score: 0.6697 - acc: 0.6741 - val_loss: 0.6306 - val__f1_score: 0.6667 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 15s 399us/step - loss: 0.6335 - _f1_score: 0.6691 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 127us/step\n",
      "37807/37807 [==============================] - 5s 125us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=128, optimizer=SGD, n_state_units=32, activation_2=tanh, activation_1=sigmoid, score=0.6668077460887785, total= 1.1min\n",
      "[CV] window_size=50, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 416us/step - loss: 0.6326 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 402us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 16s 414us/step - loss: 0.6327 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 409us/step - loss: 0.6326 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 132us/step\n",
      "37806/37806 [==============================] - 5s 136us/step\n",
      "[CV]  window_size=50, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu, score=0.6732966614586794, total= 1.1min\n",
      "[CV] window_size=50, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 17s 443us/step - loss: 0.6382 - _f1_score: 0.6086 - acc: 0.6674 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 15s 408us/step - loss: 0.6320 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 16s 414us/step - loss: 0.6320 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 408us/step - loss: 0.6319 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 131us/step\n",
      "37806/37806 [==============================] - 5s 134us/step\n",
      "[CV]  window_size=50, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu, score=0.6692763443877018, total= 1.1min\n",
      "[CV] window_size=50, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 16s 432us/step - loss: 0.6367 - _f1_score: 0.6613 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 16s 412us/step - loss: 0.6317 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 16s 413us/step - loss: 0.6316 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6291 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 15s 408us/step - loss: 0.6317 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 125us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu, score=0.6672661862936354, total= 1.1min\n",
      "[CV] window_size=50, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 433us/step - loss: 0.6514 - _f1_score: 0.3491 - acc: 0.6360 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 16s 426us/step - loss: 0.6351 - _f1_score: 0.5701 - acc: 0.6692 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 15s 409us/step - loss: 0.6350 - _f1_score: 0.5892 - acc: 0.6692 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 16s 416us/step - loss: 0.6351 - _f1_score: 0.5919 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 129us/step\n",
      "37807/37807 [==============================] - 5s 135us/step\n",
      "[CV]  window_size=50, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu, score=0.6863823961976999, total= 1.1min\n",
      "[CV] window_size=50, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 16s 430us/step - loss: 0.6332 - _f1_score: 0.6418 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 15s 406us/step - loss: 0.6315 - _f1_score: 0.6738 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 16s 421us/step - loss: 0.6317 - _f1_score: 0.6739 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 16s 432us/step - loss: 0.6313 - _f1_score: 0.6739 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 128us/step\n",
      "37807/37807 [==============================] - 5s 141us/step\n",
      "[CV]  window_size=50, units_2=32, units_1=64, optimizer=SGD, n_state_units=32, activation_2=sigmoid, activation_1=relu, score=0.6668077460887785, total= 1.1min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 23s 610us/step - loss: 0.6444 - _f1_score: 0.6564 - acc: 0.6564 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 17s 452us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 17s 438us/step - loss: 0.6325 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 17s 455us/step - loss: 0.6326 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 127us/step\n",
      "37806/37806 [==============================] - 5s 127us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6732966614586794, total= 1.3min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 19s 496us/step - loss: 0.6383 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 17s 453us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 17s 448us/step - loss: 0.6318 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 17s 437us/step - loss: 0.6317 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 129us/step\n",
      "37806/37806 [==============================] - 5s 128us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6692763443877018, total= 1.2min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 19s 515us/step - loss: 0.6358 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 17s 455us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 16s 423us/step - loss: 0.6314 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 17s 452us/step - loss: 0.6315 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 1s 125us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37806/37806 [==============================] - 5s 128us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6672661862936354, total= 1.2min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 18s 481us/step - loss: 0.6441 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 20s 518us/step - loss: 0.6349 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 23s 619us/step - loss: 0.6348 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 23s 612us/step - loss: 0.6349 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 2s 200us/step\n",
      "37807/37807 [==============================] - 8s 198us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6863823961976999, total= 1.5min\n",
      "[CV] window_size=50, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 25s 657us/step - loss: 0.6396 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 22s 590us/step - loss: 0.6314 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 24s 644us/step - loss: 0.6314 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 24s 642us/step - loss: 0.6313 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 2s 200us/step\n",
      "37807/37807 [==============================] - 7s 192us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=32, optimizer=Adam, n_state_units=32, activation_2=softmax, activation_1=relu, score=0.6668077460887785, total= 1.7min\n",
      "[CV] window_size=50, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 23s 620us/step - loss: 0.6380 - _f1_score: 0.6698 - acc: 0.6611 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 24s 624us/step - loss: 0.6327 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 21s 556us/step - loss: 0.6326 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6293 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 24s 625us/step - loss: 0.6327 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 2s 211us/step\n",
      "37806/37806 [==============================] - 8s 199us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh, score=0.6732966614586794, total= 1.6min\n",
      "[CV] window_size=50, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 25s 657us/step - loss: 0.6331 - _f1_score: 0.6673 - acc: 0.6726 - val_loss: 0.6290 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 23s 600us/step - loss: 0.6324 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 24s 622us/step - loss: 0.6322 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 23s 621us/step - loss: 0.6322 - _f1_score: 0.6734 - acc: 0.6734 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 2s 198us/step\n",
      "37806/37806 [==============================] - 7s 197us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh, score=0.6692763443877018, total= 1.6min\n",
      "[CV] window_size=50, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 25s 662us/step - loss: 0.6392 - _f1_score: 0.6675 - acc: 0.6598 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 22s 589us/step - loss: 0.6316 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 25s 663us/step - loss: 0.6315 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 25s 662us/step - loss: 0.6316 - _f1_score: 0.6739 - acc: 0.6739 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9452/9452 [==============================] - 2s 236us/step\n",
      "37806/37806 [==============================] - 8s 220us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh, score=0.6672661862936354, total= 1.7min\n",
      "[CV] window_size=50, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 26s 682us/step - loss: 0.6380 - _f1_score: 0.6677 - acc: 0.6640 - val_loss: 0.6293 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 24s 644us/step - loss: 0.6353 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 26s 687us/step - loss: 0.6352 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6311 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 23s 611us/step - loss: 0.6352 - _f1_score: 0.6692 - acc: 0.6692 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 2s 207us/step\n",
      "37807/37807 [==============================] - 8s 208us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh, score=0.6863823961976999, total= 1.7min\n",
      "[CV] window_size=50, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37807 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37807/37807 [==============================] - 25s 674us/step - loss: 0.6326 - _f1_score: 0.2304 - acc: 0.6741 - val_loss: 0.6332 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37807/37807 [==============================] - 24s 633us/step - loss: 0.6321 - _f1_score: 0.6613 - acc: 0.6741 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37807/37807 [==============================] - 24s 623us/step - loss: 0.6319 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/300\n",
      "37807/37807 [==============================] - 23s 616us/step - loss: 0.6319 - _f1_score: 0.6741 - acc: 0.6741 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 00004: early stopping\n",
      "9451/9451 [==============================] - 1s 148us/step\n",
      "37807/37807 [==============================] - 6s 166us/step\n",
      "[CV]  window_size=50, units_2=16, units_1=64, optimizer=rmsprop, n_state_units=64, activation_2=sigmoid, activation_1=tanh, score=0.6668077460887785, total= 1.7min\n",
      "[CV] window_size=50, units_2=32, units_1=128, optimizer=Adam, n_state_units=128, activation_2=sigmoid, activation_1=tanh \n",
      "Train on 37806 samples, validate on 5251 samples\n",
      "Epoch 1/300\n",
      "37806/37806 [==============================] - 25s 672us/step - loss: 0.6336 - _f1_score: 0.6725 - acc: 0.6724 - val_loss: 0.6342 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 2/300\n",
      "37806/37806 [==============================] - 25s 654us/step - loss: 0.6336 - _f1_score: 0.6723 - acc: 0.6724 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 3/300\n",
      "37806/37806 [==============================] - 25s 659us/step - loss: 0.6331 - _f1_score: 0.6723 - acc: 0.6724 - val_loss: 0.6289 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 4/300\n",
      "37806/37806 [==============================] - 25s 654us/step - loss: 0.6326 - _f1_score: 0.6724 - acc: 0.6724 - val_loss: 0.6288 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 5/300\n",
      "37806/37806 [==============================] - 24s 639us/step - loss: 0.6328 - _f1_score: 0.6723 - acc: 0.6724 - val_loss: 0.6290 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 6/300\n",
      "37806/37806 [==============================] - 23s 605us/step - loss: 0.6331 - _f1_score: 0.6717 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 7/300\n",
      "37806/37806 [==============================] - 24s 637us/step - loss: 0.6329 - _f1_score: 0.6717 - acc: 0.6724 - val_loss: 0.6287 - val__f1_score: 0.6776 - val_acc: 0.6776\n",
      "Epoch 8/300\n",
      "31300/37806 [=======================>......] - ETA: 4s - loss: 0.6327 - _f1_score: 0.6719 - acc: 0.6723"
     ]
    }
   ],
   "source": [
    "for model in model_info[Machine][\"MODEL_list\"]:\n",
    "    for idx_time_unit in model_info[Machine][\"time_unit\"]:\n",
    "        for idx_window_size in model_info[Machine][\"window_size\"]:\n",
    "            for idx_gap in model_info[Machine][\"gap\"]:\n",
    "                for idx_margin_rate in model_info[Machine][\"margin_rate\"]:\n",
    "                    param_grid = {'window_size': [idx_window_size], \n",
    "#                                   'units_1': [2],\n",
    "#                                   'units_2': [32],\n",
    "#                                   'n_state_units': [2],\n",
    "#                                   'activation_1': ['relu'], \n",
    "#                                   'activation_2': ['relu'], \n",
    "#                                   'optimizer': ['Adam']}\n",
    "                                  'units_1': [16,32,64,128],\n",
    "                                  'units_2': [16,32,64,128],\n",
    "                                  'n_state_units': [32, 64, 128],\n",
    "                                  'activation_1': ['tanh', 'sigmoid', 'relu'], \n",
    "                                  'activation_2': ['softmax', 'tanh', 'sigmoid', 'relu'], \n",
    "                                  'optimizer': ['rmsprop', 'Adam', 'SGD']}\n",
    "                    \n",
    "                    try: \n",
    "                        test_list.append(start(machine = Machine,\n",
    "                                              search_param = search_param,\n",
    "                                              _GPU = _GPU, \n",
    "                                              n_jobs = n_jobs,\n",
    "                                              MODEL = model, \n",
    "                                              idx_time_unit = idx_time_unit, \n",
    "                                              idx_window_size = idx_window_size, \n",
    "                                              idx_gap = idx_gap, \n",
    "                                              idx_margin_rate = idx_margin_rate,\n",
    "                                              cv = cv,\n",
    "                                              dataset_scale = dataset_scale,\n",
    "                                              param_grid = param_grid,\n",
    "                                              epochs = epochs,\n",
    "                                              dataset_file_dir = './RNN_coin/',\n",
    "                                              pickle_save_folder = './evaluate_result/',\n",
    "#                                               scoring='accuracy',\n",
    "                                              n_iter = 20))\n",
    "            \n",
    "#             scoring>\n",
    "#                     ['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', \n",
    "#                     'average_precision', 'completeness_score', 'explained_variance', \n",
    "#                     'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', \n",
    "#                     'fowlkes_mallows_score', 'homogeneity_score', 'mutual_info_score', \n",
    "#                     'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', \n",
    "#                     'neg_mean_squared_log_error', 'neg_median_absolute_error', \n",
    "#                     'normalized_mutual_info_score', 'precision', 'precision_macro', \n",
    "#                     'precision_micro', 'precision_samples', 'precision_weighted', 'r2', \n",
    "#                     'recall', 'recall_macro', 'recall_micro', 'recall_samples', \n",
    "#                     'recall_weighted', 'roc_auc', 'v_measure_score']\n",
    "            \n",
    "\n",
    "\n",
    "                        #print(\"{:.2f}\".format(evaluate_result_dict[key_pickleFileName]['test_score']))\n",
    "\n",
    "                    except KeyError or ValueError:\n",
    "                        #print(\"[INFO] Appropriate value of {:4s} is not exist.\".format(coin))\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_info = {}\n",
    "# model_info[\"window_size_standard\"] = {\"MODEL_list\":[\"LSTM\"],\n",
    "#                                       \"time_unit\":[10], \n",
    "#                                       \"window_size\":[10, 25, 50, 75, 100],\n",
    "#                                       \"gap\":[1], \n",
    "#                                       \"margin_rate\":[0.1],\n",
    "#                                       \"lr\":[0.01, 0.001]}\n",
    "# Machine = \"window_size_standard\"\n",
    "# # If Machine is \"test\" then, _TEST argument must be True\n",
    "# test = True\n",
    "# _GPU = False\n",
    "# n_jobs = 1\n",
    "# epochs = 1\n",
    "# cv = 2 # at least 2\n",
    "# dataset_scale = 100\n",
    "# test_list = []\n",
    "# coin_list = [\"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "# search_param = True\n",
    "\n",
    "# for model in model_info[Machine][\"MODEL_list\"]:\n",
    "#     for idx_time_unit in model_info[Machine][\"time_unit\"]:\n",
    "#         for idx_window_size in model_info[Machine][\"window_size\"]:\n",
    "#             for idx_gap in model_info[Machine][\"gap\"]:\n",
    "#                 for idx_margin_rate in model_info[Machine][\"margin_rate\"]:\n",
    "#                     param_grid = {'window_size' : [idx_window_size], \n",
    "#                                   'n_state_units': [16, 32, 64],\n",
    "#                                   'activation': ['tanh', 'sigmoid', 'relu'], \n",
    "#                                   'optimizer': ['rmsprop', 'Adam', 'Adagrad', 'SGD']}\n",
    "                    \n",
    "# #                         print(key_pickleFileName)\n",
    "#                     try: \n",
    "#                         test_list.append(start(machine = Machine,\n",
    "#                               search_param = search_param,\n",
    "#                               _GPU = _GPU, \n",
    "#                               n_jobs = n_jobs,\n",
    "#                               MODEL = model, \n",
    "#                               idx_time_unit = idx_time_unit, \n",
    "#                               idx_window_size = idx_window_size, \n",
    "#                               idx_gap = idx_gap, \n",
    "#                               idx_margin_rate = idx_margin_rate,\n",
    "#                               cv = cv,\n",
    "#                               dataset_scale = dataset_scale,\n",
    "#                               param_grid = param_grid,\n",
    "#                               epochs = epochs))\n",
    "                        \n",
    "\n",
    "#                         #print(\"{:.2f}\".format(evaluate_result_dict[key_pickleFileName]['test_score']))\n",
    "\n",
    "#                     except KeyError or ValueError:\n",
    "#                         #print(\"[INFO] Appropriate value of {:4s} is not exist.\".format(coin))\n",
    "#                         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "result_parameter = {}\n",
    "param_grid = {}\n",
    "\n",
    "for file_name in (key_pickleFileName_list):\n",
    "    try:\n",
    "        with open(dir_path + file_name + \"_param\" + \".pickle\", 'rb') as handle:\n",
    "            result[file_name] = pickle.load(handle)\n",
    "        target_list = result[file_name][file_name]\n",
    "        max_acc_score = max(target_list['Score'])\n",
    "        for idx, item in enumerate(target_list['Score']):\n",
    "            if item == max_acc_score:\n",
    "                result_parameter[file_name] = {'max_acc_score':max_acc_score,\n",
    "                                              'best_parameters':target_list['Params'][idx]}\n",
    "                \n",
    "        activation = result_parameter[file_name]['best_parameters']['activation']\n",
    "        n_state_units = result_parameter[file_name]['best_parameters']['n_state_units']\n",
    "        optimizer = result_parameter[file_name]['best_parameters']['optimizer']\n",
    "        window_size = result_parameter[file_name]['best_parameters']['window_size']\n",
    "        param_grid[file_name] = {'window_size' : [activation], \n",
    "                                  'n_state_units': [n_state_units],\n",
    "                                  'activation': [optimizer], \n",
    "                                  'optimizer': [window_size]}\n",
    "\n",
    "#         func()\n",
    "    \n",
    "    \n",
    "    except FileNotFoundError:\n",
    "#         print(\"[INFO] {} is not exist.\".format(key_pickleFileName))\n",
    "        continue\n",
    "# print(result_parameter)\n",
    "# print(param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {}\n",
    "model_info[\"window_size_standard\"] = {\"MODEL_list\":[\"LSTM\"],\n",
    "                                      \"time_unit\":[10], \n",
    "                                      \"window_size\":[10, 25, 50, 75, 100],\n",
    "                                      \"gap\":[1], \n",
    "                                      \"margin_rate\":[0.1],\n",
    "                                      \"lr\":[0.01, 0.001]}\n",
    "Machine = \"window_size_standard\"\n",
    "# If Machine is \"test\" then, _TEST argument must be True\n",
    "test = True\n",
    "_GPU = False\n",
    "n_jobs = 1\n",
    "epochs = 10000 # as possible as large\n",
    "cv = 5 # at least 2\n",
    "dataset_scale = -1 # maximum = -1\n",
    "# evaluate_result_list = []\n",
    "coin_list = [\"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "search_param = False # Training in order to maximize f1-score\n",
    "\n",
    "for model in model_info[Machine][\"MODEL_list\"]:\n",
    "    for coin in coin_list:\n",
    "        for idx_time_unit in model_info[Machine][\"time_unit\"]:\n",
    "            for idx_window_size in model_info[Machine][\"window_size\"]:\n",
    "                for idx_gap in model_info[Machine][\"gap\"]:\n",
    "                    for idx_margin_rate in model_info[Machine][\"margin_rate\"]:\n",
    "                        key_pickleFileName = model + '_' + coin + '_' + str(idx_time_unit) + '_' + str(idx_window_size) + '_' + str(idx_gap) + '_' + str(idx_margin_rate)\n",
    "                        print(key_pickleFileName)\n",
    "                        try: \n",
    "                            _ = start(machine = Machine,\n",
    "                                      search_param = search_param,\n",
    "                                      _GPU = _GPU, \n",
    "                                      n_jobs = n_jobs,\n",
    "                                      MODEL = model, \n",
    "                                      idx_time_unit = idx_time_unit, \n",
    "                                      idx_window_size = idx_window_size, \n",
    "                                      idx_gap = idx_gap, \n",
    "                                      idx_margin_rate = idx_margin_rate,\n",
    "                                      cv = cv,\n",
    "                                      dataset_scale = dataset_scale,\n",
    "                                      param_grid = param_grid[key_pickleFileName],\n",
    "                                      epochs = epochs)\n",
    "\n",
    "                            #print(\"{:.2f}\".format(evaluate_result_dict[key_pickleFileName]['test_score']))\n",
    "\n",
    "                        except KeyError:\n",
    "                            print(\"[INFO] Appropriate value of {:4s} is not exist.\".format(coin))\n",
    "                            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # 9\n",
    "first_legend_label = 'xgboost'\n",
    "second_legend_label = 'lstm'\n",
    "x_label = 'Cryptocurrency'\n",
    "y_label = 'f1-score'\n",
    "filename = '_clustering_and_diameter'\n",
    "\n",
    "graph(f1_score, \n",
    "      first_legend_label, \n",
    "      second_legend_label,\n",
    "      x_label,\n",
    "      y_label,\n",
    "      filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pwd: /home/link/RNN_181113\n",
      "\n",
      "pwd_list: ['', 'home', 'link', 'RNN_181113\\n']\n",
      "pwd_list: ['', 'home', 'link', 'RNN_181113']\n",
      "pwd_: /home/link/RNN_181113/\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pwd: /home/link/RNN_181113\n",
      "\n",
      "pwd_list: ['', 'home', 'link', 'RNN_181113\\n']\n",
      "pwd_list: ['', 'home', 'link', 'RNN_181113']\n",
      "pwd_: /home/link/RNN_181113/\n",
      "['/home/link/RNN_181113/evaluate_result/100', '/home/link/RNN_181113/evaluate_result/75', '/home/link/RNN_181113/evaluate_result/25', '/home/link/RNN_181113/evaluate_result/50', '/home/link/RNN_181113/evaluate_result/10']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# OS agnostic, read current directory path\n",
    "pwd = os.popen('pwd').read()\n",
    "print(\"pwd: {}\".format(pwd))\n",
    "pwd_list = pwd.split('/')\n",
    "print(\"pwd_list: {}\".format(pwd_list))\n",
    "pwd_list[-1] = (pwd_list[-1].split('\\n'))[0]\n",
    "print(\"pwd_list: {}\".format(pwd_list))\n",
    "#pwd_list.append('/')\n",
    "pwd_ = '/'.join(pwd_list[1:])\n",
    "pwd_ = '/' + pwd_ + '/'\n",
    "print(\"pwd_: {}\".format(pwd_))\n",
    "\n",
    "def search(dirname):\n",
    "    filename_list = []\n",
    "    filenames = os.listdir(dirname)\n",
    "    for filename in filenames:\n",
    "        full_filename = os.path.join(dirname, filename)\n",
    "#         print (full_filename)\n",
    "        filename_list.append(full_filename)\n",
    "    return filename_list\n",
    "        \n",
    "dir_name_list = search(pwd_ + \"evaluate_result\")\n",
    "print(dir_name_list)\n",
    "#filename_list.remove(\"/Users/dohyung/SourceTree/dohyung/_dataset/RNN_coin/.DS_Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = {'100':[], '75':[], '50':[], '25':[], '10':[]}\n",
    "param_ = {'100':{}, '75':{}, '50':{}, '25':{}, '10':{}}\n",
    "\n",
    "for idx, directory in enumerate(dir_name_list):\n",
    "    searched_file = search(directory)\n",
    "#     print(searched_file)\n",
    "    win_idx = directory.split('/')[-1]\n",
    "    for idx_2, file in enumerate(searched_file):\n",
    "#         print(type(file))\n",
    "        tmp = file.split('/')[-1].split('_param')[0]\n",
    "#         print(tmp)\n",
    "        \n",
    "        pickle_file[win_idx].append(tmp)\n",
    "#         print(pickle_file)\n",
    "\n",
    "    for idx, file in enumerate(searched_file):\n",
    "        tmp_pkl = pd.read_pickle(file)\n",
    "        tmp_pkl_key = str(tmp_pkl.keys())\n",
    "        tmp_pkl_key = tmp_pkl_key.split('_')\n",
    "        coin_name = tmp_pkl_key[2]\n",
    "#         print(type(coin_name))\n",
    "        param_[win_idx][coin_name] = tmp_pkl\n",
    "        \n",
    "#         print(param_[win_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coin: ETH, window size: 100, paramter: {'activation': 'tanh', 'n_state_units': 64, 'optimizer': 'Adagrad', 'window_size': 100}\n",
      "coin: ETH, window size: 100, paramter: {'activation': 'sigmoid', 'n_state_units': 64, 'optimizer': 'SGD', 'window_size': 100}\n",
      "coin: ETC, window size: 100, paramter: {'activation': 'tanh', 'n_state_units': 32, 'optimizer': 'Adam', 'window_size': 100}\n",
      "coin: BCH, window size: 100, paramter: {'activation': 'tanh', 'n_state_units': 64, 'optimizer': 'SGD', 'window_size': 100}\n",
      "coin: BCH, window size: 100, paramter: {'activation': 'relu', 'n_state_units': 32, 'optimizer': 'Adagrad', 'window_size': 100}\n",
      "coin: DASH, window size: 100, paramter: {'activation': 'relu', 'n_state_units': 32, 'optimizer': 'rmsprop', 'window_size': 100}\n",
      "coin: LTC, window size: 100, paramter: {'activation': 'tanh', 'n_state_units': 32, 'optimizer': 'SGD', 'window_size': 100}\n",
      "coin: LTC, window size: 100, paramter: {'activation': 'relu', 'n_state_units': 64, 'optimizer': 'Adagrad', 'window_size': 100}\n",
      "coin: BTC, window size: 100, paramter: {'activation': 'tanh', 'n_state_units': 32, 'optimizer': 'Adagrad', 'window_size': 100}\n",
      "coin: XRP, window size: 100, paramter: {'activation': 'sigmoid', 'n_state_units': 32, 'optimizer': 'SGD', 'window_size': 100}\n",
      "coin: BTC, window size: 75, paramter: {'activation': 'sigmoid', 'n_state_units': 64, 'optimizer': 'SGD', 'window_size': 75}\n",
      "coin: DASH, window size: 75, paramter: {'activation': 'tanh', 'n_state_units': 32, 'optimizer': 'rmsprop', 'window_size': 75}\n",
      "coin: ETH, window size: 75, paramter: {'activation': 'tanh', 'n_state_units': 32, 'optimizer': 'rmsprop', 'window_size': 75}\n",
      "coin: ETC, window size: 75, paramter: {'activation': 'sigmoid', 'n_state_units': 64, 'optimizer': 'Adagrad', 'window_size': 75}\n",
      "coin: LTC, window size: 75, paramter: {'activation': 'tanh', 'n_state_units': 64, 'optimizer': 'SGD', 'window_size': 75}\n",
      "coin: LTC, window size: 75, paramter: {'activation': 'relu', 'n_state_units': 32, 'optimizer': 'rmsprop', 'window_size': 75}\n",
      "coin: XRP, window size: 75, paramter: {'activation': 'relu', 'n_state_units': 32, 'optimizer': 'Adam', 'window_size': 75}\n",
      "coin: BCH, window size: 75, paramter: {'activation': 'tanh', 'n_state_units': 64, 'optimizer': 'Adagrad', 'window_size': 75}\n",
      "coin: BCH, window size: 50, paramter: {'activation': 'relu', 'n_state_units': 32, 'optimizer': 'Adam', 'window_size': 50}\n",
      "coin: DASH, window size: 50, paramter: {'activation': 'sigmoid', 'n_state_units': 64, 'optimizer': 'SGD', 'window_size': 50}\n",
      "coin: BTC, window size: 50, paramter: {'activation': 'tanh', 'n_state_units': 16, 'optimizer': 'Adagrad', 'window_size': 50}\n",
      "coin: BTC, window size: 50, paramter: {'activation': 'sigmoid', 'n_state_units': 32, 'optimizer': 'SGD', 'window_size': 50}\n",
      "coin: BTC, window size: 50, paramter: {'activation': 'relu', 'n_state_units': 32, 'optimizer': 'SGD', 'window_size': 50}\n",
      "coin: LTC, window size: 50, paramter: {'activation': 'sigmoid', 'n_state_units': 64, 'optimizer': 'SGD', 'window_size': 50}\n",
      "coin: LTC, window size: 50, paramter: {'activation': 'relu', 'n_state_units': 64, 'optimizer': 'SGD', 'window_size': 50}\n",
      "coin: ETC, window size: 50, paramter: {'activation': 'sigmoid', 'n_state_units': 32, 'optimizer': 'Adam', 'window_size': 50}\n",
      "coin: ETH, window size: 50, paramter: {'activation': 'tanh', 'n_state_units': 32, 'optimizer': 'Adam', 'window_size': 50}\n",
      "coin: XRP, window size: 50, paramter: {'activation': 'tanh', 'n_state_units': 64, 'optimizer': 'rmsprop', 'window_size': 50}\n",
      "coin: XRP, window size: 25, paramter: {'activation': 'sigmoid', 'n_state_units': 64, 'optimizer': 'Adam', 'window_size': 25}\n",
      "coin: BTC, window size: 25, paramter: {'activation': 'relu', 'n_state_units': 64, 'optimizer': 'Adam', 'window_size': 25}\n",
      "coin: ETC, window size: 25, paramter: {'activation': 'relu', 'n_state_units': 32, 'optimizer': 'Adam', 'window_size': 25}\n",
      "coin: DASH, window size: 25, paramter: {'activation': 'sigmoid', 'n_state_units': 64, 'optimizer': 'rmsprop', 'window_size': 25}\n",
      "coin: ETH, window size: 25, paramter: {'activation': 'relu', 'n_state_units': 64, 'optimizer': 'Adam', 'window_size': 25}\n",
      "coin: LTC, window size: 25, paramter: {'activation': 'relu', 'n_state_units': 64, 'optimizer': 'Adam', 'window_size': 25}\n",
      "coin: BCH, window size: 25, paramter: {'activation': 'tanh', 'n_state_units': 64, 'optimizer': 'SGD', 'window_size': 25}\n",
      "coin: DASH, window size: 10, paramter: {'activation': 'relu', 'n_state_units': 32, 'optimizer': 'rmsprop', 'window_size': 10}\n",
      "coin: ETC, window size: 10, paramter: {'activation': 'sigmoid', 'n_state_units': 32, 'optimizer': 'Adam', 'window_size': 10}\n",
      "coin: ETH, window size: 10, paramter: {'activation': 'sigmoid', 'n_state_units': 64, 'optimizer': 'Adagrad', 'window_size': 10}\n",
      "coin: BCH, window size: 10, paramter: {'activation': 'relu', 'n_state_units': 64, 'optimizer': 'SGD', 'window_size': 10}\n",
      "coin: BTC, window size: 10, paramter: {'activation': 'tanh', 'n_state_units': 64, 'optimizer': 'Adam', 'window_size': 10}\n",
      "coin: XRP, window size: 10, paramter: {'activation': 'relu', 'n_state_units': 64, 'optimizer': 'Adagrad', 'window_size': 10}\n",
      "coin: LTC, window size: 10, paramter: {'activation': 'relu', 'n_state_units': 64, 'optimizer': 'Adagrad', 'window_size': 10}\n"
     ]
    }
   ],
   "source": [
    "parameter_score_candidate = {}\n",
    "best_parameter_candidate = {}\n",
    "result_parameter = {}\n",
    "\n",
    "param_keys_win = tuple(param_.keys())\n",
    "for win in param_keys_win:    \n",
    "    parameter_score_candidate[win] = {}\n",
    "    best_parameter_candidate[win] = {}\n",
    "    result_parameter[win] = {}\n",
    "    \n",
    "    param_keys_coin = tuple(param_[win].keys())\n",
    "    \n",
    "    for coin in param_keys_coin:\n",
    "        parameter_score_candidate[win][coin] = param_[win][coin][str(param_[win][coin].keys()).split(\"'\")[1]]['Score']\n",
    "        best_parameter_candidate[win][coin] = param_[win][coin][str(param_[win][coin].keys()).split(\"'\")[1]]['Params']\n",
    "        result_parameter[win][coin] = {}\n",
    "        \n",
    "        max_score = max(parameter_score_candidate[win][coin])\n",
    "        for i, item in enumerate(parameter_score_candidate[win][coin]):\n",
    "            if max_score == item:\n",
    "                result_parameter[win][coin]['best_param'] = best_parameter_candidate[win][coin][i]\n",
    "                print(\"coin: {}, window size: {}, paramter: {}\".format(coin, win, best_parameter_candidate[win][coin][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100': {'ETH': array([0.59142609, 0.47092962, 0.46751954, 0.52936691, 0.53271345,\n",
       "         0.53000233, 0.59178616, 0.59155317, 0.46823968, 0.47090844,\n",
       "         0.5908754 , 0.52993879, 0.40577807, 0.59140491, 0.5908754 ,\n",
       "         0.59178616, 0.52913393, 0.53237456, 0.46728655, 0.40844683,\n",
       "         0.40912461, 0.4702942 , 0.47097198, 0.47063309]),\n",
       "  'ETC': array([0.52718531, 0.62940292, 0.47584352, 0.52532142, 0.52415648,\n",
       "         0.52786309, 0.52604156, 0.52602038, 0.47518692, 0.42189651,\n",
       "         0.47512338, 0.42193887, 0.47397962, 0.47281469, 0.52604156,\n",
       "         0.42077394, 0.52604156, 0.47588588, 0.42263783, 0.42193887,\n",
       "         0.4740008 , 0.52417766, 0.47512338, 0.52530024]),\n",
       "  'BCH': array([0.57102917, 0.42892847, 0.42695868, 0.52422002, 0.57166458,\n",
       "         0.42897083, 0.52419884, 0.57304132, 0.47516574, 0.47514456,\n",
       "         0.526211  , 0.57177049, 0.52485544, 0.47381018, 0.52441065,\n",
       "         0.47516574, 0.47758033, 0.52443183, 0.57304132, 0.47694491,\n",
       "         0.47580116, 0.47558935, 0.52305509, 0.47696609]),\n",
       "  'DASH': array([0.40959058, 0.41067079, 0.58945629, 0.59341707, 0.46362231,\n",
       "         0.59360769, 0.47200983, 0.47200983, 0.52801135, 0.53349713,\n",
       "         0.53099782, 0.52799017, 0.47056955, 0.52796899, 0.40514265,\n",
       "         0.4095694 , 0.59642471, 0.53504332, 0.53205685, 0.47054837,\n",
       "         0.46893864, 0.53502213, 0.46959524, 0.47499629]),\n",
       "  'LTC': array([0.41990554, 0.52760892, 0.52669816, 0.58003093, 0.52765128,\n",
       "         0.42075276, 0.41996908, 0.47643658, 0.52765128, 0.52671934,\n",
       "         0.42388749, 0.47842755, 0.52176307, 0.53078601, 0.42585729,\n",
       "         0.47431851, 0.42575138, 0.52769365, 0.52765128, 0.52356343,\n",
       "         0.47823693, 0.37150785, 0.58003093, 0.41996908]),\n",
       "  'BTC': array([0.67407282, 0.53262873, 0.67422109, 0.60794697, 0.53703429,\n",
       "         0.46741364, 0.6048546 , 0.53237456, 0.60805287, 0.46732892,\n",
       "         0.39660687, 0.39205304, 0.46584627, 0.5337513 , 0.60794697,\n",
       "         0.53688603, 0.53248046, 0.3920954 , 0.39662805, 0.46751954,\n",
       "         0.53394193, 0.53686485, 0.46605808, 0.46775253]),\n",
       "  'XRP': array([0.46826086, 0.52790545, 0.46845149, 0.34776439, 0.53154852,\n",
       "         0.52784191, 0.47137441, 0.34776439, 0.53154852, 0.52788427,\n",
       "         0.40734544, 0.59284519, 0.46904454, 0.53326414, 0.58973164,\n",
       "         0.40734544, 0.46673586, 0.47137441, 0.46673586, 0.53017178,\n",
       "         0.46904454, 0.58973164, 0.34776439, 0.46965878])},\n",
       " '75': {'BTC': array([0.32749021, 0.39661268, 0.60207473, 0.32736319, 0.53517519,\n",
       "         0.3953001 , 0.39737483, 0.53333334, 0.60332381, 0.46416852,\n",
       "         0.53204192, 0.32734202, 0.46721711, 0.53722875, 0.53206309,\n",
       "         0.67263682, 0.39470732, 0.4673653 , 0.53206309, 0.4652694 ,\n",
       "         0.46406267, 0.53595851, 0.53418016, 0.46488833]),\n",
       "  'DASH': array([0.65451466, 0.52960728, 0.46950355, 0.53229597, 0.52823119,\n",
       "         0.5296708 , 0.46804277, 0.47032921, 0.52964962, 0.47032921,\n",
       "         0.46804277, 0.47176882, 0.59248439, 0.40565259, 0.46626442,\n",
       "         0.40751561, 0.59024029, 0.53064465, 0.59434741, 0.59026146,\n",
       "         0.47032921, 0.47032921, 0.5296708 , 0.40565259]),\n",
       "  'ETH': array([0.65148725, 0.40806605, 0.52977665, 0.41058537, 0.46994813,\n",
       "         0.59189161, 0.59193395, 0.46778872, 0.40806605, 0.59193395,\n",
       "         0.47020218, 0.58935112, 0.53221129, 0.47020218, 0.58922409,\n",
       "         0.47291204, 0.47020218, 0.58918175, 0.46994813, 0.592188  ,\n",
       "         0.47037155, 0.47007516, 0.47291204, 0.53221129]),\n",
       "  'ETC': array([0.47922092, 0.37218164, 0.47325077, 0.52196464, 0.3721393 ,\n",
       "         0.57717794, 0.52077908, 0.57722028, 0.42860167, 0.4703292 ,\n",
       "         0.57622526, 0.4723616 , 0.41966762, 0.4216365 , 0.6278607 ,\n",
       "         0.42280089, 0.52674923, 0.46908013, 0.47803535, 0.41962528,\n",
       "         0.58033238, 0.47225574, 0.47922092, 0.57719911]),\n",
       "  'LTC': array([0.41987933, 0.47301789, 0.37131364, 0.62866518, 0.42620938,\n",
       "         0.42620938, 0.57679687, 0.62868636, 0.57372711, 0.47466921,\n",
       "         0.52154123, 0.5215624 , 0.58014184, 0.47873399, 0.52825236,\n",
       "         0.52825236, 0.62868636, 0.57671218, 0.52524611, 0.52793479,\n",
       "         0.57645813, 0.52696094, 0.52397586, 0.47301789]),\n",
       "  'XRP': array([0.651085  , 0.52931089, 0.47064677, 0.46939769, 0.52935323,\n",
       "         0.58924526, 0.53108924, 0.5322748 , 0.47064677, 0.52956494,\n",
       "         0.52914153, 0.52935323, 0.47238277, 0.5322748 , 0.59098126,\n",
       "         0.4692495 , 0.52956494, 0.651085  , 0.5307505 , 0.41054303,\n",
       "         0.5305388 , 0.5322748 , 0.5305388 , 0.47085847]),\n",
       "  'BCH': array([0.57110194, 0.52903567, 0.47329311, 0.57116545, 0.47329311,\n",
       "         0.43124802, 0.61922303, 0.57343072, 0.51908542, 0.47490208,\n",
       "         0.47329311, 0.47557955, 0.52302318, 0.38077697, 0.57482799,\n",
       "         0.4311845 , 0.48091458, 0.52444162, 0.47096433, 0.47329311,\n",
       "         0.4793056 , 0.52507675, 0.48091458, 0.52442045])},\n",
       " '50': {'BCH': array([0.56868678, 0.42820263, 0.47558085, 0.52528672, 0.52452495,\n",
       "         0.47479792, 0.47479792, 0.52285327, 0.57251682, 0.4756655 ,\n",
       "         0.47547505, 0.5212874 , 0.56868678, 0.52207034, 0.47792966,\n",
       "         0.42826611, 0.47403614, 0.61841381, 0.57253798, 0.42885861,\n",
       "         0.52141436, 0.52596386, 0.47469212, 0.42885861]),\n",
       "  'DASH': array([0.52994202, 0.34557112, 0.59084176, 0.46986754, 0.46963477,\n",
       "         0.59046088, 0.59416395, 0.40951797, 0.53362394, 0.59407931,\n",
       "         0.40625926, 0.4729358 , 0.5298997 , 0.46929621, 0.47003682,\n",
       "         0.6542596 , 0.4064497 , 0.34576157, 0.46650303, 0.4669474 ,\n",
       "         0.40640738, 0.5307038 , 0.59416395, 0.5336451 ]),\n",
       "  'BTC': array([0.72222224, 0.50000001, 0.76666668, 0.23333334, 0.52222224,\n",
       "         0.57777779, 0.46666668, 0.23333334, 0.35555557, 0.46666668,\n",
       "         0.46666668, 0.50000001, 0.52222224, 0.54444446, 0.23333334,\n",
       "         0.46666668, 0.23333334, 0.46666668, 0.24444445, 0.76666668,\n",
       "         0.45555557, 0.27777779, 0.53333335, 0.53333335, 0.47777779,\n",
       "         0.53333335, 0.23333334, 0.47777779, 0.47777779, 0.53333335,\n",
       "         0.47777779, 0.76666668, 0.46666668, 0.74444446, 0.4888889 ,\n",
       "         0.46666668]),\n",
       "  'LTC': array([0.42143129, 0.52632359, 0.52714884, 0.47285116, 0.42469   ,\n",
       "         0.57524652, 0.47687164, 0.52672563, 0.57880147, 0.47352829,\n",
       "         0.52501164, 0.47498836, 0.52526556, 0.52312836, 0.42475348,\n",
       "         0.62880359, 0.57880147, 0.42153709, 0.52357273, 0.57852639,\n",
       "         0.47473444, 0.47342249, 0.4228702 , 0.62880359]),\n",
       "  'ETC': array([0.52333996, 0.47712557, 0.52564645, 0.47414194, 0.42168522,\n",
       "         0.52551949, 0.57378645, 0.4749672 , 0.523213  , 0.62708959,\n",
       "         0.47268187, 0.42346269, 0.47680816, 0.52566761, 0.52564645,\n",
       "         0.5277625 , 0.52551949, 0.52778366, 0.42166406, 0.57378645,\n",
       "         0.37293157, 0.47691396, 0.47253375, 0.47847983]),\n",
       "  'ETH': array([0.47606755, 0.65087393, 0.4699945 , 0.40541284, 0.47067163,\n",
       "         0.52640823, 0.46472555, 0.41078759, 0.40545516, 0.52930721,\n",
       "         0.47012146, 0.59156122, 0.47067163, 0.53527445, 0.47359177,\n",
       "         0.47067163, 0.34910491, 0.59154006, 0.47606755, 0.58561513,\n",
       "         0.47065047, 0.40539168, 0.52640823, 0.4701003 ]),\n",
       "  'XRP': array([0.52945533, 0.59103221, 0.52814338, 0.40903128, 0.65021795,\n",
       "         0.41093572, 0.53004782, 0.46883068, 0.5297939 , 0.40901012,\n",
       "         0.4092852 , 0.40903128, 0.41093572, 0.4702061 , 0.52981506,\n",
       "         0.52953997, 0.52956113, 0.58929705, 0.4092852 , 0.52958229,\n",
       "         0.53004782, 0.59096873, 0.5297939 , 0.409391  ])},\n",
       " '25': {'XRP': array([0.53024535, 0.59130711, 0.53181049, 0.53058376, 0.46975465,\n",
       "         0.59010152, 0.53020305, 0.40833333, 0.46878173, 0.53090102,\n",
       "         0.53058376, 0.53087987, 0.47072758, 0.65118443, 0.40989848,\n",
       "         0.40867174, 0.34881557, 0.46818951, 0.58972081, 0.58972081,\n",
       "         0.41027919, 0.40926396, 0.34881557, 0.59166667]),\n",
       "  'BTC': array([0.6037225 , 0.53735195, 0.53735195, 0.60380711, 0.39786379,\n",
       "         0.39925973, 0.53506768, 0.46493232, 0.46683587, 0.53075296,\n",
       "         0.53257191, 0.60207276, 0.46918359, 0.46389594, 0.39500846,\n",
       "         0.46611675, 0.46922589, 0.46740694, 0.60076142, 0.53680203,\n",
       "         0.4661379 , 0.67193316, 0.46624366, 0.53443316]),\n",
       "  'ETC': array([0.52861675, 0.57631134, 0.57633249, 0.52453469, 0.52772843,\n",
       "         0.42079103, 0.42438663, 0.42074873, 0.42280034, 0.47343486,\n",
       "         0.57722081, 0.42277919, 0.47299069, 0.42438663, 0.52409052,\n",
       "         0.4248308 , 0.4733291 , 0.57920897, 0.52861675, 0.42074873,\n",
       "         0.57633249, 0.47590947, 0.47430203, 0.47229272]),\n",
       "  'DASH': array([0.5303088 , 0.52916667, 0.46774535, 0.53085872, 0.34583333,\n",
       "         0.52965313, 0.59219543, 0.53085872, 0.47028342, 0.46799916,\n",
       "         0.46918359, 0.59346447, 0.59350677, 0.5303934 , 0.34583333,\n",
       "         0.53087987, 0.40892555, 0.47041032, 0.59291455, 0.46905668,\n",
       "         0.47026227, 0.34591794, 0.4696066 , 0.4696066 ]),\n",
       "  'ETH': array([0.53005499, 0.34873097, 0.47258883, 0.47178511, 0.46840102,\n",
       "         0.46992386, 0.53109137, 0.46890863, 0.53111252, 0.59295685,\n",
       "         0.46552454, 0.53028765, 0.407022  , 0.52669205, 0.41142132,\n",
       "         0.52821489, 0.46823181, 0.40983503, 0.46890863, 0.4072335 ,\n",
       "         0.46840102, 0.592978  , 0.34873097, 0.4072335 ]),\n",
       "  'LTC': array([0.47282149, 0.4715736 , 0.47379442, 0.52616328, 0.52417513,\n",
       "         0.52294839, 0.57527496, 0.47607868, 0.57732657, 0.47286379,\n",
       "         0.52815144, 0.47485195, 0.52519036, 0.47189086, 0.47184856,\n",
       "         0.52713621, 0.4748731 , 0.52614213, 0.57527496, 0.52392132,\n",
       "         0.52840525, 0.57848985, 0.42472504, 0.37041032]),\n",
       "  'BCH': array([0.52544416, 0.4251269 , 0.52736887, 0.42906091, 0.52233503,\n",
       "         0.52605753, 0.52339255, 0.61933164, 0.47793993, 0.42821489,\n",
       "         0.61931049, 0.47660744, 0.42952623, 0.5748731 , 0.38066836,\n",
       "         0.52102369, 0.52208122, 0.57045262, 0.52102369, 0.47453469,\n",
       "         0.52208122, 0.47356176, 0.43011844, 0.52339255])},\n",
       " '10': {'DASH': array([0.46982704, 0.47293526, 0.46908699, 0.47170889, 0.46697256,\n",
       "         0.47005963, 0.40903709, 0.46697256, 0.53023639, 0.40910052,\n",
       "         0.46824122, 0.46974246, 0.58944052, 0.40578086, 0.40903709,\n",
       "         0.59221043, 0.59402884, 0.52987694, 0.46822007, 0.58941938,\n",
       "         0.47293526, 0.5341481 , 0.46822007, 0.46781833]),\n",
       "  'ETC': array([0.57924895, 0.47547258, 0.47796761, 0.52399882, 0.57781114,\n",
       "         0.42415528, 0.47464795, 0.47414048, 0.52932719, 0.62912843,\n",
       "         0.47600118, 0.47803104, 0.47215292, 0.42077219, 0.57531611,\n",
       "         0.5792701 , 0.52524633, 0.42077219, 0.47073625, 0.42415528,\n",
       "         0.57781114, 0.47456337, 0.57916438, 0.52588066]),\n",
       "  'ETH': array([0.58984226, 0.52915803, 0.59144923, 0.4709054 , 0.47092654,\n",
       "         0.40857191, 0.47048251, 0.46936186, 0.5913858 , 0.52964435,\n",
       "         0.46940415, 0.47022878, 0.41011545, 0.52905231, 0.65156257,\n",
       "         0.58988455, 0.59140694, 0.46898127, 0.53129361, 0.53103988,\n",
       "         0.47092654, 0.47044023, 0.46891783, 0.47048251]),\n",
       "  'BCH': array([0.52321647, 0.57028376, 0.42971624, 0.47699497, 0.52366051,\n",
       "         0.52361822, 0.57028376, 0.57028376, 0.57337083, 0.57288451,\n",
       "         0.42662917, 0.52057343, 0.47392904, 0.47942657, 0.52319533,\n",
       "         0.57337083, 0.52672643, 0.37992134, 0.57290565, 0.57356113,\n",
       "         0.47614919, 0.47608576, 0.47327356, 0.62018438]),\n",
       "  'BTC': array([0.46564046, 0.46703599, 0.60589081, 0.46432952, 0.3970694 ,\n",
       "         0.67310864, 0.53717174, 0.3267645 , 0.46441409, 0.46712057,\n",
       "         0.4657039 , 0.46695141, 0.604453  , 0.46443524, 0.46707828,\n",
       "         0.53294287, 0.53550133, 0.53435954, 0.60307862, 0.53429611,\n",
       "         0.60305747, 0.4628917 , 0.53442297, 0.60314205]),\n",
       "  'XRP': array([0.40912167, 0.53137819, 0.52968664, 0.47031336, 0.59163953,\n",
       "         0.47046137, 0.40836047, 0.47137058, 0.52955978, 0.40939654,\n",
       "         0.59058232, 0.40941769, 0.53059585, 0.53165307, 0.59087834,\n",
       "         0.46925614, 0.46834694, 0.53165307, 0.53135704, 0.59267561,\n",
       "         0.53032097, 0.46834694, 0.59269675, 0.52862943]),\n",
       "  'LTC': array([0.473337  , 0.57789572, 0.52763564, 0.52668415, 0.57694422,\n",
       "         0.42214657, 0.47399247, 0.52600753, 0.5270436 , 0.4768681 ,\n",
       "         0.57694422, 0.52330105, 0.57417431, 0.52431598, 0.47610691,\n",
       "         0.47669895, 0.47678353, 0.47306212, 0.52600753, 0.37220366,\n",
       "         0.42248488, 0.47337929, 0.62779634, 0.473337  ])}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_score_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100': {'ETH': {'best_param': {'activation': 'sigmoid',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'SGD',\n",
       "    'window_size': 100}},\n",
       "  'ETC': {'best_param': {'activation': 'tanh',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 100}},\n",
       "  'BCH': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'Adagrad',\n",
       "    'window_size': 100}},\n",
       "  'DASH': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'rmsprop',\n",
       "    'window_size': 100}},\n",
       "  'LTC': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'Adagrad',\n",
       "    'window_size': 100}},\n",
       "  'BTC': {'best_param': {'activation': 'tanh',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'Adagrad',\n",
       "    'window_size': 100}},\n",
       "  'XRP': {'best_param': {'activation': 'sigmoid',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'SGD',\n",
       "    'window_size': 100}}},\n",
       " '75': {'BTC': {'best_param': {'activation': 'sigmoid',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'SGD',\n",
       "    'window_size': 75}},\n",
       "  'DASH': {'best_param': {'activation': 'tanh',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'rmsprop',\n",
       "    'window_size': 75}},\n",
       "  'ETH': {'best_param': {'activation': 'tanh',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'rmsprop',\n",
       "    'window_size': 75}},\n",
       "  'ETC': {'best_param': {'activation': 'sigmoid',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'Adagrad',\n",
       "    'window_size': 75}},\n",
       "  'LTC': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'rmsprop',\n",
       "    'window_size': 75}},\n",
       "  'XRP': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 75}},\n",
       "  'BCH': {'best_param': {'activation': 'tanh',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'Adagrad',\n",
       "    'window_size': 75}}},\n",
       " '50': {'BCH': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 50}},\n",
       "  'DASH': {'best_param': {'activation': 'sigmoid',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'SGD',\n",
       "    'window_size': 50}},\n",
       "  'BTC': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'SGD',\n",
       "    'window_size': 50}},\n",
       "  'LTC': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'SGD',\n",
       "    'window_size': 50}},\n",
       "  'ETC': {'best_param': {'activation': 'sigmoid',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 50}},\n",
       "  'ETH': {'best_param': {'activation': 'tanh',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 50}},\n",
       "  'XRP': {'best_param': {'activation': 'tanh',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'rmsprop',\n",
       "    'window_size': 50}}},\n",
       " '25': {'XRP': {'best_param': {'activation': 'sigmoid',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 25}},\n",
       "  'BTC': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 25}},\n",
       "  'ETC': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 25}},\n",
       "  'DASH': {'best_param': {'activation': 'sigmoid',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'rmsprop',\n",
       "    'window_size': 25}},\n",
       "  'ETH': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 25}},\n",
       "  'LTC': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 25}},\n",
       "  'BCH': {'best_param': {'activation': 'tanh',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'SGD',\n",
       "    'window_size': 25}}},\n",
       " '10': {'DASH': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'rmsprop',\n",
       "    'window_size': 10}},\n",
       "  'ETC': {'best_param': {'activation': 'sigmoid',\n",
       "    'n_state_units': 32,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 10}},\n",
       "  'ETH': {'best_param': {'activation': 'sigmoid',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'Adagrad',\n",
       "    'window_size': 10}},\n",
       "  'BCH': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'SGD',\n",
       "    'window_size': 10}},\n",
       "  'BTC': {'best_param': {'activation': 'tanh',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'Adam',\n",
       "    'window_size': 10}},\n",
       "  'XRP': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'Adagrad',\n",
       "    'window_size': 10}},\n",
       "  'LTC': {'best_param': {'activation': 'relu',\n",
       "    'n_state_units': 64,\n",
       "    'optimizer': 'Adagrad',\n",
       "    'window_size': 10}}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'sigmoid',\n",
       " 'n_state_units': 64,\n",
       " 'optimizer': 'Adagrad',\n",
       " 'window_size': 10}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'key_pickleFileName' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-b32bfb44f569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mdataset_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_pickleFileName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m           epochs = epochs)\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'key_pickleFileName' is not defined"
     ]
    }
   ],
   "source": [
    "test = False\n",
    "_GPU = True\n",
    "n_jobs = 1\n",
    "epochs = 100000 # as possible as large\n",
    "cv = 10 # at least 2\n",
    "dataset_scale = -1 # maximum = -1\n",
    "# evaluate_result_list = []\n",
    "coin_list = [\"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "search_param = False # Training in order to maximize f1-score\n",
    "\n",
    "for win in param_keys_win:    \n",
    "    for coin in param_keys_coin:\n",
    "        result_parameter[win][coin]['best_param']\n",
    "        result_best_paramter['activation']\n",
    "        result_best_paramter['n_state_units']\n",
    "        result_best_paramter['optimizer']\n",
    "        \n",
    "for model in model_info[Machine][\"MODEL_list\"]:\n",
    "    for coin in coin_list:\n",
    "        for idx_time_unit in model_info[Machine][\"time_unit\"]:\n",
    "            for idx_window_size in model_info[Machine][\"window_size\"]:\n",
    "                for idx_gap in model_info[Machine][\"gap\"]:\n",
    "                    for idx_margin_rate in model_info[Machine][\"margin_rate\"]:\n",
    "                        key_pickleFileName = model + '_' + coin + '_' + str(idx_time_unit) + '_' + str(idx_window_size) + '_' + str(idx_gap) + '_' + str(idx_margin_rate)\n",
    "                        print(key_pickleFileName)\n",
    "                        param_grid = {'window_size' : [idx_window_size], \n",
    "                                  'n_state_units': [32, 64],\n",
    "                                  'activation': ['tanh', 'sigmoid', 'relu'], \n",
    "                                  'optimizer': ['rmsprop', 'Adam', 'Adagrad', 'SGD']}\n",
    "                        try: \n",
    "                            _ = start(machine = Machine,\n",
    "                                      search_param = search_param,\n",
    "                                      _GPU = _GPU, \n",
    "                                      n_jobs = n_jobs,\n",
    "                                      MODEL = model, \n",
    "                                      idx_time_unit = idx_time_unit, \n",
    "                                      idx_window_size = idx_window_size, \n",
    "                                      idx_gap = idx_gap, \n",
    "                                      idx_margin_rate = idx_margin_rate,\n",
    "                                      cv = cv,\n",
    "                                      dataset_scale = dataset_scale,\n",
    "                                      param_grid = param_grid[key_pickleFileName],\n",
    "                                      epochs = epochs,\n",
    "                                      dataset_file_dir = '/home/link/RNN_181113/RNN_coin',\n",
    "                                      pickle_save_folder = '/home/link/RNN_181113/result')\n",
    "\n",
    "                            #print(\"{:.2f}\".format(evaluate_result_dict[key_pickleFileName]['test_score']))\n",
    "\n",
    "                        except KeyError:\n",
    "                            print(\"[INFO] Appropriate value of {:4s} is not exist.\".format(coin))\n",
    "                            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
