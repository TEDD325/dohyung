{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 688us/step - loss: 3.7048 - acc: 0.5977\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.9408 - acc: 0.5885\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.7518 - acc: 0.6432\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.7113 - acc: 0.6628\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.6812 - acc: 0.6758\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.6503 - acc: 0.6810\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.6493 - acc: 0.6719\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 272us/step - loss: 0.6366 - acc: 0.6849\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 272us/step - loss: 0.6242 - acc: 0.6914\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.6297 - acc: 0.6784\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.6476 - acc: 0.6706\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 259us/step - loss: 0.6398 - acc: 0.6784\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.6258 - acc: 0.6810\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 268us/step - loss: 0.6191 - acc: 0.6953\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 278us/step - loss: 0.6027 - acc: 0.6914\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.5879 - acc: 0.7018\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 273us/step - loss: 0.5854 - acc: 0.7005\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.6012 - acc: 0.6849\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.5806 - acc: 0.7109\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.5798 - acc: 0.7174\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.5687 - acc: 0.7161\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.5818 - acc: 0.6966\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 250us/step - loss: 0.5734 - acc: 0.7083\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.5679 - acc: 0.7305\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 250us/step - loss: 0.5577 - acc: 0.7344\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 246us/step - loss: 0.5702 - acc: 0.7044\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.5556 - acc: 0.7240\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 263us/step - loss: 0.5558 - acc: 0.7292\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5739 - acc: 0.7135\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.5607 - acc: 0.7214\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.5685 - acc: 0.7161\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.5636 - acc: 0.7148\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.5520 - acc: 0.7201\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.5492 - acc: 0.7318\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.5507 - acc: 0.7201\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5610 - acc: 0.7083\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.5349 - acc: 0.7383\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5405 - acc: 0.7227\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.5451 - acc: 0.7253\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.5445 - acc: 0.7214\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.5435 - acc: 0.7357\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 259us/step - loss: 0.5381 - acc: 0.7409\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 249us/step - loss: 0.5311 - acc: 0.7526\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.5333 - acc: 0.7422\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.5314 - acc: 0.7539\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.5276 - acc: 0.7539\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.5320 - acc: 0.7357\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 278us/step - loss: 0.5330 - acc: 0.7396\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.5324 - acc: 0.7500\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.5264 - acc: 0.7383\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.5281 - acc: 0.7500\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.5304 - acc: 0.7474\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.5387 - acc: 0.7422\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 278us/step - loss: 0.5372 - acc: 0.7240\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5220 - acc: 0.7513\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.5277 - acc: 0.7422\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.5307 - acc: 0.7357\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5225 - acc: 0.7526\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.5119 - acc: 0.7630\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.5334 - acc: 0.7318\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.5276 - acc: 0.7409\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 278us/step - loss: 0.5169 - acc: 0.7604\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5419 - acc: 0.7305\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.5312 - acc: 0.7422\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.5197 - acc: 0.7487\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.5056 - acc: 0.7539\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.5151 - acc: 0.7409\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.5128 - acc: 0.7539\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 259us/step - loss: 0.5132 - acc: 0.7487\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 272us/step - loss: 0.5375 - acc: 0.7266\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 276us/step - loss: 0.5176 - acc: 0.7383\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.5160 - acc: 0.7500\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.5165 - acc: 0.7448\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5101 - acc: 0.7630\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 289us/step - loss: 0.5092 - acc: 0.7591\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 257us/step - loss: 0.5103 - acc: 0.7578\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5161 - acc: 0.7630\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5129 - acc: 0.7552\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.5135 - acc: 0.7513\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 249us/step - loss: 0.5096 - acc: 0.7617\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5051 - acc: 0.7708\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 250us/step - loss: 0.5042 - acc: 0.7578\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.4994 - acc: 0.7643\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.4968 - acc: 0.7643\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5048 - acc: 0.7487\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 273us/step - loss: 0.5051 - acc: 0.7552\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4988 - acc: 0.7591\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.4994 - acc: 0.7669\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5037 - acc: 0.7773\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 250us/step - loss: 0.5094 - acc: 0.7513\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 275us/step - loss: 0.5024 - acc: 0.7578\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 276us/step - loss: 0.5058 - acc: 0.7500\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.4993 - acc: 0.7656\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.4970 - acc: 0.7708\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.5033 - acc: 0.7500\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.4907 - acc: 0.7760\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.5002 - acc: 0.7721\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4902 - acc: 0.7669\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.4902 - acc: 0.7669\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.4838 - acc: 0.7812\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.4893 - acc: 0.7747\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.4985 - acc: 0.7630\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.4991 - acc: 0.7591\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.4923 - acc: 0.7930\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.5294 - acc: 0.7500\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.4903 - acc: 0.7826\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 267us/step - loss: 0.4905 - acc: 0.7721\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 276us/step - loss: 0.4968 - acc: 0.7747\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.4874 - acc: 0.7669\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 273us/step - loss: 0.4909 - acc: 0.7682\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 275us/step - loss: 0.4842 - acc: 0.7826\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.4937 - acc: 0.7799\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.4954 - acc: 0.7578\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.4913 - acc: 0.7617\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.4902 - acc: 0.7773\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.4936 - acc: 0.7747\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 259us/step - loss: 0.4904 - acc: 0.7604\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.4874 - acc: 0.7852\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.4819 - acc: 0.7682\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.4940 - acc: 0.7786\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.4912 - acc: 0.7799\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.4861 - acc: 0.7734\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.4836 - acc: 0.7669\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.4836 - acc: 0.7721\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.4865 - acc: 0.7760\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.4795 - acc: 0.7786\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.4882 - acc: 0.7721\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.4724 - acc: 0.7786\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.4809 - acc: 0.7773\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.4735 - acc: 0.7852\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.4823 - acc: 0.7682\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 254us/step - loss: 0.4813 - acc: 0.7839\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.4829 - acc: 0.7695\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 254us/step - loss: 0.4843 - acc: 0.7734\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 250us/step - loss: 0.4769 - acc: 0.7773\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.4729 - acc: 0.7826\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 249us/step - loss: 0.4674 - acc: 0.7826\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 250us/step - loss: 0.4805 - acc: 0.7839\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.4643 - acc: 0.7917\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.4804 - acc: 0.7852\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.4725 - acc: 0.7839\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 267us/step - loss: 0.4825 - acc: 0.7799\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4753 - acc: 0.7721\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.4763 - acc: 0.7747\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 272us/step - loss: 0.4867 - acc: 0.7682\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 278us/step - loss: 0.4919 - acc: 0.7747\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.4826 - acc: 0.7839\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 273us/step - loss: 0.4699 - acc: 0.7786\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.4762 - acc: 0.7643\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.4753 - acc: 0.7812\n",
      "768/768 [==============================] - 0s 89us/step\n",
      "\n",
      "acc: 79.30%\n"
     ]
    }
   ],
   "source": [
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  app.launch_new_instance()\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " - 1s - loss: 0.6773 - acc: 0.6510\n",
      "Epoch 2/150\n",
      " - 0s - loss: 0.6592 - acc: 0.6510\n",
      "Epoch 3/150\n",
      " - 0s - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 4/150\n",
      " - 0s - loss: 0.6394 - acc: 0.6510\n",
      "Epoch 5/150\n",
      " - 0s - loss: 0.6328 - acc: 0.6510\n",
      "Epoch 6/150\n",
      " - 0s - loss: 0.6191 - acc: 0.6510\n",
      "Epoch 7/150\n",
      " - 0s - loss: 0.6179 - acc: 0.6510\n",
      "Epoch 8/150\n",
      " - 0s - loss: 0.6172 - acc: 0.6510\n",
      "Epoch 9/150\n",
      " - 0s - loss: 0.6093 - acc: 0.6510\n",
      "Epoch 10/150\n",
      " - 0s - loss: 0.6178 - acc: 0.6510\n",
      "Epoch 11/150\n",
      " - 0s - loss: 0.6052 - acc: 0.6510\n",
      "Epoch 12/150\n",
      " - 0s - loss: 0.6042 - acc: 0.6510\n",
      "Epoch 13/150\n",
      " - 0s - loss: 0.6002 - acc: 0.6510\n",
      "Epoch 14/150\n",
      " - 0s - loss: 0.6035 - acc: 0.6510\n",
      "Epoch 15/150\n",
      " - 0s - loss: 0.6002 - acc: 0.6510\n",
      "Epoch 16/150\n",
      " - 0s - loss: 0.6005 - acc: 0.6510\n",
      "Epoch 17/150\n",
      " - 0s - loss: 0.5998 - acc: 0.6510\n",
      "Epoch 18/150\n",
      " - 0s - loss: 0.6039 - acc: 0.6510\n",
      "Epoch 19/150\n",
      " - 0s - loss: 0.5985 - acc: 0.6510\n",
      "Epoch 20/150\n",
      " - 0s - loss: 0.5978 - acc: 0.6510\n",
      "Epoch 21/150\n",
      " - 0s - loss: 0.5954 - acc: 0.6510\n",
      "Epoch 22/150\n",
      " - 0s - loss: 0.5951 - acc: 0.6510\n",
      "Epoch 23/150\n",
      " - 0s - loss: 0.5948 - acc: 0.6510\n",
      "Epoch 24/150\n",
      " - 0s - loss: 0.6014 - acc: 0.6510\n",
      "Epoch 25/150\n",
      " - 0s - loss: 0.5918 - acc: 0.6510\n",
      "Epoch 26/150\n",
      " - 0s - loss: 0.5979 - acc: 0.6510\n",
      "Epoch 27/150\n",
      " - 0s - loss: 0.5964 - acc: 0.6510\n",
      "Epoch 28/150\n",
      " - 0s - loss: 0.5906 - acc: 0.6510\n",
      "Epoch 29/150\n",
      " - 0s - loss: 0.5962 - acc: 0.6510\n",
      "Epoch 30/150\n",
      " - 0s - loss: 0.5907 - acc: 0.6510\n",
      "Epoch 31/150\n",
      " - 0s - loss: 0.5914 - acc: 0.6510\n",
      "Epoch 32/150\n",
      " - 0s - loss: 0.5912 - acc: 0.6510\n",
      "Epoch 33/150\n",
      " - 0s - loss: 0.5860 - acc: 0.6510\n",
      "Epoch 34/150\n",
      " - 0s - loss: 0.5910 - acc: 0.6510\n",
      "Epoch 35/150\n",
      " - 0s - loss: 0.5906 - acc: 0.6510\n",
      "Epoch 36/150\n",
      " - 0s - loss: 0.5846 - acc: 0.6510\n",
      "Epoch 37/150\n",
      " - 0s - loss: 0.5820 - acc: 0.6510\n",
      "Epoch 38/150\n",
      " - 0s - loss: 0.5918 - acc: 0.6510\n",
      "Epoch 39/150\n",
      " - 0s - loss: 0.5838 - acc: 0.6523\n",
      "Epoch 40/150\n",
      " - 0s - loss: 0.5879 - acc: 0.6784\n",
      "Epoch 41/150\n",
      " - 0s - loss: 0.5822 - acc: 0.6927\n",
      "Epoch 42/150\n",
      " - 0s - loss: 0.5814 - acc: 0.7070\n",
      "Epoch 43/150\n",
      " - 0s - loss: 0.5792 - acc: 0.7070\n",
      "Epoch 44/150\n",
      " - 0s - loss: 0.5861 - acc: 0.7109\n",
      "Epoch 45/150\n",
      " - 0s - loss: 0.5793 - acc: 0.7148\n",
      "Epoch 46/150\n",
      " - 0s - loss: 0.5769 - acc: 0.6992\n",
      "Epoch 47/150\n",
      " - 0s - loss: 0.5780 - acc: 0.7135\n",
      "Epoch 48/150\n",
      " - 0s - loss: 0.5751 - acc: 0.7018\n",
      "Epoch 49/150\n",
      " - 0s - loss: 0.5756 - acc: 0.7148\n",
      "Epoch 50/150\n",
      " - 0s - loss: 0.5756 - acc: 0.7070\n",
      "Epoch 51/150\n",
      " - 0s - loss: 0.5740 - acc: 0.7135\n",
      "Epoch 52/150\n",
      " - 0s - loss: 0.5726 - acc: 0.7096\n",
      "Epoch 53/150\n",
      " - 0s - loss: 0.5755 - acc: 0.7057\n",
      "Epoch 54/150\n",
      " - 0s - loss: 0.5719 - acc: 0.7057\n",
      "Epoch 55/150\n",
      " - 0s - loss: 0.5733 - acc: 0.7057\n",
      "Epoch 56/150\n",
      " - 0s - loss: 0.5738 - acc: 0.7109\n",
      "Epoch 57/150\n",
      " - 0s - loss: 0.5710 - acc: 0.7096\n",
      "Epoch 58/150\n",
      " - 0s - loss: 0.5730 - acc: 0.7122\n",
      "Epoch 59/150\n",
      " - 0s - loss: 0.5703 - acc: 0.7096\n",
      "Epoch 60/150\n",
      " - 0s - loss: 0.5724 - acc: 0.6992\n",
      "Epoch 61/150\n",
      " - 0s - loss: 0.5675 - acc: 0.7083\n",
      "Epoch 62/150\n",
      " - 0s - loss: 0.5687 - acc: 0.7135\n",
      "Epoch 63/150\n",
      " - 0s - loss: 0.5718 - acc: 0.6992\n",
      "Epoch 64/150\n",
      " - 0s - loss: 0.5731 - acc: 0.6953\n",
      "Epoch 65/150\n",
      " - 0s - loss: 0.5650 - acc: 0.7096\n",
      "Epoch 66/150\n",
      " - 0s - loss: 0.5639 - acc: 0.7122\n",
      "Epoch 67/150\n",
      " - 0s - loss: 0.5603 - acc: 0.7201\n",
      "Epoch 68/150\n",
      " - 0s - loss: 0.5614 - acc: 0.7109\n",
      "Epoch 69/150\n",
      " - 0s - loss: 0.5622 - acc: 0.7201\n",
      "Epoch 70/150\n",
      " - 0s - loss: 0.5684 - acc: 0.7070\n",
      "Epoch 71/150\n",
      " - 0s - loss: 0.5590 - acc: 0.7122\n",
      "Epoch 72/150\n",
      " - 0s - loss: 0.5585 - acc: 0.6940\n",
      "Epoch 73/150\n",
      " - 0s - loss: 0.5549 - acc: 0.7253\n",
      "Epoch 74/150\n",
      " - 0s - loss: 0.5618 - acc: 0.6979\n",
      "Epoch 75/150\n",
      " - 0s - loss: 0.5576 - acc: 0.7135\n",
      "Epoch 76/150\n",
      " - 0s - loss: 0.5562 - acc: 0.7187\n",
      "Epoch 77/150\n",
      " - 0s - loss: 0.5554 - acc: 0.7161\n",
      "Epoch 78/150\n",
      " - 0s - loss: 0.5495 - acc: 0.7174\n",
      "Epoch 79/150\n",
      " - 0s - loss: 0.5600 - acc: 0.7044\n",
      "Epoch 80/150\n",
      " - 0s - loss: 0.5532 - acc: 0.7109\n",
      "Epoch 81/150\n",
      " - 0s - loss: 0.5487 - acc: 0.7174\n",
      "Epoch 82/150\n",
      " - 0s - loss: 0.5545 - acc: 0.7096\n",
      "Epoch 83/150\n",
      " - 0s - loss: 0.5518 - acc: 0.7148\n",
      "Epoch 84/150\n",
      " - 0s - loss: 0.5455 - acc: 0.7253\n",
      "Epoch 85/150\n",
      " - 0s - loss: 0.5494 - acc: 0.7135\n",
      "Epoch 86/150\n",
      " - 0s - loss: 0.5597 - acc: 0.7122\n",
      "Epoch 87/150\n",
      " - 0s - loss: 0.5475 - acc: 0.7292\n",
      "Epoch 88/150\n",
      " - 0s - loss: 0.5457 - acc: 0.7227\n",
      "Epoch 89/150\n",
      " - 0s - loss: 0.5564 - acc: 0.7201\n",
      "Epoch 90/150\n",
      " - 0s - loss: 0.5455 - acc: 0.7174\n",
      "Epoch 91/150\n",
      " - 0s - loss: 0.5456 - acc: 0.7122\n",
      "Epoch 92/150\n",
      " - 0s - loss: 0.5439 - acc: 0.7148\n",
      "Epoch 93/150\n",
      " - 0s - loss: 0.5410 - acc: 0.7109\n",
      "Epoch 94/150\n",
      " - 0s - loss: 0.5434 - acc: 0.7253\n",
      "Epoch 95/150\n",
      " - 0s - loss: 0.5402 - acc: 0.7201\n",
      "Epoch 96/150\n",
      " - 0s - loss: 0.5419 - acc: 0.7331\n",
      "Epoch 97/150\n",
      " - 0s - loss: 0.5437 - acc: 0.7174\n",
      "Epoch 98/150\n",
      " - 0s - loss: 0.5377 - acc: 0.7279\n",
      "Epoch 99/150\n",
      " - 0s - loss: 0.5332 - acc: 0.7370\n",
      "Epoch 100/150\n",
      " - 0s - loss: 0.5389 - acc: 0.7279\n",
      "Epoch 101/150\n",
      " - 0s - loss: 0.5333 - acc: 0.7292\n",
      "Epoch 102/150\n",
      " - 0s - loss: 0.5370 - acc: 0.7292\n",
      "Epoch 103/150\n",
      " - 0s - loss: 0.5440 - acc: 0.7253\n",
      "Epoch 104/150\n",
      " - 0s - loss: 0.5433 - acc: 0.7305\n",
      "Epoch 105/150\n",
      " - 0s - loss: 0.5338 - acc: 0.7227\n",
      "Epoch 106/150\n",
      " - 0s - loss: 0.5311 - acc: 0.7201\n",
      "Epoch 107/150\n",
      " - 0s - loss: 0.5404 - acc: 0.7331\n",
      "Epoch 108/150\n",
      " - 0s - loss: 0.5332 - acc: 0.7253\n",
      "Epoch 109/150\n",
      " - 0s - loss: 0.5304 - acc: 0.7318\n",
      "Epoch 110/150\n",
      " - 0s - loss: 0.5285 - acc: 0.7396\n",
      "Epoch 111/150\n",
      " - 0s - loss: 0.5288 - acc: 0.7279\n",
      "Epoch 112/150\n",
      " - 0s - loss: 0.5267 - acc: 0.7174\n",
      "Epoch 113/150\n",
      " - 0s - loss: 0.5289 - acc: 0.7370\n",
      "Epoch 114/150\n",
      " - 0s - loss: 0.5312 - acc: 0.7279\n",
      "Epoch 115/150\n",
      " - 0s - loss: 0.5219 - acc: 0.7318\n",
      "Epoch 116/150\n",
      " - 0s - loss: 0.5277 - acc: 0.7448\n",
      "Epoch 117/150\n",
      " - 0s - loss: 0.5252 - acc: 0.7305\n",
      "Epoch 118/150\n",
      " - 0s - loss: 0.5274 - acc: 0.7318\n",
      "Epoch 119/150\n",
      " - 0s - loss: 0.5223 - acc: 0.7383\n",
      "Epoch 120/150\n",
      " - 0s - loss: 0.5191 - acc: 0.7383\n",
      "Epoch 121/150\n",
      " - 0s - loss: 0.5198 - acc: 0.7500\n",
      "Epoch 122/150\n",
      " - 0s - loss: 0.5285 - acc: 0.7383\n",
      "Epoch 123/150\n",
      " - 0s - loss: 0.5176 - acc: 0.7279\n",
      "Epoch 124/150\n",
      " - 0s - loss: 0.5127 - acc: 0.7422\n",
      "Epoch 125/150\n",
      " - 0s - loss: 0.5148 - acc: 0.7396\n",
      "Epoch 126/150\n",
      " - 0s - loss: 0.5176 - acc: 0.7292\n",
      "Epoch 127/150\n",
      " - 0s - loss: 0.5199 - acc: 0.7383\n",
      "Epoch 128/150\n",
      " - 0s - loss: 0.5070 - acc: 0.7513\n",
      "Epoch 129/150\n",
      " - 0s - loss: 0.5264 - acc: 0.7318\n",
      "Epoch 130/150\n",
      " - 0s - loss: 0.5081 - acc: 0.7448\n",
      "Epoch 131/150\n",
      " - 0s - loss: 0.5104 - acc: 0.7513\n",
      "Epoch 132/150\n",
      " - 0s - loss: 0.5043 - acc: 0.7539\n",
      "Epoch 133/150\n",
      " - 0s - loss: 0.5114 - acc: 0.7487\n",
      "Epoch 134/150\n",
      " - 0s - loss: 0.5052 - acc: 0.7617\n",
      "Epoch 135/150\n",
      " - 0s - loss: 0.5046 - acc: 0.7487\n",
      "Epoch 136/150\n",
      " - 0s - loss: 0.5070 - acc: 0.7448\n",
      "Epoch 137/150\n",
      " - 0s - loss: 0.5110 - acc: 0.7617\n",
      "Epoch 138/150\n",
      " - 0s - loss: 0.5098 - acc: 0.7513\n",
      "Epoch 139/150\n",
      " - 0s - loss: 0.4929 - acc: 0.7656\n",
      "Epoch 140/150\n",
      " - 0s - loss: 0.4974 - acc: 0.7656\n",
      "Epoch 141/150\n",
      " - 0s - loss: 0.4975 - acc: 0.7565\n",
      "Epoch 142/150\n",
      " - 0s - loss: 0.4997 - acc: 0.7617\n",
      "Epoch 143/150\n",
      " - 0s - loss: 0.4945 - acc: 0.7461\n",
      "Epoch 144/150\n",
      " - 0s - loss: 0.5001 - acc: 0.7630\n",
      "Epoch 145/150\n",
      " - 0s - loss: 0.4992 - acc: 0.7617\n",
      "Epoch 146/150\n",
      " - 0s - loss: 0.5023 - acc: 0.7552\n",
      "Epoch 147/150\n",
      " - 0s - loss: 0.4898 - acc: 0.7708\n",
      "Epoch 148/150\n",
      " - 0s - loss: 0.4966 - acc: 0.7734\n",
      "Epoch 149/150\n",
      " - 0s - loss: 0.4840 - acc: 0.7695\n",
      "Epoch 150/150\n",
      " - 0s - loss: 0.4881 - acc: 0.7578\n",
      "[1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Create first network with Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10,  verbose=2)\n",
    "# calculate predictions\n",
    "predictions = model.predict(X)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras에 tensorflow backend를 사용할 때, 기본적으로 gpu를 사용하여 돌아갑니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6457724511532199144\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10429723444\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 11982981407610676249\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10907251508\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 2822181352619408609\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 835us/step - loss: 3.7048 - acc: 0.5977\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.9408 - acc: 0.5885\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.7518 - acc: 0.6432\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.7113 - acc: 0.6628\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.6812 - acc: 0.6758\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.6503 - acc: 0.6810\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.6493 - acc: 0.6719\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.6366 - acc: 0.6849\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.6242 - acc: 0.6914\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.6297 - acc: 0.6784\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.6476 - acc: 0.6706\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.6398 - acc: 0.6784\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.6258 - acc: 0.6810\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.6191 - acc: 0.6953\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.6027 - acc: 0.6914\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 320us/step - loss: 0.5879 - acc: 0.7018\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.5854 - acc: 0.7005\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.6012 - acc: 0.6849\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 315us/step - loss: 0.5806 - acc: 0.7109\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 307us/step - loss: 0.5798 - acc: 0.7174\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.5687 - acc: 0.7161\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.5818 - acc: 0.6966\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.5734 - acc: 0.7083\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.5679 - acc: 0.7305\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.5577 - acc: 0.7344\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.5702 - acc: 0.7044\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 316us/step - loss: 0.5556 - acc: 0.7240\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.5558 - acc: 0.7292\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.5739 - acc: 0.7135\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.5607 - acc: 0.7214\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.5685 - acc: 0.7161\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.5636 - acc: 0.7148\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.5520 - acc: 0.7201\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5492 - acc: 0.7318\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.5507 - acc: 0.7201\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.5610 - acc: 0.7083\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 348us/step - loss: 0.5349 - acc: 0.7383\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.5405 - acc: 0.7227\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.5451 - acc: 0.7253\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.5445 - acc: 0.7214\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5435 - acc: 0.7357\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 289us/step - loss: 0.5381 - acc: 0.7409\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 276us/step - loss: 0.5311 - acc: 0.7526\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.5333 - acc: 0.7422\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.5314 - acc: 0.7539\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5276 - acc: 0.7539\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5320 - acc: 0.7357\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.5330 - acc: 0.7396\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 316us/step - loss: 0.5324 - acc: 0.7500\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.5264 - acc: 0.7383\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.5281 - acc: 0.7500\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.5304 - acc: 0.7474\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.5387 - acc: 0.7422\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.5372 - acc: 0.7240\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.5220 - acc: 0.7513\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.5277 - acc: 0.7422\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.5307 - acc: 0.7357\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.5225 - acc: 0.7526\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.5119 - acc: 0.7630\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.5334 - acc: 0.7318\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.5276 - acc: 0.7409\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.5169 - acc: 0.7604\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.5419 - acc: 0.7305\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.5312 - acc: 0.7422\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.5197 - acc: 0.7487\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.5056 - acc: 0.7539\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.5151 - acc: 0.7409\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 289us/step - loss: 0.5128 - acc: 0.7539\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.5132 - acc: 0.7487\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.5375 - acc: 0.7266\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.5176 - acc: 0.7383\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5160 - acc: 0.7500\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5165 - acc: 0.7448\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5101 - acc: 0.7630\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.5092 - acc: 0.7591\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5103 - acc: 0.7578\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.5161 - acc: 0.7630\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.5129 - acc: 0.7552\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.5135 - acc: 0.7513\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.5096 - acc: 0.7617\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.5051 - acc: 0.7708\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5042 - acc: 0.7578\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.4994 - acc: 0.7643\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.4968 - acc: 0.7643\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.5048 - acc: 0.7487\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 307us/step - loss: 0.5051 - acc: 0.7552\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.4988 - acc: 0.7591\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.4994 - acc: 0.7669\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5037 - acc: 0.7773\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.5094 - acc: 0.7513\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.5024 - acc: 0.7578\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.5058 - acc: 0.7500\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.4993 - acc: 0.7656\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.4970 - acc: 0.7708\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.5033 - acc: 0.7500\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.4907 - acc: 0.7760\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.5002 - acc: 0.7721\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 333us/step - loss: 0.4902 - acc: 0.7669\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.4902 - acc: 0.7669\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.4838 - acc: 0.7812\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.4893 - acc: 0.7747\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.4985 - acc: 0.7630\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 278us/step - loss: 0.4991 - acc: 0.7591\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.4923 - acc: 0.7930\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.5294 - acc: 0.7500\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.4903 - acc: 0.7826\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4905 - acc: 0.7721\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.4968 - acc: 0.7747\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.4874 - acc: 0.7669\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4909 - acc: 0.7682\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.4842 - acc: 0.7826\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.4937 - acc: 0.7799\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.4954 - acc: 0.7578\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.4913 - acc: 0.7617\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4902 - acc: 0.7773\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.4936 - acc: 0.7747\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.4904 - acc: 0.7604\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.4874 - acc: 0.7852\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 316us/step - loss: 0.4819 - acc: 0.7682\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.4940 - acc: 0.7786\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.4912 - acc: 0.7799\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 315us/step - loss: 0.4861 - acc: 0.7734\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.4836 - acc: 0.7669\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.4836 - acc: 0.7721\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.4865 - acc: 0.7760\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.4795 - acc: 0.7786\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.4882 - acc: 0.7721\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.4724 - acc: 0.7786\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 359us/step - loss: 0.4809 - acc: 0.7773\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.4735 - acc: 0.7852\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.4823 - acc: 0.7682\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.4813 - acc: 0.7839\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.4829 - acc: 0.7695\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.4843 - acc: 0.7734\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.4769 - acc: 0.7773\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.4729 - acc: 0.7826\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.4674 - acc: 0.7826\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.4805 - acc: 0.7839\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.4643 - acc: 0.7917\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.4804 - acc: 0.7852\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.4725 - acc: 0.7839\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.4825 - acc: 0.7799\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.4753 - acc: 0.7721\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.4763 - acc: 0.7747\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.4867 - acc: 0.7682\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.4919 - acc: 0.7747\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 289us/step - loss: 0.4826 - acc: 0.7839\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.4699 - acc: 0.7786\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.4762 - acc: 0.7643\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.4753 - acc: 0.7812\n",
      "768/768 [==============================] - 0s 155us/step\n",
      "\n",
      "acc: 79.30%\n",
      "\n",
      "35.56289720535278\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "# Create your first MLP in Keras\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "with K.tf.device('/gpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X, Y, epochs=150, batch_size=10)\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "end = time.time()\n",
    "print()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "https://tykimos.github.io/2017/07/09/Early_Stopping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  app.launch_new_instance()\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " - 0s - loss: 0.6773 - acc: 0.6510\n",
      "Epoch 2/150\n",
      " - 0s - loss: 0.6592 - acc: 0.6510\n",
      "Epoch 3/150\n",
      " - 0s - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 4/150\n",
      " - 0s - loss: 0.6394 - acc: 0.6510\n",
      "Epoch 00004: early stopping\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Create first network with Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# calculate predictions\n",
    "from keras.callbacks import EarlyStopping\n",
    "stopper = EarlyStopping(monitor='acc', \n",
    "                        patience=3, \n",
    "                        verbose=1, \n",
    "                        min_delta=0.001)\n",
    "# Fit the model\n",
    "model.fit(X, Y, \n",
    "          epochs=150, \n",
    "          batch_size=10,  \n",
    "          verbose=2, \n",
    "          callbacks=[stopper])\n",
    "predictions = model.predict(X)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-be18f75a0c88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstopper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create first network with Keras\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "    model.add(Dense(8, init='uniform', activation='relu'))\n",
    "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# calculate predictions\n",
    "from keras.callbacks import EarlyStopping\n",
    "stopper = EarlyStopping(monitor='acc', \n",
    "                        patience=3, \n",
    "                        verbose=1, \n",
    "                        min_delta=0.001)\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Fit the model\n",
    "# model.fit(X, Y, \n",
    "#           epochs=150, \n",
    "#           batch_size=10,  \n",
    "#           verbose=2, \n",
    "#           callbacks=[stopper])\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=4)\n",
    "grid_result = grid.fit(X, Y, verbose=2, callbacks=[stopper])\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# predictions = model.predict(X)\n",
    "# # round predictions\n",
    "# rounded = [round(x[0]) for x in predictions]\n",
    "# print(rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Metric\n",
    "#### Early Stopping\n",
    "https://github.com/keras-team/keras/issues/10018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/link/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 4s - loss: 0.6745 - f1_metric: 0.0000e+00 - acc: 0.6680 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6568 - f1_metric: 0.0000e+00 - acc: 0.6680 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6499 - f1_metric: 0.0000e+00 - acc: 0.6680 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6470 - f1_metric: 0.0000e+00 - acc: 0.6680 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6376 - f1_metric: 0.0000e+00 - acc: 0.6680 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6318 - f1_metric: 0.0000e+00 - acc: 0.6680 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 00006: early stopping\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.6824 - f1_metric: 0.0000e+00 - acc: 0.6465 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6680 - f1_metric: 0.0000e+00 - acc: 0.6465 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6617 - f1_metric: 0.0000e+00 - acc: 0.6465 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6576 - f1_metric: 0.0286 - acc: 0.6523 - recall: 0.0228 - precision: 0.0391\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6493 - f1_metric: 0.0603 - acc: 0.6543 - recall: 0.0394 - precision: 0.1367\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6431 - f1_metric: 0.1934 - acc: 0.6465 - recall: 0.1625 - precision: 0.3021\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.6331 - f1_metric: 0.1452 - acc: 0.6582 - recall: 0.1094 - precision: 0.2917\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.6157 - f1_metric: 0.3401 - acc: 0.6953 - recall: 0.2920 - precision: 0.5192\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6177 - f1_metric: 0.3762 - acc: 0.6816 - recall: 0.3695 - precision: 0.5234\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6017 - f1_metric: 0.3496 - acc: 0.6719 - recall: 0.3167 - precision: 0.4665\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.6844 - f1_metric: 0.0260 - acc: 0.6328 - recall: 0.0312 - precision: 0.0238\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6688 - f1_metric: 0.0000e+00 - acc: 0.6387 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6618 - f1_metric: 0.0000e+00 - acc: 0.6387 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6549 - f1_metric: 0.0000e+00 - acc: 0.6387 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6420 - f1_metric: 0.0482 - acc: 0.6426 - recall: 0.0306 - precision: 0.1172\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6317 - f1_metric: 0.2090 - acc: 0.6602 - recall: 0.1657 - precision: 0.4040\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.6308 - f1_metric: 0.1926 - acc: 0.6504 - recall: 0.1611 - precision: 0.2913\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.6188 - f1_metric: 0.2251 - acc: 0.6543 - recall: 0.1775 - precision: 0.4105\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6146 - f1_metric: 0.2318 - acc: 0.6582 - recall: 0.1893 - precision: 0.3760\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6102 - f1_metric: 0.2478 - acc: 0.6602 - recall: 0.1929 - precision: 0.4281\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4dfbaa24a115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 197\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1307\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "def recall(y_true, y_pred):\n",
    "    K.set_epsilon(1e-05)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "def precision(y_true, y_pred):\n",
    "    K.set_epsilon(1e-05)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "def f1_metric(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# Create first network with Keras\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "    model.add(Dense(8, init='uniform', activation='relu'))\n",
    "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=[f1_metric, 'accuracy', recall, precision])\n",
    "    \n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# calculate predictions\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='f1_metric', mode='max', patience = 5, verbose=1)\n",
    "# stopper = EarlyStopping(monitor='f1_metric', \n",
    "#                         verbose=1,\n",
    "#                         mode='min')\n",
    "#                         patience=3, \n",
    "#                         verbose=1, \n",
    "#                         min_delta=0.001)\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Fit the model\n",
    "# model.fit(X, Y, \n",
    "#           epochs=150, \n",
    "#           batch_size=10,  \n",
    "#           verbose=2, \n",
    "#           callbacks=[stopper])\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X, Y, verbose=2, callbacks=[early_stop])\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "predictions = model.predict(X)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
