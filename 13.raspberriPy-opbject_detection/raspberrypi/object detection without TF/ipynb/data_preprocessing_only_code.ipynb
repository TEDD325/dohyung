{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.misc import imread\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import random\n",
    "import shutil \n",
    "from PIL import Image\n",
    "\n",
    "IMG_width = 320\n",
    "IMG_height = 240\n",
    "IMG_channel = 3\n",
    "DATASET_PATH = \"dataset_jpg\"\n",
    "DATASET_PATH_2 = \"dataset\"\n",
    "kinds = [\"train\", \"validation\", \"test\"]\n",
    "train_img = np.array([], dtype=\"float32\")\n",
    "train_label = np.array([], dtype=\"int8\")\n",
    "validation_img = np.array([], dtype=\"float32\")\n",
    "validation_label = np.array([], dtype=\"int8\")\n",
    "test_img = np.array([], dtype=\"float32\")\n",
    "test_label = np.array([], dtype=\"int8\")\n",
    "(label_train, filename_train) = (0,0)\n",
    "(label_validation, filename_validation) = (0,0)\n",
    "(label_test, filename_test) = (0,0)\n",
    "\n",
    "def display_image(image, label):\n",
    "    %matplotlib inline\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 5))\n",
    "    for i in range(5):\n",
    "        print(label[i])\n",
    "        img = image[i]\n",
    "        img = img.reshape(240, 320, 3)\n",
    "        img.shape = (240, 320, 3)\n",
    "        plt.subplot(150 + (i+1))\n",
    "        plt.imshow(img)\n",
    "\n",
    "def image_resoultion_and_change_to_JPG(kind, size_rate, dataset_path=DATASET_PATH_2):\n",
    "    filepath = file_info_2(kind, dataset_path)\n",
    "    idx = len(filepath)\n",
    "    for i in range(idx):\n",
    "        im = Image.open(\".\" + filepath[i] + '.png')\n",
    "        nx, ny = im.size\n",
    "        nx = nx*size_rate\n",
    "        ny = ny*size_rate\n",
    "        print(\"-----\")\n",
    "        print(\"{nx, ny} : \",{nx, ny})\n",
    "        im = im.resize((int(nx), int(ny)), Image.BICUBIC)\n",
    "        rgb_im = im.convert('RGB')\n",
    "        rgb_im.save('./' + dataset_path + '/' + kind + '/' + filepath[i].split(\"/\")[3][:-4] + '.jpg')\n",
    "        \n",
    "def change_to_grayscale(kind, dataset_path=DATASET_PATH_2):\n",
    "    filepath = file_info_2(kind, dataset_path)\n",
    "    idx = len(filepath)\n",
    "    for i in range(idx):\n",
    "        img = Image.open(\".\" + filepath[i] + '.png').convert('LA')\n",
    "        img.save(\"./dataset_gray/\" + kind+ \"/\" + filepath[i].split(\"/\")[3] + '.png')\n",
    "        \n",
    "        \n",
    "def file_info(category_name, dataset_path = DATASET_PATH): \n",
    "    # 디렉토리 상의 파일경로와 파일의 제일 앞에 매겨진 숫자정보(라벨 정보)를 긁어서 반환\n",
    "    full_path = './' + dataset_path + '/' + category_name + '/' + '*.jpg'\n",
    "    image_filenames = glob.glob(full_path)\n",
    "    filename = []\n",
    "    label = []\n",
    "    for image_filename in image_filenames:\n",
    "        filename.append(image_filename.split(\"/\")[3])\n",
    "        label.append(image_filename.split(\"/\")[3].split(\"-\")[0])\n",
    "    return (label, filename)\n",
    "\n",
    "def file_info_2(category_name, dataset_path=DATASET_PATH_2): \n",
    "    # 디렉토리 상의 파일경로와 파일의 제일 앞에 매겨진 숫자정보(라벨 정보)를 긁어서 반환\n",
    "    full_path = dataset_path + '/' + category_name + '/' + '*.png'\n",
    "    image_filenames = glob.glob(full_path)\n",
    "    filepath = []\n",
    "#     label = []\n",
    "    for image_filename in image_filenames:\n",
    "        filepath.append(image_filename.split(\".\")[1])\n",
    "#         label.append(image_filename.split(\"/\")[3].split(\"-\")[0])\n",
    "#     return (label, filename)\n",
    "    return filepath\n",
    "\n",
    "def data_processing_about_train(idx, kind):\n",
    "    for i in range(idx):\n",
    "        global train_img\n",
    "        global train_label\n",
    "        \n",
    "        (labels, filenames) = file_info(kind)\n",
    "        random_value = random.randrange(0, len(filenames))\n",
    "        filename = filenames[random_value]\n",
    "        label = labels[random_value]\n",
    "        \n",
    "        full_path = ('./' + DATASET_PATH + '/' + kind + '/' + filename)\n",
    "        image = imread(full_path)\n",
    "        image = image.reshape(IMG_width*IMG_height*IMG_channel)/255.0\n",
    "        train_img = np.append(train_img, image)\n",
    "        label = _change_one_hot_label(label)\n",
    "        train_label = np.append(train_label, label)\n",
    "        \n",
    "        # file move\n",
    "        # 학습한 데이터는 이동시킴\n",
    "        print(\"---------\")\n",
    "        print(len(filenames))\n",
    "        print(filename)\n",
    "        src = './' + DATASET_PATH + '/' + kind + '/'\n",
    "        dir = './' + DATASET_PATH + '/' + 'tmp' + '/' + kind + '/'\n",
    "        shutil.move(src + filename, dir + filename)\n",
    "\n",
    "def data_processing_about_validation(idx, kind):\n",
    "    for i in range(idx):\n",
    "        global validation_img\n",
    "        global validation_label\n",
    "        \n",
    "        (labels, filenames) = file_info(kind)\n",
    "        random_value = random.randrange(0, len(filenames))\n",
    "        filename = filenames[random_value]\n",
    "        label = labels[random_value]\n",
    "        \n",
    "        full_path = ('./' + DATASET_PATH + '/' + kind + '/' + filename)\n",
    "        image = imread(full_path)\n",
    "        image = image.reshape(IMG_width*IMG_height*IMG_channel)/255.0\n",
    "        validation_img = np.append(validation_img, image)\n",
    "        label = _change_one_hot_label(label)\n",
    "        validation_label = np.append(validation_label, label)\n",
    "        # file move\n",
    "        print(\"---------\")\n",
    "        print(len(filenames))\n",
    "        print(filename)\n",
    "        src = './' + DATASET_PATH + '/' + kind + '/'\n",
    "        dir = './' + DATASET_PATH + '/' + 'tmp' + '/' + kind + '/'\n",
    "        shutil.move(src + filename, dir + filename)\n",
    "\n",
    "def data_processing_about_test(idx, kind):\n",
    "    for i in range(idx):\n",
    "        global test_img\n",
    "        global test_label\n",
    "        \n",
    "        (labels, filenames) = file_info(kind)\n",
    "        random_value = random.randrange(0, len(filenames))\n",
    "        filename = filenames[random_value]\n",
    "        label = labels[random_value]\n",
    "        \n",
    "        full_path = ('./' + DATASET_PATH + '/' + kind + '/' + filename)\n",
    "        image = imread(full_path)\n",
    "        image = image.reshape(IMG_width*IMG_height*IMG_channel)/255.0\n",
    "        test_img = np.append(test_img, image)\n",
    "        label = _change_one_hot_label(label)\n",
    "        test_label = np.append(test_label, label)\n",
    "        # file move\n",
    "        print(\"---------\")\n",
    "        print(len(filenames))\n",
    "        print(filename)\n",
    "        src = './' + DATASET_PATH + '/' + kind + '/'\n",
    "        dir = './' + DATASET_PATH + '/' + 'tmp' + '/' + kind + '/'\n",
    "        shutil.move(src + filename, dir + filename)\n",
    "        \n",
    "        \n",
    "def _change_one_hot_label(target_label):\n",
    "    target_label = int(target_label)\n",
    "    T = np.zeros((1, 3))\n",
    "    T[0][target_label] = 1\n",
    "\n",
    "    return T\n",
    "\n",
    "\n",
    "def store_dataset(dataset_path = DATASET_PATH):\n",
    "    global train_img\n",
    "    global train_label\n",
    "    global validation_img\n",
    "    global validation_label\n",
    "    global test_img\n",
    "    global test_label\n",
    "    \n",
    "    (_, idx_train) = file_info(\"train\")\n",
    "    (_, idx_validation) = file_info(\"validation\")\n",
    "    (_, idx_test) = file_info(\"test\")\n",
    "    if len(idx_train)!=0 or len(idx_validation) != 0 or len(idx_test) != 0:\n",
    "        data_processing_about_train(len(idx_train), \"train\")\n",
    "        data_processing_about_validation(len(idx_validation), \"validation\")\n",
    "        data_processing_about_test(len(idx_test), \"test\")\n",
    "\n",
    "        #file로 쓰기\n",
    "        train_img.tofile('./' + dataset_path + '/' + 'train_img_dataset.txt')\n",
    "        train_label.tofile('./' + dataset_path + '/' + 'train_label.txt')\n",
    "        validation_img.tofile('./' + dataset_path + '/' + 'validation_img_dataset.txt')\n",
    "        validation_label.tofile('./' + dataset_path + '/' + 'validation_label.txt')\n",
    "        test_img.tofile('./' + dataset_path + '/' + 'test_img_dataset.txt')\n",
    "        test_label.tofile('./' + dataset_path + '/' + 'test_label.txt')\n",
    "\n",
    "    else : \n",
    "        print(\"[!] Already Finished Generateing Dataset. Please check directory.\")\n",
    "\n",
    "\n",
    "def load_dataset(dataset_path):\n",
    "    global train_img\n",
    "    global train_label\n",
    "    global validation_img\n",
    "    global validation_label\n",
    "    global test_img\n",
    "    global test_label\n",
    "    filenames = glob.glob(\"./\" + dataset_path + \"/\" + \"*.txt\")\n",
    "    filename = []\n",
    "    for filename in filenames:\n",
    "        print(filename, )\n",
    "    if filename.split(\"/\")[2][-4:] == \".txt\":\n",
    "        train_img = np.fromfile(open('./' + dataset_path + \"/\" + \"train_img_dataset.txt\", 'rb')).reshape(451,IMG_width*IMG_height*IMG_channel)\n",
    "        train_label = np.fromfile(open('./' + dataset_path + \"/\" + \"train_label.txt\", 'rb')).reshape(451,3)\n",
    "        validation_img = np.fromfile(open('./' + dataset_path + \"/\" + \"validation_img_dataset.txt\", 'rb')).reshape(65,IMG_width*IMG_height*IMG_channel)\n",
    "        validation_label = np.fromfile(open(dataset_path + \"/\" + \"validation_label.txt\", 'rb')).reshape(65,3)\n",
    "        test_img = np.fromfile(open('./' + dataset_path + \"/\" + \"test_img_dataset.txt\", 'rb')).reshape(130,IMG_width*IMG_height*IMG_channel)\n",
    "        test_label = np.fromfile(open('./' + dataset_path + \"/\" + \"test_label.txt\", 'rb')).reshape(130,3)\n",
    "    return ((train_img,train_label),(validation_img,validation_label),(test_img,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change_to_grayscale(\"train\", \"./dataset\")\n",
    "change_to_grayscale(\"validation\", \"./dataset\")\n",
    "change_to_grayscale(\"test\", \"./dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_resoultion_and_change_to_JPG(\"train\", 0.5, dataset_path=\"./dataset_gray\")\n",
    "image_resoultion_and_change_to_JPG(\"test\", 0.5, dataset_path=\"./dataset_gray\")\n",
    "image_resoultion_and_change_to_JPG(\"validation\", 0.5, dataset_path=\"./dataset_gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_dataset(\"imdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_validation, label_validation), (img_test, label_test) = load_dataset(\"imdata\")\n",
    "print(img_train.shape)\n",
    "print(label_train.shape)\n",
    "print(img_validation.shape)\n",
    "print(label_validation.shape)\n",
    "print(img_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display_image(img_train, label_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
