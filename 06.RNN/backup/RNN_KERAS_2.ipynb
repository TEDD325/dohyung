{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/link/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version: 2.2.2 backend: tensorflow\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import metrics\n",
    "from keras import losses\n",
    "from keras import __version__\n",
    "print('Using Keras version:', __version__, 'backend:', K.backend())\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report # https://stackoverflow.com/questions/50065484/getting-precision-recall-and-f1-score-per-class-in-keras\n",
    "\n",
    "from IPython.display import Javascript\n",
    "import numpy as np\n",
    "from distutils.version import LooseVersion as LV\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pprint\n",
    "#import boto3\n",
    "import pickle\n",
    "import time\n",
    "import os.path\n",
    "import pickle\n",
    "sys.path.append(os.getcwd())\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText # simple MSG\n",
    "from email.mime.multipart import MIMEMultipart # complex MSG\n",
    "        \n",
    "from link_aws_key import *\n",
    "from email_info import *\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "coins = {\n",
    "    0: 'KRW',\n",
    "    1: 'BTC',\n",
    "    2: 'ETH',\n",
    "    3: 'XRP',\n",
    "    4: 'BCH',\n",
    "    5: 'LTC',\n",
    "    6: 'DASH',\n",
    "    7: 'ETC'\n",
    "}\n",
    "\n",
    "# aws_client = boto3.client(\n",
    "#     's3',\n",
    "#     aws_access_key_id=LINK_AWSAccessKeyId,\n",
    "#     aws_secret_access_key=LINK_AWSSecretKey\n",
    "# )\n",
    "\n",
    "bucket = \"bithumb10\"\n",
    "cleanup_file_name = \"coin_{0}_{1}_cleanup.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_all_raw_data_from_aws(coin_name_list, start_date, end_date):\n",
    "    start_ms_time = datetime.strptime(start_date + \" +0900\", \"%Y-%m-%d %H:%M:%S %z\").timestamp() * 1000\n",
    "    end_ms_time = datetime.strptime(end_date + \" +0900\", \"%Y-%m-%d %H:%M:%S %z\").timestamp() * 1000\n",
    "    \n",
    "    year_temp = start_date[:4]\n",
    "    years = [year_temp]\n",
    "    while year_temp < end_date[:4]:\n",
    "        year_temp = str(int(start_date[:4]) + 1)\n",
    "        years.append(year_temp)\n",
    "    raw_data = {}  # 전체 CSV Raw 데이터\n",
    "    for coin_name in coin_name_list:\n",
    "        raw_data[coin_name] = []\n",
    "\n",
    "    # KRW 제외한 나머지 CSV Raw 데이터 수집\n",
    "    for coin_name in coin_name_list:\n",
    "        if coin_name == 'KRW':\n",
    "            continue\n",
    "        lines = []\n",
    "        for year in years:\n",
    "            obj = aws_client.get_object(\n",
    "                Bucket=bucket,\n",
    "                Key='cleanup/' + year + '/' + cleanup_file_name.format(coin_name, year)\n",
    "            )\n",
    "            if lines != []:\n",
    "                lines += obj.get('Body')._raw_stream.readlines()\n",
    "            else:\n",
    "                lines = obj.get('Body')._raw_stream.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            line = str(line.strip())[2:-1]\n",
    "            line = line.split(',')\n",
    "            if start_ms_time <= int(line[0]) and int(line[0]) <= end_ms_time:\n",
    "                raw_data[coin_name].append(line)\n",
    "\n",
    "    raw_data['KRW'] = list()\n",
    "    for line in raw_data['BTC']:\n",
    "        raw_data['KRW'].append([line[0], line[1], 1, 1, 1, 1, 1.0, 'normal'])\n",
    "\n",
    "    return raw_data\n",
    "\n",
    "def get_all_raw_data(coin_name_list, start_date, end_date, data_files_dir):\n",
    "    trading_files = []\n",
    "    for coin_name in coin_name_list:\n",
    "        for data_file_name in [f for f in listdir(data_files_dir) if isfile(join(data_files_dir, f))]:\n",
    "            if coin_name in data_file_name:\n",
    "                trading_files.append(data_file_name)\n",
    "\n",
    "    start_ms_time = datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\").timestamp() * 1000\n",
    "    end_ms_time = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\").timestamp() * 1000\n",
    "    \n",
    "    raw_data = {} #전체 CSV Raw 데이터\n",
    "    for coin_name in coin_name_list:\n",
    "        raw_data[coin_name] = []\n",
    "    \n",
    "    #KRW 제외한 나머지 CSV Raw 데이터 수집\n",
    "    for coin_name in coin_name_list:\n",
    "        for data_file_name in trading_files:\n",
    "            if coin_name in data_file_name:\n",
    "                file = open(data_files_dir + data_file_name, 'r', encoding='utf-8')\n",
    "                rdr = csv.reader(file)\n",
    "                for line in rdr:\n",
    "                    if start_ms_time <= int(line[0]) and int(line[0]) <= end_ms_time:\n",
    "                        raw_data[coin_name].append(line)\n",
    "                file.close()\n",
    "    \n",
    "    for line in raw_data['BTC']:\n",
    "        raw_data['KRW'].append([line[0], line[1], 1, 1, 1, 1, 1.0, 'normal'])\n",
    "#     print(\"test\")\n",
    "    return raw_data\n",
    "    \n",
    "def make_cryptocurrency_dataset_X(coin_name_list, start_date, end_date, time_unit, window_size, gap, margin_rate, data_files_dir):\n",
    "    num_coins = len(coin_name_list)\n",
    "    #raw_data = get_all_raw_data_from_aws(coin_name_list, start_date, end_date)\n",
    "    raw_data = get_all_raw_data(coin_name_list, start_date, end_date, data_files_dir)    \n",
    "    num_sticks = len(raw_data['BTC'])\n",
    "    \n",
    "    if time_unit % 10 != 0 or num_sticks < (time_unit / 10) * window_size + gap:\n",
    "        return None, None\n",
    "    \n",
    "    num = int(num_sticks - ((time_unit / 10) * window_size + gap) + 1)\n",
    "        \n",
    "    X = []\n",
    "    # (윈도우 개수, 코인 개수, 윈도우 사이즈, 3)\n",
    "    for idx in range(num):\n",
    "        X.append([])\n",
    "        idx_coin = 0\n",
    "        for coin_name in coin_name_list:\n",
    "            X[idx].append([])\n",
    "            \n",
    "            last_idx_in_window = int(idx + time_unit / 10 * window_size - 1)\n",
    "            close_price_in_last_idx_in_window = float(raw_data[coin_name][last_idx_in_window][3])\n",
    "            \n",
    "            for idx_in_window in range(window_size):\n",
    "                X[idx][idx_coin].append([])\n",
    "                idx_stick = int(idx + time_unit / 10 * (idx_in_window + 1) - 1)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][3]) / close_price_in_last_idx_in_window)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][4]) / close_price_in_last_idx_in_window)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][5]) / close_price_in_last_idx_in_window)\n",
    "                X[idx][idx_coin][idx_in_window].append(float(raw_data[coin_name][idx_stick][6]))\n",
    "                \n",
    "    X = np.array(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def make_cryptocurrency_dataset_y(coin_name_list, start_date, end_date, time_unit, window_size, gap, margin_rate, data_files_dir):\n",
    "    y_trv = []\n",
    "    y_btv = []\n",
    "    num_coins = len(coin_name_list)\n",
    "    #raw_data = get_all_raw_data_from_aws(coin_name_list, start_date, end_date)\n",
    "    raw_data = get_all_raw_data(coin_name_list, start_date, end_date, data_files_dir)    \n",
    "    num_sticks = len(raw_data['BTC'])\n",
    "    \n",
    "    if time_unit % 10 != 0 or num_sticks < (time_unit / 10) * window_size + gap:\n",
    "        return None, None\n",
    "    \n",
    "    num = int(num_sticks - ((time_unit / 10) * window_size + gap) + 1)\n",
    "        \n",
    "    \n",
    "    y = []\n",
    "    # (윈도우 개수, 코인 개수, 윈도우 사이즈, 3)\n",
    "    for idx in range(num):\n",
    "        \n",
    "        y.append([])\n",
    "        idx_coin = 0\n",
    "        for coin_name in coin_name_list:            \n",
    "            last_idx_in_window = int(idx + time_unit / 10 * window_size - 1)\n",
    "            close_price_in_last_idx_in_window = float(raw_data[coin_name][last_idx_in_window][3])\n",
    "            target_idx_for_window = int(idx + time_unit / 10 * window_size - 1 + gap)\n",
    "            target_price = float(raw_data[coin_name][target_idx_for_window][3])\n",
    "            target = 0\n",
    "            \n",
    "            if target_price >= close_price_in_last_idx_in_window * (1.0 + float(margin_rate) / 100.0):\n",
    "                target = 1\n",
    "            y[idx].append(target)\n",
    "            \n",
    "            idx_coin += 1\n",
    "           \n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def Load_Dataset_X(dir_path, time_unit, window_size, gap, margin_rate):\n",
    "    key_name_X = \"X_\" + \\\n",
    "                    str(time_unit) + \"_\" + \\\n",
    "                    str(window_size) + \"_\" + \\\n",
    "                    str(gap) + \"_\" + \\\n",
    "                    str(margin_rate)\n",
    "                    \n",
    "\n",
    "    with open(dir_path + key_name_X + \".pickle\", 'rb') as handle:\n",
    "        b_x = pickle.load(handle)\n",
    "    return b_x\n",
    "    \n",
    "def Load_Dataset_y(dir_path, time_unit, window_size, gap, margin_rate):\n",
    "    key_name_y = \"y_\" + \\\n",
    "                    str(time_unit) + \"_\" + \\\n",
    "                    str(window_size) + \"_\" + \\\n",
    "                    str(gap) + \"_\" + \\\n",
    "                    str(margin_rate)\n",
    "                    \n",
    "\n",
    "    with open(dir_path + key_name_y + \".pickle\", 'rb') as handle:\n",
    "        b_y = pickle.load(handle)\n",
    "    return b_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "data_files_dir = \"/Users/dohyung/OneDrive/2018-RNN/RNN_python/AWS_dataset/\"\n",
    "dataset_dir_path_tuple_type = \"./dataset_pickle_tuple_type/\"\n",
    "dataset_dir_path_numpy_type = \"./dataset_pickle_numpy.ndarray_type)/\"\n",
    "coin_list = [\"KRW\", \"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "start_date = \"2017-08-04 21:40:00\"\n",
    "end_date = \"2018-08-20 23:50:00\"\n",
    "# time_unit = [10,30,60]     # candle stick minutes\n",
    "# window_size = [10,25,50,75,100]  # Unit: num. of candle sticks\n",
    "# gap = [1,2,3]            # Unit: num. of candle sticks\n",
    "# margin_rate = [0.1,0.25,0.5]  # Unit: percent\n",
    "\n",
    "# for slave04\n",
    "#time_unit = [10,30,60]     # candle stick minutes\n",
    "#window_size = [10,25,50]  # Unit: num. of candle sticks\n",
    "#gap = [1,2,3]            # Unit: num. of candle sticks\n",
    "#margin_rate = [0.1,0.25,0.5]  # Unit: percent\n",
    "\n",
    "# for slave05\n",
    "# time_unit = [10,30,60]     # candle stick minutes\n",
    "# window_size = [75,100]  # Unit: num. of candle sticks\n",
    "# gap = [1,2,3]            # Unit: num. of candle sticks\n",
    "# margin_rate = [0.1,0.25,0.5]  # Unit: percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_reshape(X_train_data, X_test_data, n_steps, n_coins, n_price):\n",
    "    X_train_reshape = X_train_data.reshape(\n",
    "        -1, \n",
    "        n_steps, \n",
    "        n_coins * n_price\n",
    "    )\n",
    "    X_test_reshape = X_test_data.reshape(\n",
    "        -1, \n",
    "        n_steps, \n",
    "        n_coins * n_price\n",
    "    )\n",
    "    return X_train_reshape, X_test_reshape\n",
    "\n",
    "def onehottify(x, n=None, dtype=np.int):\n",
    "    \"\"\"1-hot encode x with the max value n (computed from data if n is None).\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    n = np.max(x) + 1 if n is None else n\n",
    "    return np.eye(n, dtype=dtype)[x]\n",
    "\n",
    "def Start_Model(pickle_load_dir_path, data_files_dir, epochs, pickle_result_dir_path, MODEL, idx_time_unit, idx_window_size, idx_gap, idx_margin_rate, _TEST, _ENHANCE, _GPU, n_jobs, machine, Internet_connection):\n",
    "    X = {}\n",
    "    y = {}\n",
    "\n",
    "    key_name_X = \"X_\"\n",
    "    key_name_y = \"y_\"\n",
    "\n",
    "    key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margin_rate)\n",
    "    key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margin_rate)\n",
    "\n",
    "    X = Load_Dataset_X(pickle_load_dir_path, idx_time_unit, idx_window_size, idx_gap, idx_margin_rate)\n",
    "    y = Load_Dataset_y(pickle_load_dir_path, idx_time_unit, idx_window_size, idx_gap, idx_margin_rate)\n",
    "\n",
    "    y_single = {}\n",
    "    y_single['BTC'] = y[:, 1]\n",
    "    y_single['ETH'] = y[:, 2]\n",
    "    y_single['XRP'] = y[:, 3]\n",
    "    y_single['BCH'] = y[:, 4]\n",
    "    y_single['LTC'] = y[:, 5]\n",
    "    y_single['DASH'] = y[:, 6]\n",
    "    y_single['ETC'] = y[:, 7]\n",
    "\n",
    "    coin_list2 = [\"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "\n",
    "    if (_TEST == False):\n",
    "        for coin in coin_list2:\n",
    "            if (os.path.isfile(pickle_result_dir_path + \\\n",
    "                              MODEL + \"_\" + \\\n",
    "                              coin + \"_\" + \\\n",
    "                              str(idx_time_unit) + \"_\" + \\\n",
    "                              str(idx_window_size) + \"_\" + \\\n",
    "                              str(idx_gap) + \"_\" + \\\n",
    "                              str(idx_margin_rate) + \\\n",
    "                              \"_result.pickle\")) is True:\n",
    "                print(MODEL + \"_\" + \\\n",
    "                      coin + \"_\" + \\\n",
    "                      str(idx_time_unit) + \"_\" + \\\n",
    "                      str(idx_window_size) + \"_\" + \\\n",
    "                      str(idx_gap) + \"_\" + \\\n",
    "                      str(idx_margin_rate) + \\\n",
    "                      \"_result.pickle FILE ALREADY EXIST.\")\n",
    "                continue\n",
    "            else:\n",
    "                y2 = onehottify(y_single[coin], n=2)\n",
    "\n",
    "                Evaluate(pickle_load_dir_path, \n",
    "                         data_files_dir, \n",
    "                         epochs, \n",
    "                         pickle_result_dir_path,\n",
    "                         _TEST, \n",
    "                         _ENHANCE,\n",
    "                         coin,\n",
    "                         X, y2,\n",
    "                         key_name_X,\n",
    "                         key_name_y,\n",
    "                         idx_time_unit,\n",
    "                         idx_window_size,\n",
    "                         idx_gap,\n",
    "                         idx_margin_rate, \n",
    "                         MODEL,\n",
    "                         _GPU,\n",
    "                         n_jobs,\n",
    "                         machine,\n",
    "                         Internet_connection)\n",
    "\n",
    "\n",
    "    if (_TEST == True):\n",
    "        # for test                                \n",
    "        for coin in range(1):\n",
    "            if (os.path.isfile(pickle_result_dir_path + \\\n",
    "                              \"_test_\" + \\\n",
    "                              MODEL + \"_\" + \\\n",
    "                              \"BTC\" + \"_\" + \\\n",
    "                              str(idx_time_unit) + \"_\" + \\\n",
    "                              str(idx_window_size) + \"_\" + \\\n",
    "                              str(idx_gap) + \"_\" + \\\n",
    "                              str(idx_margin_rate) + \\\n",
    "                              \"_result.pickle\")) is True:\n",
    "                print(\"_test_\" + \\\n",
    "                      MODEL + \"_\" + \\\n",
    "                      \"BTC\" + \"_\" + \\\n",
    "                      str(idx_time_unit) + \"_\" + \\\n",
    "                      str(idx_window_size) + \"_\" + \\\n",
    "                      str(idx_gap) + \"_\" + \\\n",
    "                      str(idx_margin_rate) + \\\n",
    "                      \"_result.pickle FILE ALREADY EXIST.\")\n",
    "                continue\n",
    "            else:\n",
    "                y2 = onehottify(y_single['BTC'], n=2)                          \n",
    "\n",
    "                Evaluate(pickle_load_dir_path, \n",
    "                         data_files_dir, \n",
    "                         epochs, \n",
    "                         pickle_result_dir_path, \n",
    "                         _TEST, \n",
    "                         _ENHANCE,\n",
    "                         coin,\n",
    "                         X, y2,\n",
    "                         key_name_X,\n",
    "                         key_name_y,\n",
    "                         idx_time_unit,\n",
    "                         idx_window_size,\n",
    "                         idx_gap,\n",
    "                         idx_margin_rate, \n",
    "                         MODEL,\n",
    "                         _GPU,\n",
    "                         n_jobs, \n",
    "                         machine,\n",
    "                         Internet_connection)\n",
    "    \n",
    "\n",
    "# 저장된 pickle 파일의 데이터 구조\n",
    "# tmp = {}\n",
    "# tmp[\"10_1_1_0.1\"] = {\"grid_result.best_score_\":{}}, {\"grid_result.best_params_\":{}}\n",
    "# type(tmp[\"10_1_1_0.1\"][0])\n",
    "# print(tmp[\"10_1_1_0.1\"])\n",
    "# print(tmp[\"10_1_1_0.1\"])\n",
    "# print(tmp[\"10_1_1_0.1\"][0])\n",
    "# print(tmp[\"10_1_1_0.1\"][0]['grid_result.best_score_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_RNN(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        RNN(  n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model_SimpleRNN(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        SimpleRNN(n_state_units, \n",
    "                  input_shape=(window_size, 32),\n",
    "                  use_bias=True, \n",
    "                  activation='tanh',\n",
    "                  kernel_initializer='glorot_uniform', \n",
    "                  recurrent_initializer='orthogonal', \n",
    "                  bias_initializer='zeros', \n",
    "                  dropout=0.0,\n",
    "                  recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model_LSTM(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        LSTM( n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_GRU(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        GRU(  n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_RNN_non_GPU(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        RNN(  n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_SimpleRNN_non_GPU(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        SimpleRNN(n_state_units, \n",
    "                  input_shape=(window_size, 32),\n",
    "                  use_bias=True, \n",
    "                  activation='tanh',\n",
    "                  kernel_initializer='glorot_uniform', \n",
    "                  recurrent_initializer='orthogonal', \n",
    "                  bias_initializer='zeros', \n",
    "                  dropout=0.0,\n",
    "                  recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model_LSTM_non_GPU(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        LSTM( n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_GRU_non_GPU(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        GRU(  n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(pickle_load_dir_path, \n",
    "             data_files_dir, \n",
    "             epochs, \n",
    "             pickle_result_dir_path,\n",
    "             _TEST, \n",
    "             _ENHANCE, \n",
    "             coin, \n",
    "             X, y2, \n",
    "             key_name_X,\n",
    "             key_name_y,\n",
    "             idx_time_unit,\n",
    "             idx_window_size,\n",
    "             idx_gap,\n",
    "             idx_margin_rate, \n",
    "             MODEL,\n",
    "             _GPU,\n",
    "             n_jobs, \n",
    "             machine,\n",
    "             Internet_connection):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.1, random_state=42)\n",
    "#     print(\"X_train.shape\")\n",
    "#     print(X_train.shape)\n",
    "#     print(\"y_train.shape\")\n",
    "#     print(y_train.shape)\n",
    "#     print()\n",
    "#     print(\"X_test.shape\")\n",
    "#     print(X_test.shape)\n",
    "#     print(\"y_test.shape\")\n",
    "#     print(y_test.shape)\n",
    "#     print()\n",
    "\n",
    "    n_coins = 8\n",
    "    n_price = 4\n",
    "    n_steps = idx_window_size # 원래 100이었음. reshape 문제 때문에 수정함\n",
    "\n",
    "    X_train_2 = X_train.transpose([0, 2, 1, 3])\n",
    "    X_test_2 = X_test.transpose([0, 2, 1, 3])\n",
    "#     print(\"X_train_2.shape\")\n",
    "#     print(X_train_2.shape)\n",
    "#     print(\"X_test_2.shape\")\n",
    "#     print(X_test_2.shape)\n",
    "#     print()\n",
    "\n",
    "    X_train_3 = X_train_2.reshape([X_train.shape[0], n_steps, n_coins * n_price])\n",
    "    X_test_3 = X_test_2.reshape([X_test.shape[0], n_steps, n_coins * n_price])\n",
    "#     print(\"X_train_3.shape\")\n",
    "#     print(X_train_3.shape)\n",
    "#     print(\"X_test_3.shape\")\n",
    "#     print(X_test_3.shape)\n",
    "#     print()\n",
    "\n",
    "    if (_TEST==True and _ENHANCE==False):\n",
    "        param_grid = {'window_size' : [n_steps], \n",
    "                      'n_state_units': [100],\n",
    "                      'activation': ['relu'], \n",
    "                      'optimizer': ['rmsprop'], #sgd 추가\n",
    "                      'init': ['glorot_uniform'], #he 추가\n",
    "                      'batch_size': [2048]}\n",
    "\n",
    "    elif (_TEST==False and _ENHANCE==False):\n",
    "        param_grid = {'window_size' : [n_steps], \n",
    "                      'n_state_units': [40, 80, 160],\n",
    "                      'activation': ['relu', 'softmax'], \n",
    "                      'optimizer': ['rmsprop', 'adam'], #sgd 추가\n",
    "                      'init': ['glorot_uniform', 'uniform', 'he_uniform'], #he 추가\n",
    "                      'batch_size': [64,128,256]}\n",
    "        \n",
    "    elif (_TEST==False and _ENHANCE==True):\n",
    "        param_grid = {'window_size' : [], \n",
    "                      'n_state_units': [],\n",
    "                      'activation': [], \n",
    "                      'optimizer': [], #sgd 추가\n",
    "                      'init': [], #he 추가\n",
    "                      'batch_size': [10, 50],\n",
    "                      'dropout_rate':[0.0, 0.1, 0.2, 0.3, 0.4, 0.5], # after paramter select. when epochs raise..\n",
    "                      'neurons':[2,10,100]}\n",
    "\n",
    "\n",
    "\n",
    "    X_train_reshape = X_train_2.reshape([X_train.shape[0], n_steps*n_coins * n_price])\n",
    "    X_test_reshape = X_test_2.reshape([X_test.shape[0], n_steps*n_coins * n_price])\n",
    "#     print(\"X_train_reshape.shape\")\n",
    "#     print(X_train_reshape.shape)\n",
    "#     print(\"X_test_reshape.shape\")\n",
    "#     print(X_test_reshape.shape)\n",
    "#     print()\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train_reshape)\n",
    "    X_train_scaled = scaler.transform(X_train_reshape)\n",
    "    X_test_scaled = scaler.transform(X_test_reshape)\n",
    "\n",
    "    X_train_scaled = X_train_scaled.reshape(-1, n_steps, n_coins * n_price)\n",
    "\n",
    "    X_test_scaled = X_test_scaled.reshape(-1, n_steps, n_coins * n_price)\n",
    "\n",
    "    if _GPU == True:\n",
    "        if MODEL == \"SimpleRNN\" :\n",
    "            model = KerasClassifier(build_fn=create_model_SimpleRNN, \n",
    "                                    epochs=epochs, \n",
    "#                                     batch_size=100, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"LSTM\":\n",
    "            model = KerasClassifier(build_fn=create_model_LSTM, \n",
    "                                    epochs=epochs, \n",
    "#                                     batch_size=100, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"RNN\":\n",
    "            model = KerasClassifier(build_fn=create_model_RNN, \n",
    "                                    epochs=epochs, \n",
    "#                                     batch_size=100, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"GRU\":\n",
    "            model = KerasClassifier(build_fn=create_model_GRU, \n",
    "                                    epochs=epochs, \n",
    "#                                     batch_size=100, \n",
    "                                    verbose=True)\n",
    "    elif _GPU == False:\n",
    "        if MODEL == \"SimpleRNN\" :\n",
    "            model = KerasClassifier(build_fn=create_model_SimpleRNN_non_GPU, \n",
    "                                    epochs=epochs, \n",
    "                                    batch_size=10, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"LSTM\":\n",
    "            model = KerasClassifier(build_fn=create_model_LSTM_non_GPU, \n",
    "                                    epochs=epochs, \n",
    "                                    batch_size=10, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"RNN\":\n",
    "            model = KerasClassifier(build_fn=create_model_RNN_non_GPU, \n",
    "                                    epochs=epochs, \n",
    "                                    batch_size=10, \n",
    "                                    verbose=True)\n",
    "\n",
    "        elif MODEL == \"GRU\":\n",
    "            model = KerasClassifier(build_fn=create_model_GRU_non_GPU, \n",
    "                                    epochs=epochs, \n",
    "                                    batch_size=10, \n",
    "                                    verbose=True)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model, \n",
    "        cv=5, \n",
    "        n_jobs=n_jobs, # test\n",
    "        param_grid=param_grid,\n",
    "        verbose=1)\n",
    "\n",
    "    X_train_scaled, X_test_scaled = input_reshape(X_train_scaled, X_test_scaled, n_steps, n_coins, n_price)\n",
    "    \n",
    "    if (_TEST == True): \n",
    "        print()\n",
    "        print()\n",
    "        print(\"TEST!\")\n",
    "        print()\n",
    "        print(\"----------------------\")\n",
    "        print(\"<\"+MODEL+\">\")\n",
    "        print(\"----------------------\")\n",
    "        print(\"__\"+\"BTC\"+\"__\" + \\\n",
    "                \"time unit: \"+str(idx_time_unit) + \"  |  \" + \\\n",
    "                \"window_size :\"+str(idx_window_size) + \"  |  \" + \\\n",
    "                \"gap :\"+str(idx_gap) + \"  |  \" + \\\n",
    "                \"margin_rate :\"+str(idx_margin_rate) + \\\n",
    "                \"  started.\")\n",
    "    elif (_TEST == False):\n",
    "        print()\n",
    "        print()\n",
    "        print(\"----------------------\")\n",
    "        print(\"<\"+MODEL+\">\")\n",
    "        print(\"----------------------\")\n",
    "        print(\"__\"+coin+\"__\" + \\\n",
    "                \"time unit: \"+str(idx_time_unit) + \"  |  \" + \\\n",
    "                \"window_size :\"+str(idx_window_size) + \"  |  \" + \\\n",
    "                \"gap :\"+str(idx_gap) + \"  |  \" + \\\n",
    "                \"margin_rate :\"+str(idx_margin_rate) + \\\n",
    "                \"  started.\")\n",
    "\n",
    "    grid_result = grid.fit(X_train_scaled, \n",
    "                           y_train, \n",
    "                           validation_data=(X_test_scaled,y_test))\n",
    "    \n",
    "    print(\"----------------------\")\n",
    "    print(\"grid_result.score(X_test_scaled, y_test): \",grid_result.score(X_test_scaled, y_test))\n",
    "    \n",
    "    evaluate_result = {}\n",
    "    \n",
    "    if (_TEST == True): \n",
    "        test_score = grid_result.score(X_test_scaled, y_test)\n",
    "        evaluate_result[MODEL + \"_\" + \\\n",
    "                      \"BTC\" + \"_\" + \\\n",
    "                      str(idx_time_unit) + \"_\" + \\\n",
    "                      str(idx_window_size) + \"_\" + \\\n",
    "                      str(idx_gap) + \"_\" + \\\n",
    "                      str(idx_margin_rate)] = {\"MODEL\":MODEL,\\\n",
    "                                        \"Cryptocurrency\":\"BTC\",\\\n",
    "#                                         \"grid_result.cv_results_\":grid_result.cv_results_, \\\n",
    "#                                         \"grid_result.best_estimator_\":grid_result.best_estimator_, \\\n",
    "                                        \"Score\":grid_result.cv_results_['mean_test_score'], \\\n",
    "                                        \"Params\":grid_result.cv_results_['params'],\\\n",
    "                                        \"test_score\":test_score}     \n",
    "                                        \n",
    "    elif (_TEST == False): \n",
    "        test_score = grid_result.score(X_test_scaled, y_test)\n",
    "        evaluate_result[MODEL + \"_\" + \\\n",
    "                      coin + \"_\" + \\\n",
    "                      str(idx_time_unit) + \"_\" + \\\n",
    "                      str(idx_window_size) + \"_\" + \\\n",
    "                      str(idx_gap) + \"_\" + \\\n",
    "                      str(idx_margin_rate)] = {\"MODEL\":MODEL,\\\n",
    "                                        \"Cryptocurrency\":coin, \\\n",
    "                                        \"Score\":grid_result.cv_results_['mean_test_score'], \\\n",
    "                                        \"Params\":grid_result.cv_results_['params'],\\\n",
    "                                        \"test_score\":test_score} \n",
    "#     print()\n",
    "#     print(\"evaluate result dict: \", evaluate_result)\n",
    "#     print()\n",
    "\n",
    "    # summarize results\n",
    "    print()\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    print()\n",
    "    # for checking pickle file exist\n",
    "    print(\"---pickle saving..\")\n",
    "    if (_TEST == True):\n",
    "        X = {}\n",
    "        y = {}\n",
    "        key_name_X = \"X_\"\n",
    "        key_name_y = \"y_\"\n",
    "        for idx_time_unit in time_unit:\n",
    "            for idx_window_size in window_size:\n",
    "                for idx_gap in gap:\n",
    "                    for idx_margin_rate in margin_rate:\n",
    "                        key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margin_rate)\n",
    "                        key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margin_rate)\n",
    "                        if (os.path.isfile(pickle_result_dir_path + \\\n",
    "                                          \"_test_\" + \\\n",
    "                                          MODEL + \"_\" + \\\n",
    "                                          \"BTC\" + \"_\" + \\\n",
    "                                          str(idx_time_unit) + \"_\" + \\\n",
    "                                          str(idx_window_size) + \"_\" + \\\n",
    "                                          str(idx_gap) + \"_\" + \\\n",
    "                                          str(idx_margin_rate) + \\\n",
    "                                          \"_result.pickle\")) is not True:\n",
    "                            with open(pickle_result_dir_path + \\\n",
    "                                      \"_test_\" + \\\n",
    "                                      MODEL + \"_\" + \\\n",
    "                                      \"BTC\" + \"_\" + \\\n",
    "                                      str(idx_time_unit) + \"_\" + \\\n",
    "                                      str(idx_window_size) + \"_\" + \\\n",
    "                                      str(idx_gap) + \"_\" + \\\n",
    "                                      str(idx_margin_rate) + \\\n",
    "                                      \"_result.pickle\", 'wb') as handle:\n",
    "                                pickle.dump(evaluate_result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                                \n",
    "                                # Sending Email\n",
    "                                if Internet_connection == True:\n",
    "                                    smtp = smtplib.SMTP('smtp.naver.com', 587)\n",
    "                                    smtp.ehlo()      # say Hello\n",
    "                                    smtp.starttls()  # TLS 사용시 필요\n",
    "                                    smtp.login(EMAIL_ADDRESS, EMAIL_PASSWORD)\n",
    "\n",
    "                                    msg = MIMEText(pickle_result_dir_path + \\\n",
    "                                                   \"_test_\" + \\\n",
    "                                                   MODEL + \"_\" + \\\n",
    "                                                   \"BTC\" + \"_\" + \\\n",
    "                                                   str(idx_time_unit) + \"_\" + \\\n",
    "                                                   str(idx_window_size) + \"_\" + \\\n",
    "                                                   str(idx_gap) + \"_\" + \\\n",
    "                                                   str(idx_margin_rate) + \\\n",
    "                                                   \"_result.pickle\")\n",
    "                                    msg['Subject'] =   pickle_result_dir_path + \\\n",
    "                                                       MODEL + \"_\" + \\\n",
    "                                                       \"BTC\" + \"_\" + \\\n",
    "                                                       str(idx_time_unit) + \"_\" + \\\n",
    "                                                       str(idx_window_size) + \"_\" + \\\n",
    "                                                       str(idx_gap) + \"_\" + \\\n",
    "                                                       str(idx_margin_rate) + \\\n",
    "                                                       \"_result.pickle\"\n",
    "                                    msg['To'] = EMAIL_ADDRESS\n",
    "                                    smtp.sendmail(EMAIL_ADDRESS, EMAIL_ADDRESS, msg.as_string())\n",
    "\n",
    "                                    smtp.quit()\n",
    "                        else:\n",
    "                            print(\"Already exist the file: \", pickle_result_dir_path + \\\n",
    "                                                              \"_test_\" + \\\n",
    "                                                              MODEL + \"_\" + \\\n",
    "                                                              \"BTC\" + \"_\" + \\\n",
    "                                                              str(idx_time_unit) + \"_\" + \\\n",
    "                                                              str(idx_window_size) + \"_\" + \\\n",
    "                                                              str(idx_gap) + \"_\" + \\\n",
    "                                                              str(idx_margin_rate) + \\\n",
    "                                                              \"_result.pickle\")\n",
    "\n",
    "    elif (_TEST == False): \n",
    "        X = {}\n",
    "        y = {}\n",
    "        key_name_X = \"X_\"\n",
    "        key_name_y = \"y_\"\n",
    "        \n",
    "        key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margin_rate)\n",
    "        key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margin_rate)\n",
    "        if (os.path.isfile(pickle_result_dir_path + \\\n",
    "                          MODEL + \"_\" + \\\n",
    "                          coin + \"_\" + \\\n",
    "                          str(idx_time_unit) + \"_\" + \\\n",
    "                          str(idx_window_size) + \"_\" + \\\n",
    "                          str(idx_gap) + \"_\" + \\\n",
    "                          str(idx_margin_rate) + \\\n",
    "                          \"_result.pickle\")) is not True:\n",
    "            with open(pickle_result_dir_path + \\\n",
    "                      MODEL + \"_\" + \\\n",
    "                      coin + \"_\" + \\\n",
    "                      str(idx_time_unit) + \"_\" + \\\n",
    "                      str(idx_window_size) + \"_\" + \\\n",
    "                      str(idx_gap) + \"_\" + \\\n",
    "                      str(idx_margin_rate) + \\\n",
    "                      \"_result.pickle\", 'wb') as handle:\n",
    "                pickle.dump(evaluate_result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                # Sending Email\n",
    "                if Internet_connection == True:\n",
    "                    smtp = smtplib.SMTP('smtp.naver.com', 587)\n",
    "                    smtp.ehlo()      # say Hello\n",
    "                    smtp.starttls()  # TLS 사용시 필요\n",
    "                    smtp.login(EMAIL_EMAIL_ADDRESS, EMAIL_PASSWORD)\n",
    "\n",
    "                    msg = MIMEText(machine + \\\n",
    "                                   pickle_result_dir_path + \\\n",
    "                                   MODEL + \"_\" + \\\n",
    "                                   coin + \"_\" + \\\n",
    "                                   str(idx_time_unit) + \"_\" + \\\n",
    "                                   str(idx_window_size) + \"_\" + \\\n",
    "                                   str(idx_gap) + \"_\" + \\\n",
    "                                   str(idx_margin_rate) + \\\n",
    "                                   \"_result.pickle\")\n",
    "                    msg['Subject'] =   machine + \\\n",
    "                                       pickle_result_dir_path + \\\n",
    "                                       MODEL + \"_\" + \\\n",
    "                                       coin + \"_\" + \\\n",
    "                                       str(idx_time_unit) + \"_\" + \\\n",
    "                                       str(idx_window_size) + \"_\" + \\\n",
    "                                       str(idx_gap) + \"_\" + \\\n",
    "                                       str(idx_margin_rate) + \\\n",
    "                                       \"_result.pickle\"\n",
    "                    msg['To'] = EMAIL_ADDRESS\n",
    "                    smtp.sendmail(EMAIL_ADDRESS, EMAIL_ADDRESS, msg.as_string())\n",
    "\n",
    "                    smtp.quit()\n",
    "        else:\n",
    "            print(\"Already exist the file: \", pickle_result_dir_path + \\\n",
    "                                              \"_test_\" + \\\n",
    "                                              MODEL + \"_\" + \\\n",
    "                                              \"BTC\" + \"_\" + \\\n",
    "                                              str(idx_time_unit) + \"_\" + \\\n",
    "                                              str(idx_window_size) + \"_\" + \\\n",
    "                                              str(idx_gap) + \"_\" + \\\n",
    "                                              str(idx_margin_rate) + \\\n",
    "                                              \"_result.pickle\")\n",
    "    \n",
    "    print()\n",
    "#     for mean, stdev, param in zip(means, stds, params):\n",
    "#         print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "#     print()\n",
    "    key_name_X = \"X_\"\n",
    "    key_name_y = \"y_\"\n",
    "    \n",
    "    \n",
    "#     return eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(machine, Internet_connection, _TEST, _GPU, n_jobs, MODEL, idx_time_unit, idx_window_size, idx_gap, idx_margin_rate, epochs):\n",
    "    '''\n",
    "        [ATTENTION] In create_model METHOD part, need to set appropriate about GPU\n",
    "        \n",
    "        LINK01 -> GPU OFF\n",
    "        MSI -> GPU OFF\n",
    "        SLAVE04 -> GPU ON\n",
    "        SLAVE05 -> GPU ON\n",
    "    ''' \n",
    "    \n",
    "    if machine==\"slave05\":\n",
    "        #time_unit = [10,30,60]     # candle stick minutes\n",
    "        #window_size = [25]  # Unit: num. of candle sticks\n",
    "        #gap = [1]            # Unit: num. of candle sticks\n",
    "        #margin_rate = [0.1]  # Unit: percent\n",
    "\n",
    "        start_time = time.time()\n",
    "        Start_Model( pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                     data_files_dir = dataset_dir_path_tuple_type, \n",
    "                     epochs=epochs, \n",
    "                     pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                     MODEL=MODEL, \n",
    "                    idx_time_unit=idx_time_unit,\n",
    "                    idx_window_size=idx_window_size, \n",
    "                    idx_gap=idx_gap, \n",
    "                    idx_margin_rate=idx_margin_rate, \n",
    "                     _TEST=False, \n",
    "                     _ENHANCE=False,\n",
    "                     _GPU=True,\n",
    "                     n_jobs=2,\n",
    "                     machine=machine, \n",
    "                     Internet_connection=Internet_connection)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')\n",
    "\n",
    "    elif machine==\"link-koreatech\":\n",
    "        #time_unit = [10]     # candle stick minutes\n",
    "        #window_size = [10,25,50]  # Unit: num. of candle sticks\n",
    "        #gap = [1]            # Unit: num. of candle sticks\n",
    "        #margin_rate = [0.1]  # Unit: percent\n",
    "\n",
    "        Start_Model( pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                     data_files_dir = dataset_dir_path_tuple_type, \n",
    "                     epochs=epochs, \n",
    "                     pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                     MODEL=MODEL, \n",
    "                    idx_time_unit=idx_time_unit,\n",
    "                    idx_window_size=idx_window_size, \n",
    "                    idx_gap=idx_gap, \n",
    "                    idx_margin_rate=idx_margin_rate,\n",
    "                     _TEST=False, \n",
    "                     _ENHANCE=False,\n",
    "                     _GPU=False,\n",
    "                     n_jobs=1,\n",
    "                     machine=machine, \n",
    "                     Internet_connection=Internet_connection)\n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')\n",
    "\n",
    "    elif machine==\"slave04\":\n",
    "        #time_unit = [10]     # candle stick minutes\n",
    "        #window_size = [75]  # Unit: num. of candle sticks\n",
    "        #gap = [1]            # Unit: num. of candle sticks\n",
    "        #margin_rate = [0.1]  # Unit: percent\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        Start_Model(pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                 data_files_dir = dataset_dir_path_tuple_type, \n",
    "                 epochs=epochs, \n",
    "                 pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                 MODEL=MODEL, \n",
    "                idx_time_unit=idx_time_unit,\n",
    "                idx_window_size=idx_window_size, \n",
    "                idx_gap=idx_gap, \n",
    "                idx_margin_rate=idx_margin_rate,\n",
    "                 _TEST=False, \n",
    "                 _ENHANCE=False,\n",
    "                 _GPU=True,\n",
    "                 n_jobs=2,\n",
    "                 machine=machine,\n",
    "                 Internet_connection=Internet_connection)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')\n",
    "\n",
    "    elif machine==\"link01\":\n",
    "        #time_unit = [10]     # candle stick minutes\n",
    "        #window_size = [25]  # Unit: num. of candle sticks\n",
    "        #gap = [1,2,3]            # Unit: num. of candle sticks\n",
    "        #margin_rate = [0.1]  # Unit: percent\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        Start_Model(pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                 data_files_dir = dataset_dir_path_tuple_type, \n",
    "                 epochs=epochs, \n",
    "                 pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                 MODEL=MODEL, \n",
    "                idx_time_unit=idx_time_unit,\n",
    "                idx_window_size=idx_window_size, \n",
    "                idx_gap=idx_gap, \n",
    "                idx_margin_rate=idx_margin_rate,\n",
    "                 _TEST=False,\n",
    "                 _ENHANCE=False,\n",
    "                 _GPU=False,\n",
    "                 n_jobs=1,\n",
    "                 machine=machine, \n",
    "                 Internet_connection=Internet_connection)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')\n",
    "\n",
    "    elif machine==\"MSI\":\n",
    "        #time_unit = [10]     # candle stick minutes\n",
    "        #window_size = [25]  # Unit: num. of candle sticks\n",
    "        #gap = [1]            # Unit: num. of candle sticks\n",
    "        #margin_rate = [0.1,0.25,0.5]  # Unit: percent\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        Start_Model(pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                 data_files_dir = dataset_dir_path_tuple_type, \n",
    "                 epochs=epochs, \n",
    "                 pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                 MODEL=MODEL, \n",
    "                idx_time_unit=idx_time_unit,\n",
    "                idx_window_size=idx_window_size, \n",
    "                idx_gap=idx_gap, \n",
    "                idx_margin_rate=idx_margin_rate,\n",
    "                 _TEST=False, \n",
    "                 _ENHANCE=False,\n",
    "                 _GPU=False,\n",
    "                 n_jobs=1,\n",
    "                 machine=machine, \n",
    "                 Internet_connection=Internet_connection)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')\n",
    "        \n",
    "    elif _TEST==True:\n",
    "        \n",
    "        #time_unit = [10]     # candle stick minutes\n",
    "        #window_size = [10]  # Unit: num. of candle sticks\n",
    "        #gap = [1]            # Unit: num. of candle sticks\n",
    "        #margin_rate = [0.1]  # Unit: percent\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        Start_Model(pickle_load_dir_path = \"./dataset_pickle_tuple_type/\",  \n",
    "                 data_files_dir = dataset_dir_path_tuple_type, \n",
    "                 epochs=epochs, \n",
    "                 pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                 MODEL=MODEL, \n",
    "                idx_time_unit=idx_time_unit,\n",
    "                idx_window_size=idx_window_size, \n",
    "                idx_gap=idx_gap, \n",
    "                idx_margin_rate=idx_margin_rate,\n",
    "                 _TEST=_TEST, \n",
    "                 _ENHANCE=False,\n",
    "                 _GPU=_GPU,\n",
    "                 n_jobs=1,\n",
    "                 machine=\"test\", \n",
    "                 Internet_connection=Internet_connection)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print()\n",
    "        print(\"TIME: \", end_time-start_time)\n",
    "        Javascript('IPython.notebook.kernel.restart()')\n",
    "        time.sleep(1)\n",
    "        Javascript('IPython.notebook.execute_all_cells()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load pickle file \n",
    "# import pickle\n",
    "# b_x = pickle.load(open(\"./evaluate_result/_test_SimpleRNN_BTC_10_10_1_0.1_result.pickle\", \"rb\"))\n",
    "# b_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Boost-up Acc, F1\n",
    "# evaluate_result_dir_path = \"./evaluate_result/acc_f1/\"\n",
    "# dataset_dir_path = dataset_dir_path_tuple_type \n",
    "# # dataset_dir_path = dataset_dir_path_numpy_type\n",
    "# epochs = 100\n",
    "# Evaluate(dataset_dir_path, data_files_dir, epochs, evaluate_result_dir_path, time_unit, window_size, gap, margin_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {}\n",
    "model_info[\"test\"] = {\"MODEL_list\":[\"SimpleRNN\", \"LSTM\", \"GRU\"],\n",
    "                      \"time_unit\":[10], \n",
    "                      \"window_size\":[10],\n",
    "                      \"gap\":[1], \n",
    "                      \"margin_rate\":[0.1]}\n",
    "model_info[\"slave05\"] = {\"MODEL_list\":[\"SimpleRNN\", \"LSTM\", \"GRU\"],\n",
    "                      \"time_unit\":[10,30,60], \n",
    "                      \"window_size\":[25],\n",
    "                      \"gap\":[1], \n",
    "                      \"margin_rate\":[0.1]}\n",
    "model_info[\"slave04\"] = {\"MODEL_list\":[\"SimpleRNN\", \"LSTM\", \"GRU\"],\n",
    "                      \"time_unit\":[10], \n",
    "                      \"window_size\":[10,50,75],\n",
    "                      \"gap\":[1], \n",
    "                      \"margin_rate\":[0.1]}\n",
    "model_info[\"link01\"] = {\"MODEL_list\":[\"SimpleRNN\", \"LSTM\", \"GRU\"],\n",
    "                      \"time_unit\":[10], \n",
    "                      \"window_size\":[25],\n",
    "                      \"gap\":[2,3], \n",
    "                      \"margin_rate\":[0.1]}\n",
    "model_info[\"link-koreatech\"] = {\"MODEL_list\":[\"SimpleRNN\", \"LSTM\", \"GRU\"],\n",
    "                      \"time_unit\":[10], \n",
    "                      \"window_size\":[25],\n",
    "                      \"gap\":[1], \n",
    "                      \"margin_rate\":[0.25,0.5]}\n",
    "\n",
    "model_info[\"MSI\"] = {\"MODEL_list\":[\"SimpleRNN\", \"LSTM\", \"GRU\"],\n",
    "                      \"time_unit\":[10], \n",
    "                      \"window_size\":[25],\n",
    "                      \"gap\":[1], \n",
    "                      \"margin_rate\":[0.1,0.25,0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNN_BTC_10_25_1_0.1_result.pickle FILE ALREADY EXIST.\n",
      "SimpleRNN_ETH_10_25_1_0.1_result.pickle FILE ALREADY EXIST.\n",
      "SimpleRNN_XRP_10_25_1_0.1_result.pickle FILE ALREADY EXIST.\n",
      "SimpleRNN_BCH_10_25_1_0.1_result.pickle FILE ALREADY EXIST.\n",
      "SimpleRNN_LTC_10_25_1_0.1_result.pickle FILE ALREADY EXIST.\n",
      "SimpleRNN_DASH_10_25_1_0.1_result.pickle FILE ALREADY EXIST.\n",
      "SimpleRNN_ETC_10_25_1_0.1_result.pickle FILE ALREADY EXIST.\n",
      "\n",
      "TIME:  0.2713916301727295\n",
      "SimpleRNN_BTC_30_25_1_0.1_result.pickle FILE ALREADY EXIST.\n",
      "SimpleRNN_ETH_30_25_1_0.1_result.pickle FILE ALREADY EXIST.\n",
      "SimpleRNN_XRP_30_25_1_0.1_result.pickle FILE ALREADY EXIST.\n",
      "\n",
      "\n",
      "----------------------\n",
      "<SimpleRNN>\n",
      "----------------------\n",
      "__BCH__time unit: 30  |  window_size :25  |  gap :1  |  margin_rate :0.1  started.\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 312us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 310us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 312us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 312us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 311us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 313us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 312us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 313us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 314us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 311us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 312us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 311us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 312us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 313us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 313us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 316us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 315us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 312us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 313us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 313us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 313us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 314us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 311us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 314us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 312us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 316us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 6.1649 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9373/9373 [==============================] - 2s 185us/step\n",
      "9372/9372 [==============================] - 2s 194us/step\n",
      "37488/37488 [==============================] - 7s 179us/step\n",
      "37489/37489 [==============================] - 6s 173us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "   64/37489 [..............................] - ETA: 2:54 - loss: 0.7116 - acc: 0.5156 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 1.4137 - acc: 0.3823 - f1_score: 5.2528e-05 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6701 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6670 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6656 - acc: 0.3821 - f1_score: 1.5288e-04 - val_loss: 0.6612 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6644 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6643 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6641 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6641 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6636 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6636 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6605 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6630 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6631 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6637 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6245 - val_f1_score: 0.6668\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6632 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6629 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6629 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6632 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6245 - val_f1_score: 0.6668\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6629 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6630 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6626 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6695 - val_acc: 0.3799 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6629 - acc: 0.6193 - f1_score: 0.6668 - val_loss: 0.6604 - val_acc: 0.6242 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6624 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6793 - val_acc: 0.4029 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6625 - acc: 0.6198 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6626 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6601 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6626 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6623 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6622 - acc: 0.6201 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6242 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6619 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6618 - acc: 0.6192 - f1_score: 0.6668 - val_loss: 0.6606 - val_acc: 0.6242 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6617 - acc: 0.3799 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6621 - acc: 0.6203 - f1_score: 0.6667 - val_loss: 0.6761 - val_acc: 0.6130 - val_f1_score: 0.6664\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6617 - acc: 0.3794 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6619 - acc: 0.6200 - f1_score: 0.6668 - val_loss: 0.6617 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6615 - acc: 0.3799 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6621 - acc: 0.6199 - f1_score: 0.6668 - val_loss: 0.6620 - val_acc: 0.6234 - val_f1_score: 0.6666\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6614 - acc: 0.3801 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6616 - acc: 0.6198 - f1_score: 0.6668 - val_loss: 0.6607 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 2s 177us/step\n",
      "9372/9372 [==============================] - 2s 184us/step\n",
      "37489/37489 [==============================] - 7s 180us/step\n",
      "37489/37489 [==============================] - 7s 175us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      " 1088/37489 [..............................] - ETA: 20s - loss: 0.7293 - acc: 0.4513 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6691 - acc: 0.3847 - f1_score: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 331us/step - loss: 0.6680 - acc: 0.3837 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 311us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 0.6651 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 0.6647 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 312us/step - loss: 0.6647 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 0.6644 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6642 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 0.6646 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6642 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 316us/step - loss: 0.6640 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 312us/step - loss: 0.6639 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 314us/step - loss: 0.6637 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6638 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6656 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 0.6636 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 313us/step - loss: 0.6632 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6664 - val_acc: 0.3791 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6636 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 313us/step - loss: 0.6633 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 0.6633 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6631 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 0.6631 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6605 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6629 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 0.6634 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6627 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6625 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6626 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6625 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6628 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6711 - val_acc: 0.3789 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6624 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6604 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6630 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6638 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 0.6623 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6631 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6622 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6624 - acc: 0.3819 - f1_score: 1.0426e-04 - val_loss: 0.6637 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6620 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 1.0426e-04 - val_loss: 0.6609 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6622 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6640 - acc: 0.3813 - f1_score: 1.0346e-04 - val_loss: 0.6637 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 189us/steposs: 0.6628 - acc: 0.3815 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6621 - acc: 0.3801 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 194us/step\n",
      "37489/37489 [==============================] - 7s 182us/step\n",
      "32576/37488 [=========================>....] - ETA: 0sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 149us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6080/37489 [===>..........................] - ETA: 10s - loss: 7.5660 - acc: 0.3824 - f1_score: 0.3811Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 6.3928 - acc: 0.3825 - f1_score: 0.3816 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 1.3090 - acc: 0.6018 - f1_score: 0.6410 - val_loss: 0.6631 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6649 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6646 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6647 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6647 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6648 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6642 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6639 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6642 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6642 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6641 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6636 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6634 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6632 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6639 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6641 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6636 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1658 - acc: 0.3825 - f1_score: 0.3817 - val_loss: 6.0547 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "9372/9372 [==============================] - 2s 184us/steposs: 0.6633 - acc: 0.6186 - f1_score: \n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6635 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 194us/step\n",
      "37489/37489 [==============================] - 7s 185us/step\n",
      "37489/37489 [==============================] - 6s 155us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      " 4160/37489 [==>...........................] - ETA: 11s - loss: 0.6695 - acc: 0.3815 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6664 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 341us/step - loss: 0.6670 - acc: 0.3833 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6651 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6658 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6661 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6643 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6649 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6639 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6648 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6640 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6649 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6637 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6643 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6635 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6641 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6634 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6639 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6632 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6638 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6634 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6636 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6629 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6635 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6630 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6637 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6624 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6635 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6620 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6678 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6632 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6622 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6651 - val_acc: 0.3785 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6628 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6659 - val_acc: 0.3803 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6622 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6631 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6619 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6629 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6619 - acc: 0.3798 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 178us/steposs: 0.6625 - acc: 0.3818 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6625 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 186us/step\n",
      "37489/37489 [==============================] - 7s 183us/step\n",
      "35584/37489 [===========================>..] - ETA: 0sTrain on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 165us/step\n",
      " 5440/37488 [===>..........................] - ETA: 10s - loss: 1.5050 - acc: 0.5991 - f1_score: 0.6392Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 0.7889 - acc: 0.6143 - f1_score: 0.6627 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 13s 340us/step - loss: 0.8894 - acc: 0.6114 - f1_score: 0.6597 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 313us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6661 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 314us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 314us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "30912/37489 [=======================>......] - ETA: 1s - loss: 0.6653 - acc: 0.6184 - f1_score: 0.6667Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 315us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6654 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 316us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 313us/step - loss: 0.6649 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6688 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 315us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6649 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 0.6642 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 0.6642 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6644 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6637 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6644 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6635 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6658 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6641 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 0.6636 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6603 - val_acc: 0.6234 - val_f1_score: 0.6665\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6641 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 315us/step - loss: 0.6634 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6639 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 0.6633 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6602 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6640 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6631 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6704 - val_acc: 0.6220 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6637 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6633 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6635 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6627 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6636 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6634 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6634 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6631 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 2s 183us/steposs: 0.6637 - acc: 0.6173 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6635 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 196us/step\n",
      "37488/37488 [==============================] - 7s 184us/step\n",
      "35328/37489 [===========================>..] - ETA: 0sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 158us/step\n",
      " 4672/37489 [==>...........................] - ETA: 12s - loss: 0.6825 - acc: 0.3776 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6689 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 344us/step - loss: 9.3395 - acc: 0.3816 - f1_score: 0.3809 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6650 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6649 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6643 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6640 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6650 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6639 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6605 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6640 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6642 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6638 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6636 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6631 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6633 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6632 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6602 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6630 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.3747 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6626 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6626 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6602 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6627 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6602 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6625 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.3749 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 189us/steposs: 9.9520 - acc: 0.3820 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.9622 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 192us/step\n",
      "37489/37489 [==============================] - 7s 185us/step\n",
      "32960/37489 [=========================>....] - ETA: 0sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 156us/step\n",
      " 7104/37489 [====>.........................] - ETA: 10s - loss: 9.6826 - acc: 0.6147 - f1_score: 0.6154Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.8494 - acc: 0.6174 - f1_score: 0.6175 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 350us/step - loss: 0.6664 - acc: 0.6179 - f1_score: 0.6666 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6652 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 0.6645 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6900 - acc: 0.6143 - f1_score: 0.6558 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6645 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6643 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6644 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6644 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6643 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6642 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6643 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6646 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6644 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6645 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6644 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6656 - acc: 0.6190 - f1_score: 0.6666 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.8646 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 9.9426 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 176us/steposs: 0.6648 - acc: 0.6177 - f1_score: 0.\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6641 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 2s 202us/step\n",
      "37489/37489 [==============================] - 7s 185us/step\n",
      "21184/37488 [===============>..............] - ETA: 2sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 152us/stepss: 0.7202 - acc: 0.5976 - f1_score: 0.66\n",
      "13248/37489 [=========>....................] - ETA: 7s - loss: 0.6892 - acc: 0.6110 - f1_score: 0.6651Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6749 - acc: 0.6139 - f1_score: 0.6661 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 348us/step - loss: 0.6743 - acc: 0.6143 - f1_score: 0.6661 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6655 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6650 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6653 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "22784/37489 [=================>............] - ETA: 4s - loss: 0.6644 - acc: 0.6192 - f1_score: 0.6667Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6650 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "22976/37489 [=================>............] - ETA: 4s - loss: 0.6656 - acc: 0.6176 - f1_score: 0.6667Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6654 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6649 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6646 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6648 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6645 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6648 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6645 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6646 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6644 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "17536/37489 [=============>................] - ETA: 5s - loss: 0.6619 - acc: 0.6230 - f1_score: 0.6667Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6645 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6643 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6650 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6648 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6670 - acc: 0.6182 - f1_score: 0.6658 - val_loss: 0.6632 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6646 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6644 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6746 - acc: 0.6184 - f1_score: 0.6646 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6646 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6649 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6644 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6645 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6641 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6645 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6643 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6646 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6643 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6647 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6666 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6647 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6643 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 196us/steposs: 0.6638 - acc: 0.6194 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6645 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 178us/step\n",
      "37489/37489 [==============================] - 7s 184us/step\n",
      "20672/37489 [===============>..............] - ETA: 2sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 153us/stepss: 9.8106 - acc: 0.6160 - f1_score: 0.\n",
      "13760/37489 [==========>...................] - ETA: 7s - loss: 9.7763 - acc: 0.6153 - f1_score: 0.4167Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4172 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 9.8865 - acc: 0.6174 - f1_score: 0.5255 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4170 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4170 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4171 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4170 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4170 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4169 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4173 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4171 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4174 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "17984/37489 [=============>................] - ETA: 5s - loss: 9.8910 - acc: 0.6196 - f1_score: 0.4192Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4174 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4173 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4172 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4172 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4171 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4172 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4173 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4172 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4169 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.8775 - acc: 0.6186 - f1_score: 0.4170 - val_loss: 9.9243 - val_acc: 0.6242 - val_f1_score: 0.4230\n",
      "9372/9372 [==============================] - 2s 191us/steposs: 9.9434 - acc: 0.6169 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 176us/step\n",
      "37489/37489 [==============================] - 7s 185us/step\n",
      "25920/37489 [===================>..........] - ETA: 1sTrain on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 151us/stepss: 9.8629 - acc: 0.3732 - f1_score: 0.\n",
      "11456/37488 [========>.....................] - ETA: 8s - loss: 9.9580 - acc: 0.3790 - f1_score: 0.3766Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 9.9602 - acc: 0.3812 - f1_score: 0.3804 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 350us/step - loss: 9.9212 - acc: 0.3825 - f1_score: 0.3819 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 12s 316us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 315us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 316us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "22400/37489 [================>.............] - ETA: 4s - loss: 9.9580 - acc: 0.3809 - f1_score: 0.3809Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 317us/step - loss: 9.9749 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0541 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9373/9373 [==============================] - 2s 187us/steposs: 9.9036 - acc: 0.3847 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9381 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0417 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 191us/step\n",
      "37488/37488 [==============================] - 7s 186us/step\n",
      "20928/37489 [===============>..............] - ETA: 2sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 153us/stepss: 0.6849 - acc: 0.3917 - f1_score: 0.0000\n",
      "13632/37489 [=========>....................] - ETA: 7s - loss: 0.6743 - acc: 0.3858 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6686 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 0.6684 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 0.6655 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6655 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6654 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 0.6655 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6652 - acc: 0.4101 - f1_score: 0.0824 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6651 - acc: 0.6043 - f1_score: 0.6281 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6657 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6652 - acc: 0.5549 - f1_score: 0.4825 - val_loss: 0.6644 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6652 - acc: 0.3815 - f1_score: 3.8590e-04 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6655 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 1.9806e-04 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6651 - acc: 0.5469 - f1_score: 0.4687 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6653 - acc: 0.4491 - f1_score: 0.1907 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "20608/37489 [===============>..............] - ETA: 5s - loss: 0.6640 - acc: 0.6207 - f1_score: 0.6667Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6666 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6689 - acc: 0.5286 - f1_score: 0.4172 - val_loss: 0.6620 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6651 - acc: 0.5150 - f1_score: 0.3896 - val_loss: 0.6620 - val_acc: 0.3756 - val_f1_score: 0.0011\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6653 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6651 - acc: 0.3815 - f1_score: 8.2772e-04 - val_loss: 0.6620 - val_acc: 0.3755 - val_f1_score: 0.0015\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6666 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 2.0693e-04 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6657 - acc: 0.4152 - f1_score: 0.0993 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 193us/steposs: 0.6653 - acc: 0.3817 - f1_score: 7.1469\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 5.1732e-05 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 175us/step\n",
      "37489/37489 [==============================] - 7s 185us/step\n",
      "21120/37489 [===============>..............] - ETA: 2sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 153us/stepss: 9.6909 - acc: 0.6132 - f1_score: 0.\n",
      "13440/37489 [=========>....................] - ETA: 7s - loss: 9.9383 - acc: 0.6208 - f1_score: 0.6124Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9274 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 0.6755 - acc: 0.6182 - f1_score: 0.6666 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6653 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "21056/37488 [===============>..............] - ETA: 4s - loss: 0.6661 - acc: 0.6171 - f1_score: 0.6667Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6653 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6096 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6096 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6095 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6183\n",
      "9372/9372 [==============================] - 2s 181us/steposs: 0.6648 - acc: 0.6191 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "37489/37489 [==============================] - 7s 187us/step\n",
      "9373/9373 [==============================] - 1s 152us/step\n",
      "11392/37488 [========>.....................] - ETA: 3sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 155us/stepss: 2.2116 - acc: 0.5708 - f1_score: 0.59\n",
      "20864/37489 [===============>..............] - ETA: 5s - loss: 1.4522 - acc: 0.5958 - f1_score: 0.6304Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 1.1039 - acc: 0.6050 - f1_score: 0.6465 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 1.1863 - acc: 0.6033 - f1_score: 0.6439 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6660 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "14080/37489 [==========>...................] - ETA: 6s - loss: 0.6649 - acc: 0.6190 - f1_score: 0.6667Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6639 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6638 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "11584/37489 [========>.....................] - ETA: 7s - loss: 0.6640 - acc: 0.6209 - f1_score: 0.6667Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 185us/steposs: 0.6631 - acc: 0.6225 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "37489/37489 [==============================] - 7s 186us/step\n",
      "9372/9372 [==============================] - 1s 151us/step\n",
      " 5504/37489 [===>..........................] - ETA: 3sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 157us/steps: 0.7439 - acc: 0.6023 - f1_score: 0.66\n",
      "22016/37489 [================>.............] - ETA: 5s - loss: 0.7130 - acc: 0.6113 - f1_score: 0.6630Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6937 - acc: 0.6136 - f1_score: 0.6645 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6969 - acc: 0.6127 - f1_score: 0.6645 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6654 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6659 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6658 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6659 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6654 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6654 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6659 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6661 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6639 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6651 - acc: 0.6181 - f1_score: 0.6662 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 198us/steposs: 0.6637 - acc: 0.6217 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 186us/steps: 0.6655 - \n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 124us/step\n",
      " 4800/37489 [==>...........................] - ETA: 3sTrain on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 167us/steps: 0.7431 - acc: 0.6185 - f1_score: 0.\n",
      "24960/37488 [==================>...........] - ETA: 3s - loss: 0.7119 - acc: 0.6191 - f1_score: 0.6644Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6972 - acc: 0.6173 - f1_score: 0.6652 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.9941 - acc: 0.6071 - f1_score: 0.6556 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6648 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6653 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6649 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6679 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6638 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6646 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6635 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6642 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6238 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6632 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6662 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6641 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 0.6632 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6640 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6634 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6232 - val_f1_score: 0.6666\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6638 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6628 - acc: 0.6198 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6636 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6626 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6636 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6626 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6663 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6634 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6251 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 0.6624 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6631 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6621 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6647 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6633 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6621 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6656 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6629 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 318us/step - loss: 0.6633 - acc: 0.6196 - f1_score: 0.6666 - val_loss: 0.6668 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6630 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6696 - acc: 0.4171 - f1_score: 0.0946 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6627 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6654 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6627 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6625 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 180us/steposs: 0.6602 - acc: 0.6221 - f1_score: 0.\n",
      "37488/37488 [==============================] - 7s 187us/steps: 0.6627 - acc: 0.6177 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 12s 307us/step - loss: 0.6624 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6244 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 1s 138us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 168us/steps: 0.6661 - acc: 0.6197 - f1_score: 0.66\n",
      "28160/37489 [=====================>........] - ETA: 2s - loss: 0.6665 - acc: 0.6185 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6664 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6661 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6649 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6647 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6642 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6641 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6668 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6640 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6638 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6638 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6635 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6230 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6634 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6630 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6635 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6629 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6629 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6649 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6628 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6628 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6628 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6226 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6627 - acc: 0.6190 - f1_score: 0.6666 - val_loss: 0.6608 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6628 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6217 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6623 - acc: 0.6192 - f1_score: 0.6666 - val_loss: 0.6616 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6625 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6242 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6625 - acc: 0.6189 - f1_score: 0.6666 - val_loss: 0.6611 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6622 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6619 - acc: 0.6195 - f1_score: 0.6666 - val_loss: 0.6605 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6625 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6621 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6624 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6722 - val_acc: 0.6226 - val_f1_score: 0.6666\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6618 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6730 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6619 - acc: 0.6201 - f1_score: 0.6667 - val_loss: 0.6707 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6618 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6621 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6618 - acc: 0.6197 - f1_score: 0.6667 - val_loss: 0.6603 - val_acc: 0.6247 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6619 - acc: 0.6200 - f1_score: 0.6668 - val_loss: 0.6646 - val_acc: 0.6182 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6613 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 194us/steposs: 0.6609 - acc: 0.6214 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 189us/steps: 0.6614 - acc: 0.6197 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 11s 296us/step - loss: 0.6613 - acc: 0.6199 - f1_score: 0.6668 - val_loss: 0.6608 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "7104/9372 [=====================>........] - ETA: 0sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "9372/9372 [==============================] - 1s 135us/step\n",
      "37489/37489 [==============================] - 6s 173us/steps: 0.6983 - acc: 0.3820 - f1_score: 0.0000\n",
      "28288/37489 [=====================>........] - ETA: 2s - loss: 0.6876 - acc: 0.3833 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6824 - acc: 0.3833 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6846 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 312us/step - loss: 0.6659 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6647 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6649 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6641 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6648 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6643 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6643 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6605 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6640 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6641 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6643 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6640 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6642 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6638 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6636 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6639 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6636 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6633 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6638 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6633 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6632 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6634 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6631 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6634 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6636 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6632 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6628 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6632 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6624 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6629 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6626 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6604 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6628 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6624 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6625 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6621 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6602 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6625 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "9372/9372 [==============================] - 2s 200us/steploss: 0.6631 - acc: 0.3835 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 7s 190us/steps: 0.6619 - acc: 0.3805 - f1_score: 0.0000\n",
      "37184/37488 [============================>.] - ETA: 0s - loss: 0.6624 - acc: 0.3814 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 11s 288us/step - loss: 0.6622 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 1s 137us/step\n",
      "37488/37488 [==============================] - 7s 191us/steps: 9.3586 - acc: 0.3823 - f1_score: 0.32\n",
      "34944/37489 [==========================>...] - ETA: 0s - loss: 9.5355 - acc: 0.3825 - f1_score: 0.3392Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.5641 - acc: 0.3825 - f1_score: 0.3421 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6674 - acc: 0.6170 - f1_score: 0.6656 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6647 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6646 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6648 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6645 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6646 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6639 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6641 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6641 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6640 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6641 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6637 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6632 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6634 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6635 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6631 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9532 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6638 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "9372/9372 [==============================] - 2s 176us/steposs: 0.6629 - acc: 0.6169 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 191us/steps: 0.6626 - acc: 0.6196 - f1_score: 0.\n",
      "36160/37489 [===========================>..] - ETA: 0s - loss: 0.6629 - acc: 0.6190 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 289us/step - loss: 0.6629 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 146us/steploss: 10.3650 - acc: 0.3569 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 190us/steps: 7.0958 - acc: 0.3812 - f1_score: 0.37\n",
      "36352/37489 [============================>.] - ETA: 0s - loss: 6.8415 - acc: 0.3817 - f1_score: 0.3772Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.8154 - acc: 0.3814 - f1_score: 0.3770 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 2.3342 - acc: 0.5739 - f1_score: 0.6144 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3759 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6650 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3759 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6649 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3759 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6645 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6647 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6644 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6644 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3759 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6644 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3759 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6640 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6636 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6228 - val_f1_score: 0.6666\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3759 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6635 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6213 - val_f1_score: 0.6665\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6632 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6629 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6682 - val_acc: 0.6211 - val_f1_score: 0.6665\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6633 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6242 - val_f1_score: 0.6665\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6633 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6236 - val_f1_score: 0.6665\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3760 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3702\n",
      "9372/9372 [==============================] - 2s 182us/steposs: 0.6628 - acc: 0.617\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6629 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6228 - val_f1_score: 0.6666\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 187us/steps: 0.6643 - acc: 0.6144 - f1_score: 0.66\n",
      "31936/37489 [========================>.....] - ETA: 1s - loss: 0.6640 - acc: 0.6157 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 280us/step - loss: 0.6630 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6240 - val_f1_score: 0.6665\n",
      "9372/9372 [==============================] - 2s 202us/steploss: 0.6843 - acc: 0.6182 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 190us/steps: 0.6706 - acc: 0.6174 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 13s 342us/step - loss: 0.6692 - acc: 0.6187 - f1_score: 0.6662 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "  576/37488 [..............................] - ETA: 8s - loss: 0.6643 - acc: 0.6198 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 11s 306us/step - loss: 0.6653 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6669 - acc: 0.6172 - f1_score: 0.6660 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6653 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6658 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      " 9600/37488 [======>.......................] - ETA: 7s - loss: 0.6646 - acc: 0.6192 - f1_score: 0.6667Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6666 - val_loss: 0.6631 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6644 - acc: 0.6186 - f1_score: 0.6666 - val_loss: 0.6627 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6244 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6666 - acc: 0.3973 - f1_score: 0.0459 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6649 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6645 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6645 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6648 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6217 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6642 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6642 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6642 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6644 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6640 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6639 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6640 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6637 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "14912/37488 [==========>...................] - ETA: 6s - loss: 0.6635 - acc: 0.3791 - f1_score: 0.0000e+00Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 0.6641 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 201us/steposs: 0.6650 - acc: 0.5926 - f1_score: 0.60\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6649 - acc: 0.5584 - f1_score: 0.5124 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 189us/steps: 0.6671 - acc: 0.3842 - f1_score: 0.0000e+\n",
      "25728/37489 [===================>..........] - ETA: 3s - loss: 0.6661 - acc: 0.3825 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 281us/step - loss: 0.6660 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 198us/steposs: 8.2753 - acc: 0.3843 - f1_score: 0.21\n",
      "37489/37489 [==============================] - 7s 188us/steps: 9.3373 - acc: 0.3825 - f1_s\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 9.3367 - acc: 0.3826 - f1_score: 0.3196 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      " 9408/37489 [======>.......................] - ETA: 5s - loss: 9.9573 - acc: 0.3821 - f1_score: 0.3821Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 281us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 6.1427 - acc: 0.3823 - f1_score: 0.3504 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3778 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3778 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "20224/37489 [===============>..............] - ETA: 5s - loss: 6.1176 - acc: 0.3795 - f1_score: 0.3767Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3778 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3778 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3778 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3778 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9643 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 202us/steposs: 6.1000 - acc: 0.3785 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3779 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 187us/steps: 6.0947 - acc: 0.3781 - f1_score: 0.37\n",
      "21632/37489 [================>.............] - ETA: 3s - loss: 6.1382 - acc: 0.3808 - f1_score: 0.3774Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 276us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3778 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3730\n",
      "9372/9372 [==============================] - 2s 182us/steposs: 0.7863 - acc: 0.3861 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 185us/steps: 0.7200 \n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.7198 - acc: 0.3837 - f1_score: 0.0000e+00 - val_loss: 0.6654 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "10176/37489 [=======>......................] - ETA: 6s - loss: 0.6672 - acc: 0.3853 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 281us/step - loss: 0.6660 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 14s 382us/step - loss: 0.6676 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6652 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6648 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6659 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6648 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6642 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6643 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6642 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6639 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6657 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6674 - acc: 0.4979 - f1_score: 0.3165 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6638 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6642 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6665 - val_acc: 0.3753 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6638 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6635 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6638 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6691 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6647 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6648 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6643 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 333us/step - loss: 0.6649 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6642 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 194us/steposs: 0.6639 - acc: 0.3803 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 0.6647 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 186us/stepss: 0.6695 - acc: 0.3910 - f1_score: 0.0000e+\n",
      "14080/37488 [==========>...................] - ETA: 5s - loss: 0.6641 - acc: 0.3802 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 11s 282us/step - loss: 0.6643 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 192us/steposs: 0.7860 - acc: 0.3899 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 0.7420 - acc: 0.3858 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 7s 188us/steps: 0.6697 - acc: 0.3902 - f1_score: 0.0000e+\n",
      " 7232/37489 [====>.........................] - ETA: 8s - loss: 0.6676 - acc: 0.3862 - f1_score: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 96.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17792/37489 [=============>................] - ETA: 4s - loss: 0.6655 - acc: 0.3815 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 281us/step - loss: 0.6659 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 385us/step - loss: 0.6664 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6643 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6653 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6646 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6655 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6648 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6652 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6647 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6652 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6646 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6647 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6648 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6650 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6641 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6661 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6648 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6640 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6647 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6642 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6639 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6648 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6636 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6645 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "30592/37489 [=======================>......] - ETA: 2s - loss: 0.6651 - acc: 0.3826 - f1_score: 0.0000e+00Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6650 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6644 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6645 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6638 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6647 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6644 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6646 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6645 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6644 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6637 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6645 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 186us/steposs: 0.6618 - acc: 0.3778 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 189us/steps: 0.6631 - acc: 0.3\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6631 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "10432/37489 [=======>......................] - ETA: 5s - loss: 0.6611 - acc: 0.3765 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 285us/step - loss: 0.6636 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 200us/steposs: 9.8185 - acc: 0.6204 - f1_score: 0.57\n",
      "37489/37489 [==============================] - 14s 382us/step - loss: 9.8366 - acc: 0.6186 - f1_score: 0.5885 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 186us/steps: 10.0856 - acc: 0.6257 - f1_score: 0.\n",
      "21952/37489 [================>.............] - ETA: 3s - loss: 10.0143 - acc: 0.6213 - f1_score: 0.6213Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 275us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 383us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 200us/steposs: 6.1066 - acc: 0.3789 - f1_score: 0.37\n",
      "37489/37489 [==============================] - 7s 190us/steps: 6.1498 - acc: 0.3815 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 313us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      " 7168/37489 [====>.........................] - ETA: 6s - loss: 6.1612 - acc: 0.3823 - f1_score: 0.3822Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 291us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 189us/steposs: 6.1859 - acc: 0.3846 - f1_score: 0.38\n",
      "37488/37488 [==============================] - 14s 379us/step - loss: 6.1336 - acc: 0.3812 - f1_score: 0.3805 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 7s 186us/steps: 6.1333 - acc: 0.3805 - f1_score: 0.\n",
      "25408/37488 [===================>..........] - ETA: 3s - loss: 6.0988 - acc: 0.3784 - f1_score: 0.3784Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 10s 275us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 385us/step - loss: 6.1532 - acc: 0.3824 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 316us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 320us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9373/9373 [==============================] - 2s 191us/steposs: 6.1613 - acc: 0.3823 - f1_score: 0.38\n",
      "37488/37488 [==============================] - 7s 191us/steps: 6.1650 - acc: 0.3825 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 11s 303us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      " 3776/37489 [==>...........................] - ETA: 6s - loss: 6.0784 - acc: 0.3771 - f1_score: 0.3771Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 296us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3824 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 196us/steposs: 0.8427 - acc: 0.6130 - f1_score: 0.65\n",
      "37489/37489 [==============================] - 15s 388us/step - loss: 0.8242 - acc: 0.6139 - f1_score: 0.6554 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 186us/steps: 0.6662 - acc: 0.6167 - f1_score: 0.\n",
      "29184/37489 [======================>.......] - ETA: 2s - loss: 0.6661 - acc: 0.6174 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 270us/step - loss: 0.6656 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 386us/step - loss: 6.1401 - acc: 0.6180 - f1_score: 0.6180 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6652 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6653 - acc: 0.4804 - f1_score: 0.2708 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "9372/9372 [==============================] - 2s 180us/steposs: 6.0947 - acc: 0.6219 - f1_score: 0.62\n",
      "37489/37489 [==============================] - 7s 191us/steps: 6.0937 - acc: 0.6219 - f1_score: 0.\n",
      "37440/37489 [============================>.] - ETA: 0s - loss: 6.1455 - acc: 0.6187 - f1_score: 0.6187Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 288us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 312us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 186us/steposs: 0.6780 - acc: 0\n",
      "37489/37489 [==============================] - 15s 387us/step - loss: 0.6780 - acc: 0.3857 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 192us/steps: 0.6657 - acc: 0.3817 - f1_score: 0.0000\n",
      "36096/37489 [===========================>..] - ETA: 0s - loss: 0.6661 - acc: 0.3828 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 276us/step - loss: 0.6660 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 309us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 15s 392us/step - loss: 0.9529 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6653 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6659 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      " 9856/37489 [======>.......................] - ETA: 8s - loss: 0.6666 - acc: 0.3848 - f1_score: 0.0000e+00Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6654 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 331us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 330us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 331us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 333us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 332us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "16448/37489 [============>.................] - ETA: 6s - loss: 0.6670 - acc: 0.3856 - f1_score: 0.0000e+00Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 186us/steposs: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 189us/steps: 0.6651 - acc: 0.3818 - f1_score: 0.0000e+\n",
      "28416/37488 [=====================>........] - ETA: 2s - loss: 0.6649 - acc: 0.3813 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 10s 273us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 15s 394us/step - loss: 0.6672 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 197us/steposs: 0.6684 - acc: 0.3870 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 7s 196us/steps: 0.6665 - acc: 0.3834 - f1_score: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 11s 303us/step - loss: 0.6659 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      " 4224/37489 [==>...........................] - ETA: 6s - loss: 0.6624 - acc: 0.3767 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 290us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 15s 393us/step - loss: 9.9514 - acc: 0.3817 - f1_score: 0.3806 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6658 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 195us/steposs: 9.9448 - acc: 0.3830 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 190us/steps: 9.9378 - acc: 0.3834 - f1_score: 0.38\n",
      "24896/37489 [==================>...........] - ETA: 3s - loss: 9.9411 - acc: 0.3832 - f1_score: 0.3832Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 275us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 15s 399us/step - loss: 0.6770 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6650 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 196us/steposs: 0.6654 - acc: 0.3793 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 194us/steps: 0.6655 - acc: 0.3813 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 12s 311us/step - loss: 0.6656 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      " 7488/37489 [====>.........................] - ETA: 5s - loss: 0.6727 - acc: 0.3986 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 286us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6665 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 15s 394us/step - loss: 0.6674 - acc: 0.6160 - f1_score: 0.6658 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6662 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6659 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6644 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6643 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6639 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6641 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6756 - acc: 0.4377 - f1_score: 0.1603 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6656 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6649 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6655 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6654 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6643 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6649 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 206us/steposs: 0.6657 - acc: 0.6177 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 191us/steps: 0.6650 - acc: 0.6185 - f1_score: 0.66\n",
      "22656/37489 [=================>............] - ETA: 3s - loss: 0.6641 - acc: 0.6203 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 272us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 15s 394us/step - loss: 0.6684 - acc: 0.6184 - f1_score: 0.6628 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 198us/steposs: 0.6671 - acc: 0.6156 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 191us/steps: 0.6651 - acc: 0.6189 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 12s 312us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "10368/37488 [=======>......................] - ETA: 5s - loss: 0.6647 - acc: 0.6196 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 10s 272us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 15s 392us/step - loss: 0.6727 - acc: 0.3836 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6646 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 13s 340us/step - loss: 0.6641 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 0.6638 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6644 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6653 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 13s 351us/step - loss: 0.6638 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6650 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6637 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6644 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6632 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6641 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6636 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6638 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6632 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6636 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6662 - val_acc: 0.3785 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6627 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6637 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "23808/37488 [==================>...........] - ETA: 4s - loss: 0.6635 - acc: 0.6179 - f1_score: 0.6666Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6628 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6635 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6626 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6634 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 0.6625 - acc: 0.6202 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 0.6631 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 332us/step - loss: 0.6624 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6602 - val_acc: 0.6247 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6630 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6605 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6622 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6630 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6623 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6602 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6630 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6638 - val_acc: 0.3793 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6618 - acc: 0.6198 - f1_score: 0.6667 - val_loss: 0.6656 - val_acc: 0.6220 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6628 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6620 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6600 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 2s 207us/steposs: 0.6625 - acc: 0.3803 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6624 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 191us/stepss: 0.6633 - acc: 0.3859 - f1_score: 0.0000e+\n",
      "17472/37489 [============>.................] - ETA: 4s - loss: 0.6606 - acc: 0.3789 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 272us/step - loss: 0.6627 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 15s 396us/step - loss: 6.5833 - acc: 0.6183 - f1_score: 0.6160 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6626 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6604 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 201us/steposs: 6.1762 - acc: 0.6168 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 194us/stepss: 5.9656 - acc: 0.6299 - f1_score: 0.\n",
      "14336/37489 [==========>...................] - ETA: 5s - loss: 6.1410 - acc: 0.6189 - f1_score: 0.6189Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 264us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 15s 393us/step - loss: 0.6686 - acc: 0.6186 - f1_score: 0.6665 - val_loss: 0.6648 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "12224/37489 [========>.....................] - ETA: 7s - loss: 0.6653 - acc: 0.6179 - f1_score: 0.6667Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6648 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6643 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6642 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "28992/37489 [======================>.......] - ETA: 2s - loss: 6.1127 - acc: 0.6208 - f1_score: 0.6208Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6638 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6635 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6632 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6628 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6631 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6627 - acc: 0.6188 - f1_score: 0.6666 - val_loss: 0.6607 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6633 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6602 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6631 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6222 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6627 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6600 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6625 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6652 - val_acc: 0.6207 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6623 - acc: 0.6210 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 193us/steposs: 0.6600 - acc: 0.6234 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 190us/steps: 0.6627 - acc: 0.6194 - f1_sco\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6627 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "11584/37489 [========>.....................] - ETA: 5s - loss: 0.6619 - acc: 0.6220 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 272us/step - loss: 0.6623 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 15s 391us/step - loss: 8.6008 - acc: 0.3826 - f1_score: 0.2553 - val_loss: 10.0636 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6621 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 2s 186us/steposs: 9.9307 - acc: 0.3838 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 8.8779 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 7s 192us/steps: 6.1958 - acc: 0.3844 - f1_score: 0.38\n",
      "21952/37489 [================>.............] - ETA: 3s - loss: 6.1574 - acc: 0.3822 - f1_score: 0.3822Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 261us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 15s 399us/step - loss: 0.6659 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6651 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 331us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6646 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 13s 334us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 332us/step - loss: 0.6644 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6643 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6642 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6641 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6638 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 333us/step - loss: 0.6634 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 330us/step - loss: 0.6637 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6633 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 332us/step - loss: 0.6631 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6629 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "   64/37489 [..............................] - ETA: 9s - loss: 6.7998 - acc: 0.4219 - f1_score: 0.4219Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1658 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6631 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "9372/9372 [==============================] - 2s 203us/steposs: 0.6643 - acc: 0.3858 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 7s 193us/steps: 0.6617 - acc: 0.3798 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 11s 297us/step - loss: 0.6626 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      " 3520/37488 [=>............................] - ETA: 8s - loss: 0.6590 - acc: 0.3787 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 11s 297us/step - loss: 0.6625 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 15s 404us/step - loss: 0.6681 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 0.6624 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 188us/steposs: 0.6660 - acc: 0.3831 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6657 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 193us/steps: 0.6651 - acc: 0.3815 - f1_score: 0.0000\n",
      "30464/37489 [=======================>......] - ETA: 1s - loss: 0.6659 - acc: 0.3836 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 262us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6653 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 15s 408us/step - loss: 0.6676 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6650 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6653 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6651 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6647 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6647 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6645 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 0.6645 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6647 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6648 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6642 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6643 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6641 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6641 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6638 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6640 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6636 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6638 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6635 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6642 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6634 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3783 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6634 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6634 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6634 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6632 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6630 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6630 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6632 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6632 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6629 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 0.6633 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6628 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 195us/steposs: 0.6630 - acc: 0.3809 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6630 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 190us/steps: 0.6620 - acc: 0.3793 - f1_score: 0.0000\n",
      "33152/37489 [=========================>....] - ETA: 1s - loss: 0.6622 - acc: 0.3802 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 279us/step - loss: 0.6629 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6626 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 15s 408us/step - loss: 0.6755 - acc: 0.6175 - f1_score: 0.6609 - val_loss: 0.6627 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6621 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3795 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6648 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9372/9372 [==============================] - 2s 198us/steploss: 0.6752 - acc: 0.6031 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 192us/steps: 0.6665 - acc: 0.6154 - f1_score: 0.66\n",
      "37440/37489 [============================>.] - ETA: 0s - loss: 0.6646 - acc: 0.6181 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 287us/step - loss: 0.6645 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6689 - val_acc: 0.6240 - val_f1_score: 0.6666\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 11s 300us/step - loss: 0.6645 - acc: 0.6184 - f1_score: 0.6666 - val_loss: 0.6668 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 15s 410us/step - loss: 0.6744 - acc: 0.6163 - f1_score: 0.6610 - val_loss: 0.6630 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6644 - acc: 0.6183 - f1_score: 0.6666 - val_loss: 0.6631 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6643 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6655 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6694 - val_acc: 0.6242 - val_f1_score: 0.6668\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6644 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6654 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6654 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6642 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6651 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6645 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6651 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6642 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6643 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6648 - acc: 0.6168 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6640 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6652 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6637 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6647 - acc: 0.6169 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6641 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6649 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6639 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 333us/step - loss: 0.6648 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6638 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 0.6636 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6646 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6636 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6646 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6635 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 0.6642 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6635 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6661 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6641 - acc: 0.6168 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6631 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 2s 200us/steposs: 0.6639 - acc: 0.6185 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6643 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 194us/steps: 0.6673 - acc: 0.6099 - f1_score: 0.\n",
      "30016/37489 [=======================>......] - ETA: 1s - loss: 0.6643 - acc: 0.6163 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 264us/step - loss: 0.6639 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6643 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6652 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 15s 409us/step - loss: 0.9704 - acc: 0.6173 - f1_score: 0.6632 - val_loss: 0.6639 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6638 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "9372/9372 [==============================] - 2s 185us/steposs: 0.6595 - acc: 0.6305 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 194us/steps: 0.6648 - acc: 0.6193 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 11s 296us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      " 2112/37488 [>.............................] - ETA: 6s - loss: 0.6706 - acc: 0.6075 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 11s 289us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 15s 404us/step - loss: 2.4475 - acc: 0.6166 - f1_score: 0.6490 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 319us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6658 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6647 - acc: 0.6187 - f1_score: 0.6666 - val_loss: 0.6612 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6643 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6645 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6641 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6646 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6653 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6650 - acc: 0.6185 - f1_score: 0.6666 - val_loss: 0.6630 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6652 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6704 - acc: 0.6187 - f1_score: 0.6662 - val_loss: 0.6607 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6647 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6638 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6643 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6638 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6643 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6635 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6644 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6636 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6640 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6657 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6639 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6686 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6641 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6633 - acc: 0.6186 - f1_score: 0.6666 - val_loss: 0.6607 - val_acc: 0.6240 - val_f1_score: 0.6666\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6639 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 330us/step - loss: 0.6634 - acc: 0.6190 - f1_score: 0.6666 - val_loss: 0.6615 - val_acc: 0.6232 - val_f1_score: 0.6666\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6638 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 0.6797 - acc: 0.6194 - f1_score: 0.6662 - val_loss: 0.6598 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 2s 185us/steposs: 0.6640 - acc: 0.6174 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6640 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 194us/steps: 0.6618 - acc: 0.6217 - f1_score: 0.\n",
      "26944/37489 [====================>.........] - ETA: 2s - loss: 0.6640 - acc: 0.6167 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 266us/step - loss: 0.6639 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6635 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 15s 405us/step - loss: 8.8826 - acc: 0.3826 - f1_score: 0.2803 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 0.6636 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 189us/steposs: 9.9292 - acc: 0.3840 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 7s 196us/steps: 9.9453 - acc: 0.3830 - f1_score: 0.\n",
      "37489/37489 [==============================] - 11s 304us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6144/37489 [===>..........................] - ETA: 6s - loss: 10.1105 - acc: 0.3727 - f1_score: 0.3727Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 280us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 15s 405us/step - loss: 6.1532 - acc: 0.3819 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 192us/steposs: 6.1405 - acc: 0.3810 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 194us/steps: 6.2808 - acc: 0.3897 - f1_score: 0.00\n",
      "24448/37489 [==================>...........] - ETA: 3s - loss: 6.1485 - acc: 0.3815 - f1_score: 0.0056Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 267us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 15s 406us/step - loss: 0.6685 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6659 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.0055 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0056\n",
      "9372/9372 [==============================] - 2s 192us/steposs: 0.6629 - acc: 0.3768 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 7s 192us/steps: 0.6657 - acc: 0.3826 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 12s 311us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      " 8448/37489 [=====>........................] - ETA: 6s - loss: 0.6647 - acc: 0.3801 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 270us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 15s 410us/step - loss: 0.6671 - acc: 0.3835 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 330us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6647 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 332us/step - loss: 0.6647 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 330us/step - loss: 0.6645 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6650 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6651 - acc: 0.3825 - f1_score: 5.1732e-05 - val_loss: 0.6611 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.6645 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6666 - acc: 0.6017 - f1_score: 0.6179 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 333us/step - loss: 0.6643 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6641 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6638 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 330us/step - loss: 0.6639 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 331us/step - loss: 0.6641 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 13s 334us/step - loss: 0.6639 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6641 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 13s 335us/step - loss: 0.6638 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6655 - acc: 0.6110 - f1_score: 0.6489 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 12s 330us/step - loss: 0.6639 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6647 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6655 - acc: 0.4706 - f1_score: 0.2655 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 331us/step - loss: 0.6637 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 188us/steposs: 0.6636 - acc: 0.3808 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 192us/steps: 0.6636 - acc: 0.3815 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 0.6635 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "11648/37488 [========>.....................] - ETA: 5s - loss: 0.6662 - acc: 0.3877 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 10s 273us/step - loss: 0.6632 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 16s 421us/step - loss: 6.2050 - acc: 0.6175 - f1_score: 0.6029 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 0.6633 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 331us/step - loss: 0.6632 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 208us/steposs: 6.1043 - acc: 0.6212 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 196us/stepss: 6.1198 - acc: 0.6201 - f1_score: 0.62\n",
      "20032/37489 [===============>..............] - ETA: 4s - loss: 6.1706 - acc: 0.6171 - f1_score: 0.6171Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 10s 262us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 16s 416us/step - loss: 0.6670 - acc: 0.6167 - f1_score: 0.6658 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6647 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 333us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6649 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6645 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6647 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6645 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6644 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 0.6644 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6645 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6644 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6642 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6642 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 0.6637 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6639 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6706 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1641 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "9372/9372 [==============================] - 2s 206us/steposs: 0.6649 - acc: 0.6193 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 196us/steps: 0.6645 - acc: 0.6187 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 312us/step - loss: 0.6646 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "10048/37489 [=======>......................] - ETA: 6s - loss: 0.6625 - acc: 0.6224 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 277us/step - loss: 0.6641 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 16s 419us/step - loss: 8.4019 - acc: 0.6186 - f1_score: 0.2762 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6636 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 0.6636 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6661 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 193us/steposs: 6.1429 - acc: 0.6189 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 194us/steps: 6.2375 - acc: 0.6130 - f1_score: 0.\n",
      "20352/37489 [===============>..............] - ETA: 4s - loss: 6.1995 - acc: 0.6154 - f1_score: 0.6154Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 263us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 16s 420us/step - loss: 9.9385 - acc: 0.6174 - f1_score: 0.6160 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 338us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      " 2496/37489 [>.............................] - ETA: 9s - loss: 9.8865 - acc: 0.6134 - f1_score: 0.6131Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 333us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 339us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 210us/steposs: 9.8681 - acc: 0.6122 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 7s 196us/steps: 9.9672 - acc: 0.6184 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 12s 310us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 18/20\n",
      " 6784/37489 [====>.........................] - ETA: 7s - loss: 10.0120 - acc: 0.6212 - f1_score: 0.6211Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 287us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 16s 421us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6244\n",
      "9372/9372 [==============================] - 2s 193us/steposs: 9.9882 - acc: 0.3797 - f1_score: 0.37\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 197us/steps: 9.9096 - acc: 0.3843 - f1_score: 0.38\n",
      "25920/37488 [===================>..........] - ETA: 2s - loss: 9.9376 - acc: 0.3828 - f1_score: 0.3826Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 9s 252us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "  448/37489 [..............................] - ETA: 4:11 - loss: 9.5701 - acc: 0.4107 - f1_score: 0.4107Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 12s 323us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 16s 420us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 329us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 12s 323us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 324us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 12s 328us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 325us/step - loss: 9.9642 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 17/20\n",
      "9373/9373 [==============================] - 2s 185us/steploss: 9.6617 - acc: 0.4013 - f1_score: 0.40\n",
      "37488/37488 [==============================] - 7s 191us/steps: 9.9308 - acc: 0.3827 - f1_score: 0.\n",
      "37489/37489 [==============================] - 11s 289us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 18/20\n",
      "  832/37489 [..............................] - ETA: 7s - loss: 9.7251 - acc: 0.3930 - f1_score: 0.3930Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 296us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 16s 417us/step - loss: 0.6690 - acc: 0.6181 - f1_score: 0.6655 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 9.9394 - acc: 0.3825 - f1_score: 0.3823 - val_loss: 10.0262 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "9372/9372 [==============================] - 2s 190us/steposs: 0.6654 - acc: 0.6182 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 195us/steps: 0.6652 - acc: 0.6186 - f1_score: 0.\n",
      "30784/37489 [=======================>......] - ETA: 1s - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 267us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 16s 426us/step - loss: 0.6706 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6666 - val_loss: 0.6622 - val_acc: 0.6249 - val_f1_score: 0.6664\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 0.6652 - acc: 0.6168 - f1_score: 0.6621 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6652 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 191us/steposs: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 192us/steps: 0.6657 - acc: 0.3827 - f1_score: 0.0000\n",
      "36864/37489 [============================>.] - ETA: 0s - loss: 0.6648 - acc: 0.3813 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 279us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 308us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 16s 422us/step - loss: 2.5284 - acc: 0.3829 - f1_score: 1.5758e-04 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 210us/steposs: 0.6660 - acc: 0.3830 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 194us/steps: 0.6625 - acc: 0.3759 - f1_score: 0.0000e+\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 0.6658 - acc: 0.3827 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 275us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 11s 299us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 16s 433us/step - loss: 1.5389 - acc: 0.3821 - f1_score: 1.0506e-04 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 318us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 13s 337us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 330us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 333us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 333us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 333us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6659 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 13s 335us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 12s 330us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 13s 335us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 13s 335us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 325us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 5.1732e-05 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 332us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6656 - acc: 0.4338 - f1_score: 0.1349 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 13s 339us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6666 - val_loss: 0.6639 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 13s 334us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 13s 335us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 13s 336us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 197us/steposs: 0.6660 - acc: 0.3835 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 12s 327us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 193us/stepss: 0.6663 - acc: 0.3839 - f1_score: 0.0000e+\n",
      "18944/37488 [==============>...............] - ETA: 4s - loss: 0.6658 - acc: 0.3828 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 10s 266us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 16s 432us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0696 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 332us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0698 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 13s 344us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0698 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 13s 339us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 202us/steposs: 6.8164 - acc: 0.3875 - f1_score: 0.06\n",
      "37488/37488 [==============================] - 7s 200us/steps: 6.7545 - acc: 0.3823 - f1\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0698 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 5/20\n",
      "14656/37489 [==========>...................] - ETA: 4s - loss: 6.7250 - acc: 0.3785 - f1_score: 0.0708Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 258us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0697 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 16s 429us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0693 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0697 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0694 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0699 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 338us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0695 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0699 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0695 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0698 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 339us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0694 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0697 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0694 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0697 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 340us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0695 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0696 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 339us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0694 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0697 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0694 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 338us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0698 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 338us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0693 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0698 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0694 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0698 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0694 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0698 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0693 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0696 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0694 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0697 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0695 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 6.7535 - acc: 0.3825 - f1_score: 0.0698 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "9372/9372 [==============================] - 2s 211us/steposs: 6.6552 - acc: 0.3772 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 197us/steps: 6.7742 - acc: 0.3817 - f1_score: 0.06\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0694 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 17/20\n",
      "16192/37489 [===========>..................] - ETA: 4s - loss: 6.7660 - acc: 0.3827 - f1_score: 0.0685Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 260us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0695 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 16s 430us/step - loss: 6.1373 - acc: 0.6183 - f1_score: 0.6187 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0693 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0694 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 6.7763 - acc: 0.3817 - f1_score: 0.0695 - val_loss: 6.5407 - val_acc: 0.3758 - val_f1_score: 0.0795\n",
      "9372/9372 [==============================] - 2s 187us/steposs: 6.2587 - acc: 0.6117 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 196us/steps: 6.1465 - acc: 0.618\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "15360/37489 [===========>..................] - ETA: 4s - loss: 6.1555 - acc: 0.6181 - f1_score: 0.6181Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 262us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 16s 433us/step - loss: 6.1562 - acc: 0.6172 - f1_score: 0.6176 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "32448/37489 [========================>.....] - ETA: 1s - loss: 6.1397 - acc: 0.6191 - f1_score: 0.6191Epoch 2/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 340us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 201us/steposs: 6.1540 - acc: 0.6182 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 7s 195us/steps: 6.1666 - acc: 0.6174 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "12224/37489 [========>.....................] - ETA: 5s - loss: 6.2579 - acc: 0.6117 - f1_score: 0.6117Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 273us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 10s 263us/step - loss: 0.6782 - acc: 0.3835 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 163us/step - loss: 0.6653 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6645 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6644 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 338us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 162us/step - loss: 0.6639 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6637 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 204us/steposs: 0.6633 - acc: 0.3815 - f1_sco\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 0.6633 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 160us/step - loss: 0.6633 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 195us/steps: 0.6649 - acc: 0.3862 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 5s 124us/step - loss: 0.6626 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      " 1536/37488 [>.............................] - ETA: 4s - loss: 0.6597 - acc: 0.3757 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 126us/step - loss: 0.6623 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 10s 261us/step - loss: 0.6777 - acc: 0.3837 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 158us/step - loss: 0.6623 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3785 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6659 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 163us/step - loss: 0.6623 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6653 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 0.6620 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6651 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 164us/step - loss: 0.6623 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6647 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 163us/step - loss: 0.6617 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6644 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6617 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6641 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 165us/step - loss: 0.6617 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3785 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6636 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 162us/step - loss: 0.6616 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3820 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6636 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6612 - acc: 0.3796 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3810 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6634 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 0.6614 - acc: 0.3799 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 1s 99us/steploss: 0.6661 - acc: 0.3891 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 4s 99us/stepss: 0.6638 - acc: 0.3831 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6631 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "26880/37489 [====================>.........] - ETA: 1s - loss: 0.6608 - acc: 0.3785 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 116us/step - loss: 0.6629 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 0.6627 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 10s 264us/step - loss: 0.6682 - acc: 0.6174 - f1_score: 0.6665 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 0.6624 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6624 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6655 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6647 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6624 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6646 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6625 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6646 - acc: 0.6185 - f1_score: 0.6666 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6621 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6637 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6673 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6619 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6638 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6619 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 99us/steploss: 0.6642 - acc: 0.6180 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6636 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6232 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 4s 99us/stepss: 0.6638 - acc: 0.6175 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 131us/step - loss: 0.6635 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6211 - val_f1_score: 0.6666\n",
      "Epoch 10/20\n",
      " 5888/37489 [===>..........................] - ETA: 3s - loss: 0.6622 - acc: 0.6191 - f1_score: 0.6666Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 120us/step - loss: 0.6631 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6629 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6215 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 10s 268us/step - loss: 5.8273 - acc: 0.6186 - f1_score: 0.6207 - val_loss: 0.6621 - val_acc: 0.6240 - val_f1_score: 0.6666\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6627 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6658 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6724 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6625 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6222 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6624 - acc: 0.6193 - f1_score: 0.6666 - val_loss: 0.6608 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6648 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6621 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6228 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6644 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6624 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6671 - val_acc: 0.6194 - val_f1_score: 0.6665\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6641 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6618 - acc: 0.6198 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6636 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6616 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6228 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6632 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6616 - acc: 0.6202 - f1_score: 0.6667 - val_loss: 0.6682 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6632 - acc: 0.6188 - f1_score: 0.6666 - val_loss: 0.6616 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6615 - acc: 0.6200 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6627 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6666 - val_acc: 0.6205 - val_f1_score: 0.6666\n",
      "Epoch 11/20\n",
      "9372/9372 [==============================] - 1s 98us/steploss: 0.6591 - acc: 0.6279 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 4s 100us/steps: 0.6622 - acc: 0.6206 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 158us/step - loss: 0.6628 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6220 - val_f1_score: 0.6665\n",
      "Epoch 12/20\n",
      "24192/37489 [==================>...........] - ETA: 1s - loss: 0.6632 - acc: 0.6189 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 115us/step - loss: 0.6629 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 148us/step - loss: 0.6626 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6219 - val_f1_score: 0.6666\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 10s 272us/step - loss: 0.6713 - acc: 0.3838 - f1_score: 0.0000e+00 - val_loss: 0.6643 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6626 - acc: 0.6197 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6226 - val_f1_score: 0.6666\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6618 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6619 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6648 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6643 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6619 - acc: 0.6198 - f1_score: 0.6667 - val_loss: 0.6668 - val_acc: 0.6236 - val_f1_score: 0.6665\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6646 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6616 - acc: 0.6200 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6643 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6616 - acc: 0.6206 - f1_score: 0.6668 - val_loss: 0.6718 - val_acc: 0.6207 - val_f1_score: 0.6665\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6637 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6612 - acc: 0.6202 - f1_score: 0.6667 - val_loss: 0.6656 - val_acc: 0.6192 - val_f1_score: 0.6666\n",
      "9372/9372 [==============================] - 1s 111us/steposs: 0.6634 - acc: 0.3818 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6639 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 4s 99us/stepss: 0.6621 - acc: 0.3788 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 5s 131us/step - loss: 0.6636 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      " 7552/37489 [=====>........................] - ETA: 3s - loss: 0.6603 - acc: 0.3762 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 117us/step - loss: 0.6634 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 0.6630 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 10s 271us/step - loss: 0.6657 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6628 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6701 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 165us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6627 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6650 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6625 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3791 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6627 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 164us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6624 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6643 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 0.6619 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6676 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6639 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6621 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3787 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 165us/step - loss: 0.6639 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6614 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6638 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6618 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 105us/steposs: 0.6636 - acc: 0.3814 - f1_score: 0.\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6635 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 4s 97us/stepss: 0.6630 - acc: 0.3806 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 5s 141us/step - loss: 0.6632 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "16256/37488 [============>.................] - ETA: 2s - loss: 0.6634 - acc: 0.3824 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 4s 116us/step - loss: 0.6632 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 162us/step - loss: 0.6629 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 10s 273us/step - loss: 0.6666 - acc: 0.6170 - f1_score: 0.6630 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 165us/step - loss: 0.6631 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6630 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6656 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6654 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6630 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6650 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6624 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3783 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6626 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6648 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6624 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6644 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6624 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3785 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 1s 96us/steploss: 0.6645 - acc: 0.6175 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6644 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 4s 97us/stepss: 0.6638 - acc: 0.6194 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 0.6645 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6664 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "13952/37489 [==========>...................] - ETA: 2s - loss: 0.6638 - acc: 0.6180 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 114us/step - loss: 0.6640 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6639 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 10s 274us/step - loss: 0.6661 - acc: 0.6178 - f1_score: 0.6627 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 160us/step - loss: 0.6641 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6650 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6635 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6633 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6647 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6661 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6626 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6213 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6633 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6645 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6626 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6228 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6640 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6626 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6638 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6624 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6641 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6621 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 98us/steploss: 0.6633 - acc: 0.6196 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6637 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 4s 99us/stepss: 0.6635 - acc: 0.6193 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 138us/step - loss: 0.6635 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "12160/37489 [========>.....................] - ETA: 2s - loss: 0.6651 - acc: 0.6143 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 115us/step - loss: 0.6635 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6630 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 10s 277us/step - loss: 6.1723 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 0.6626 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6624 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6645 - val_acc: 0.6211 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6621 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6619 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6244 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6625 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6220 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6616 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6614 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 1s 95us/steploss: 6.1702 - acc: 0.6188 - f1\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 4s 101us/steps: 6.1920 - acc: 0.6177 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19584/37489 [==============>...............] - ETA: 1s - loss: 6.2163 - acc: 0.6161 - f1_score: 0.6161Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 116us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 10s 278us/step - loss: 1.0370 - acc: 0.6117 - f1_score: 0.6535 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6662 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6648 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1740 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0702 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "9372/9372 [==============================] - 1s 95us/steploss: 0.6642 - acc: 0.6186 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6650 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 4s 100us/steps: 0.6638 - acc: 0.6208 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 136us/step - loss: 0.6650 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      " 7296/37489 [====>.........................] - ETA: 3s - loss: 0.6632 - acc: 0.6208 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 118us/step - loss: 0.6649 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6647 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 10s 273us/step - loss: 0.6679 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6650 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6644 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 164us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6643 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6643 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6641 - acc: 0.6168 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6644 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6645 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 98us/steploss: 0.6664 - acc: 0.3851 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6641 - acc: 0.3810 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 6s 157us/step - loss: 0.6641 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "31232/37488 [=======================>......] - ETA: 0s - loss: 0.6649 - acc: 0.3792 - f1_score: 0.0013Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 4s 119us/step - loss: 0.6655 - acc: 0.3810 - f1_score: 0.0011 - val_loss: 0.7222 - val_acc: 0.3791 - val_f1_score: 0.2701\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 5s 136us/step - loss: 0.6694 - acc: 0.3816 - f1_score: 0.0065 - val_loss: 0.6606 - val_acc: 0.3764 - val_f1_score: 0.0011\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 10s 279us/step - loss: 0.6686 - acc: 0.3845 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 163us/step - loss: 0.6635 - acc: 0.3810 - f1_score: 8.8982e-04 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 165us/step - loss: 0.6816 - acc: 0.4096 - f1_score: 0.1058 - val_loss: 0.6648 - val_acc: 0.6236 - val_f1_score: 0.6665\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6647 - acc: 0.4097 - f1_score: 0.0918 - val_loss: 0.6644 - val_acc: 0.3762 - val_f1_score: 0.0052\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6654 - acc: 0.4868 - f1_score: 0.2878 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 0.6653 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6653 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6647 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 6s 165us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 1s 100us/steposs: 0.6659 - acc: 0.3850 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 4s 98us/stepss: 0.6718 - acc: 0.440\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6717 - acc: 0.4421 - f1_score: 0.1697 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "35584/37489 [===========================>..] - ETA: 0s - loss: 0.6663 - acc: 0.6172 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 124us/step - loss: 0.6661 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 133us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 10s 276us/step - loss: 6.1698 - acc: 0.6172 - f1_score: 0.6160 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 104us/steposs: 6.1305 - acc: 0.6197 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "36224/37489 [===========================>..] - ETA: 0sEpoch 10/20\n",
      "37489/37489 [==============================] - 4s 101us/steps: 6.6109 - acc: 0.5898 - f1_score: 0.\n",
      "36992/37489 [============================>.] - ETA: 0s - loss: 6.1510 - acc: 0.6184 - f1_score: 0.6184Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 120us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 125us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 10s 279us/step - loss: 6.1564 - acc: 0.6180 - f1_score: 0.6166 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 160us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "9372/9372 [==============================] - 1s 106us/steposs: 5.9933 - acc: 0.6282 - f1_score: 0.62\n",
      "37489/37489 [==============================] - 4s 99us/stepss: 6.0896 - acc: 0.6222 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "26240/37489 [===================>..........] - ETA: 1s - loss: 6.1794 - acc: 0.6167 - f1_score: 0.6167Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 117us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 147us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 11s 281us/step - loss: 0.6739 - acc: 0.6170 - f1_score: 0.6644 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6660 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6649 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 6.1482 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 1s 111us/steposs: 0.6649 - acc: 0.6175 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6649 - acc: 0.6169 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6643 - acc: 0.6190 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 132us/step - loss: 0.6649 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      " 7040/37489 [====>.........................] - ETA: 3s - loss: 0.6656 - acc: 0.6165 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 116us/step - loss: 0.6649 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6643 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 11s 286us/step - loss: 6.1217 - acc: 0.6186 - f1_score: 0.6162 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6644 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6644 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6640 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6640 - acc: 0.6175 - f1_score: 0.6665 - val_loss: 0.6661 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6644 - acc: 0.6175 - f1_score: 0.6665 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6639 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6635 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 105us/steposs: 6.1457 - acc: 0.6187 - f1_score: 0.\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 102us/steps: 6.1084 - acc: 0.6210 - f1_score: 0.62\n",
      "37488/37488 [==============================] - 5s 146us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "17792/37488 [=============>................] - ETA: 2s - loss: 6.0923 - acc: 0.6220 - f1_score: 0.6220Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 4s 119us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 6s 159us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 11s 288us/step - loss: 0.7031 - acc: 0.6112 - f1_score: 0.6582 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 164us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6645 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6655 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6652 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6651 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6648 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6648 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6648 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9373/9373 [==============================] - 1s 99us/steploss: 0.6641 - acc: 0.6186 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6647 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 4s 101us/steps: 0.6668 - acc: 0.6127 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 0.6647 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6638 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "21632/37489 [================>.............] - ETA: 1s - loss: 0.6643 - acc: 0.6183 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 117us/step - loss: 0.6643 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6642 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 11s 293us/step - loss: 0.7033 - acc: 0.6109 - f1_score: 0.6581 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6643 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6640 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6651 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6650 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6645 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6673 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6641 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6647 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6636 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6649 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6638 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6647 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6640 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6645 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6663 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6637 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 107us/steposs: 0.6631 - acc: 0.6213 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6643 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 100us/steps: 0.6733 - acc: 0.5991 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 130us/step - loss: 0.6641 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "  128/37489 [..............................] - ETA: 5s - loss: 0.7329 - acc: 0.5000 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 128us/step - loss: 0.6639 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 11s 286us/step - loss: 0.6839 - acc: 0.6177 - f1_score: 0.6612 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6640 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6637 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6639 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6641 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6638 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6646 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6631 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6635 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6633 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6641 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6629 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6647 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 107us/steposs: 0.6650 - acc: 0.6180 - f1_score: 0.\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6636 - acc: 0.6202 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6642 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "34176/37489 [==========================>...] - ETA: 0s - loss: 0.6639 - acc: 0.6194 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 118us/step - loss: 0.6643 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 133us/step - loss: 0.6638 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 11s 293us/step - loss: 0.6849 - acc: 0.6088 - f1_score: 0.6589 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 0.6631 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6631 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6633 - acc: 0.6183 - f1_score: 0.6666 - val_loss: 0.6616 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6630 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6628 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6226 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6631 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6630 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6628 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 107us/steposs: 0.6674 - acc: 0.6117 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6656 - acc: 0.6156 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6647 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 0.6646 - acc: 0.6174 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 118us/step - loss: 0.6646 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 127us/step - loss: 0.6648 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6648 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 11s 292us/step - loss: 0.6707 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6640 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6638 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6632 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6635 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      " 3200/37488 [=>............................] - ETA: 4s - loss: 0.6653 - acc: 0.3816 - f1_score: 0.0000e+00Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6630 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6632 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6650 - acc: 0.3942 - f1_score: 0.0416 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6635 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6649 - acc: 0.6172 - f1_score: 0.6628 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6666\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6638 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6631 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 96us/steploss: 0.6667 - acc: 0.6155 - f1_score: 0.\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6650 - acc: 0.6187 - f1_score: 0.\n",
      "37488/37488 [==============================] - 6s 163us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "35712/37488 [===========================>..] - ETA: 0s - loss: 0.6652 - acc: 0.5843 - f1_score: 0.5661Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 4s 118us/step - loss: 0.6649 - acc: 0.5864 - f1_score: 0.5709 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 5s 130us/step - loss: 0.6648 - acc: 0.5095 - f1_score: 0.3740 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 11s 296us/step - loss: 0.6711 - acc: 0.3839 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6660 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6658 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 1s 97us/steploss: 0.6683 - acc: 0.3882 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 4s 102us/steps: 0.6659 - acc: 0.3831 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "32000/37489 [========================>.....] - ETA: 0s - loss: 0.6663 - acc: 0.3838 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 120us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 11s 296us/step - loss: 9.8896 - acc: 0.6171 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 113us/steposs: 9.8866 - acc: 0.6153 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 4s 103us/steps: 9.9232 - acc: 0.6182 \n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 9.9259 - acc: 0.6184 - f1_score: 0.6184Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 120us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 11s 295us/step - loss: 0.7088 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6665 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 9.9239 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0107 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "9372/9372 [==============================] - 1s 93us/steploss: 0.6665 - acc: 0.3839 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6652 - acc: 0.3818 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "27008/37489 [====================>.........] - ETA: 1s - loss: 0.6665 - acc: 0.3843 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 118us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 11s 294us/step - loss: 9.9065 - acc: 0.6171 - f1_score: 0.6152 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6644 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 95us/steploss: 9.8906 - acc: 0.6142 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 4s 100us/steps: 9.8317 - acc: 0.6103 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      " 5504/37489 [===>..........................] - ETA: 3s - loss: 9.9537 - acc: 0.6210 - f1_score: 0.6210 Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 118us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 11s 300us/step - loss: 9.6165 - acc: 0.3811 - f1_score: 0.3787 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "11264/37489 [========>.....................] - ETA: 4s - loss: 9.9150 - acc: 0.6161 - f1_score: 0.6161Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9394 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0355 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 1s 101us/steposs: 9.9291 - acc: 0.3808 - f1_score: 0.38\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 4s 102us/steps: 9.9049 - acc: 0.3821 - f1_score: 0.\n",
      "37488/37488 [==============================] - 5s 141us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "16128/37488 [===========>..................] - ETA: 2s - loss: 9.9889 - acc: 0.3783 - f1_score: 0.3783Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 121us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 158us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 11s 300us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0150 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0149 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0150 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0149 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0149 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0150 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0149 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0150 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 173us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0150 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 9.9293 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 9.9705 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9373/9373 [==============================] - 1s 103us/steposs: 6.1589 - acc: 0.3822 - f1_score: 0.01\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0149 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 4s 101us/steps: 6.1402 - acc: 0.3809 - f1_score: 0.01\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0149 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 12/20\n",
      "17664/37489 [=============>................] - ETA: 2s - loss: 6.1392 - acc: 0.3809 - f1_score: 0.0136Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 116us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0149 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0150 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 11s 301us/step - loss: 6.1337 - acc: 0.6184 - f1_score: 0.6162 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0150 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0149 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0150 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0149 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0150 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0149 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1641 - acc: 0.3825 - f1_score: 0.0150 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.0161\n",
      "9372/9372 [==============================] - 1s 105us/steposs: 6.1296 - acc: 0.6198 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 4s 99us/stepss: 6.0536 - acc: 0.6244 - f1_score: 0.62\n",
      "37489/37489 [==============================] - 5s 133us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      " 8576/37489 [=====>........................] - ETA: 3s - loss: 6.0838 - acc: 0.6228 - f1_score: 0.6228Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 118us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 11s 300us/step - loss: 4.4681 - acc: 0.3820 - f1_score: 0.1301 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "12544/37489 [=========>....................] - ETA: 3s - loss: 6.1085 - acc: 0.6210 - f1_score: 0.6210Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6655 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "31488/37489 [========================>.....] - ETA: 0s - loss: 0.6652 - acc: 0.3821 - f1_score: 0.0000e+00Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1538 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 1s 108us/steposs: 0.6652 - acc: 0.3817 - f1_score: \n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 4s 103us/steps: 0.6656 - acc: 0.3827 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 147us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "23808/37489 [==================>...........] - ETA: 1s - loss: 0.6647 - acc: 0.3804 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 118us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 11s 303us/step - loss: 0.6856 - acc: 0.6164 - f1_score: 0.6663 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6659 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6644 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 100us/steposs: 0.6665 - acc: 0.6161 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 4s 100us/steps: 0.6665 - acc: 0.6148 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 121us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      " 2944/37489 [=>............................] - ETA: 4s - loss: 0.6651 - acc: 0.6185 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 11s 298us/step - loss: 0.6675 - acc: 0.6187 - f1_score: 0.6657 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6647 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6642 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6642 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6639 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6639 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 165us/step - loss: 0.6634 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6636 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6634 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "9372/9372 [==============================] - 1s 101us/steposs: 0.6681 - acc: 0.6098 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 4s 100us/steps: 0.6633 - acc: 0.6185 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 6s 150us/step - loss: 0.6631 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "31872/37488 [========================>.....] - ETA: 0s - loss: 0.6626 - acc: 0.6198 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 121us/step - loss: 0.6628 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 5s 131us/step - loss: 0.6626 - acc: 0.6200 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 11s 303us/step - loss: 0.6672 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 164us/step - loss: 0.6623 - acc: 0.6197 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6226 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6653 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6621 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6601 - val_acc: 0.6251 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6652 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6617 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6645 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6617 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6645 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6617 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6639 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6617 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6638 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 0.6617 - acc: 0.6197 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "9373/9373 [==============================] - 1s 99us/steploss: 0.6643 - acc: 0.3828 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 4s 100us/steps: 0.6639 - acc: 0.3819 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 160us/step - loss: 0.6638 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "36480/37489 [============================>.] - ETA: 0s - loss: 0.6627 - acc: 0.3811 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 124us/step - loss: 0.6631 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6707 - val_acc: 0.3814 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 127us/step - loss: 0.6631 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 11s 302us/step - loss: 0.9804 - acc: 0.3926 - f1_score: 1.0587e-04 - val_loss: 0.6619 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6632 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6629 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6703 - val_acc: 0.3803 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6628 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6627 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6669 - val_acc: 0.3808 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6644 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6627 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6642 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6625 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6639 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6620 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3799 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6637 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6621 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6635 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6620 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6633 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6620 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6663 - val_acc: 0.3795 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 110us/steposs: 0.6627 - acc: 0.3804 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 4s 104us/steps: 0.6631 - acc: 0.3812 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6630 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37120/37489 [============================>.] - ETA: 0s - loss: 0.6630 - acc: 0.3812 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 117us/step - loss: 0.6631 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 4s 117us/step - loss: 0.6625 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6624 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 11s 303us/step - loss: 9.9325 - acc: 0.6186 - f1_score: 0.6121 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6621 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6622 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6619 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6616 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6618 - acc: 0.3800 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6615 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 8/20\n",
      "9372/9372 [==============================] - 1s 97us/steploss: 10.4516 - acc: 0.6484 - f1_score: 0.64\n",
      "37489/37489 [==============================] - 4s 101us/steps: 9.9653 - acc: 0.6184 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 9/20\n",
      "26496/37489 [====================>.........] - ETA: 1s - loss: 10.0075 - acc: 0.6211 - f1_score: 0.6188Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 118us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 11s 300us/step - loss: 0.6673 - acc: 0.6171 - f1_score: 0.6666 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6660 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6648 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6646 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6641 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6652 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "25728/37489 [===================>..........] - ETA: 1s - loss: 9.9704 - acc: 0.6192 - f1_score: 0.6167Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6636 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6676 - val_acc: 0.6201 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6637 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6635 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 9.9643 - acc: 0.6186 - f1_score: 0.6163 - val_loss: 10.0726 - val_acc: 0.6242 - val_f1_score: 0.6216\n",
      "9372/9372 [==============================] - 1s 96us/steploss: 0.6638 - acc: 0.6173 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6633 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6654 - acc: 0.6127 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 126us/step - loss: 0.6627 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "11264/37489 [========>.....................] - ETA: 2s - loss: 0.6649 - acc: 0.6136 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 115us/step - loss: 0.6629 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6643 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6628 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 12s 307us/step - loss: 0.6665 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6624 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6624 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6649 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6622 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 0.6644 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6624 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6213 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6617 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6186 - val_f1_score: 0.6667\n",
      "20480/37488 [===============>..............] - ETA: 2s - loss: 0.6631 - acc: 0.3789 - f1_score: 0.0000e+00Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6641 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6620 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 100us/steposs: 0.6652 - acc: 0.3831 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6642 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 4s 98us/stepss: 0.6625 - acc: 0.3780 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 5s 131us/step - loss: 0.6639 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "12160/37488 [========>.....................] - ETA: 3s - loss: 0.6631 - acc: 0.3796 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 122us/step - loss: 0.6637 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 6s 156us/step - loss: 0.6636 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "28800/37489 [======================>.......] - ETA: 2s - loss: 6.1814 - acc: 0.6165 - f1_score: 0.6165Epoch 11/20\n",
      "37489/37489 [==============================] - 11s 304us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6635 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6638 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 0.6633 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6632 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6630 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6628 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6626 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6626 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6628 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6625 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 1s 110us/steposs: 6.1718 - acc: 0.6171 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 4s 100us/steps: 6.1788 - acc: 0.6167 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 5s 136us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "17280/37489 [============>.................] - ETA: 2s - loss: 6.1963 - acc: 0.6156 - f1_score: 0.6156Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 123us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 12s 311us/step - loss: 0.7600 - acc: 0.6160 - f1_score: 0.6455 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6650 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6644 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6645 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1649 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 1s 108us/steposs: 0.6626 - acc: 0.6220 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6645 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6640 - acc: 0.6191 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 127us/step - loss: 0.6641 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      " 6912/37489 [====>.........................] - ETA: 3s - loss: 0.6676 - acc: 0.6110 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      " 7424/37489 [====>.........................] - ETA: 3s - loss: 0.6684 - acc: 0.6096 - f1_score: 0.6667Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 121us/step - loss: 0.6642 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6638 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 308us/step - loss: 6.9036 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 0.6634 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6633 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6634 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6638 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6629 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6629 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6215 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6629 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6623 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6624 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6627 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6647 - val_acc: 0.6203 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6620 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 96us/steploss: 6.1458 - acc: 0.3813 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 4s 101us/steps: 6.1273 - acc: 0.3802 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 13/20\n",
      "20992/37489 [===============>..............] - ETA: 1s - loss: 6.1134 - acc: 0.3793 - f1_score: 0.3793Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 118us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 147us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 310us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 160us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "28928/37489 [======================>.......] - ETA: 1s - loss: 6.1078 - acc: 0.3789 - f1_score: 0.3789Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "9372/9372 [==============================] - 1s 96us/steploss: 9.9221 - acc: 0.6168 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 4s 100us/steps: 9.5701 - acc: 0.6094 - f1_score: 0.60\n",
      "37489/37489 [==============================] - 5s 125us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 9/20\n",
      " 2560/37489 [=>............................] - ETA: 4s - loss: 10.0927 - acc: 0.6238 - f1_score: 0.6238Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 120us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 12s 310us/step - loss: 6.1784 - acc: 0.3812 - f1_score: 0.3406 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9063 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 10.0015 - val_acc: 0.6242 - val_f1_score: 0.6240\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "9372/9372 [==============================] - 1s 94us/steploss: 6.0739 - acc: 0.3727 - f1_score: 0.37\n",
      "37489/37489 [==============================] - 4s 101us/steps: 6.1457 - acc: 0.3798 - f1_score: 0.37\n",
      "37488/37488 [==============================] - 6s 152us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "31616/37488 [========================>.....] - ETA: 0s - loss: 6.1830 - acc: 0.3813 - f1_score: 0.3813Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 121us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 5s 129us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 12s 311us/step - loss: 9.8435 - acc: 0.6175 - f1_score: 0.0564 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 164us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0573 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 6.1810 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1197 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9373/9373 [==============================] - 1s 114us/steposs: 10.0016 - acc: 0.6205 - f1_score: 0.05\n",
      "37488/37488 [==============================] - 4s 100us/steps: 9.9564 - acc: 0.6177 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 160us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 8/20\n",
      "35840/37489 [===========================>..] - ETA: 0s - loss: 9.9555 - acc: 0.6177 - f1_score: 0.0575Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 120us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 123us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0573 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6977 - acc: 0.3833 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0573 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6655 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6642 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6655 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6643 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0573 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6646 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6665 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6647 - acc: 0.3836 - f1_score: 0.0052 - val_loss: 0.6611 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0573 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6642 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0572 - val_loss: 10.0582 - val_acc: 0.6242 - val_f1_score: 0.0568\n",
      "9372/9372 [==============================] - 1s 107us/steposs: 0.6612 - acc: 0.3784 - f1_score: 8.5928\n",
      "37489/37489 [==============================] - 4s 103us/steps: 0.6642 - acc: 0.3816 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6643 - acc: 0.3817 - f1_score: 0.0023 - val_loss: 0.6610 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 4s 117us/step - loss: 0.6641 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      " 9344/37489 [======>.......................] - ETA: 3s - loss: 0.6660 - acc: 0.4904 - f1_score: 0.3226Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 120us/step - loss: 0.6645 - acc: 0.4089 - f1_score: 0.0826 - val_loss: 0.6636 - val_acc: 0.3778 - val_f1_score: 3.7819e-04\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6637 - acc: 0.3813 - f1_score: 1.5678e-04 - val_loss: 0.6613 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6700 - acc: 0.3834 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 0.6634 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6637 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6636 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6636 - acc: 0.3816 - f1_score: 1.0506e-04 - val_loss: 0.6660 - val_acc: 0.3787 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6633 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3791 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 110us/steposs: 0.6648 - acc: 0.3815 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 4s 100us/steps: 0.6618 - acc: 0.3762 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 5s 136us/step - loss: 0.6642 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "13824/37489 [==========>...................] - ETA: 2s - loss: 0.6651 - acc: 0.3830 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 119us/step - loss: 0.6643 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6639 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9166 - acc: 0.3826 - f1_score: 0.3790 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 0.6636 - acc: 0.3813 - f1_score: 5.2935e-05 - val_loss: 0.6611 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6637 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6652 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6633 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6634 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6676 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6629 - acc: 0.3808 - f1_score: 5.2935e-05 - val_loss: 0.6647 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6628 - acc: 0.3809 - f1_score: 5.2935e-05 - val_loss: 0.6616 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6627 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6624 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6605 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6623 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6626 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6629 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6708 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 102us/steposs: 9.9957 - acc: 0.3798 - f1_score: 0.37\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 4s 101us/steps: 9.9096 - acc: 0.3852 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "20096/37489 [===============>..............] - ETA: 1s - loss: 9.9583 - acc: 0.3822 - f1_score: 0.3822Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 117us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 0.6691 - acc: 0.3870 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6648 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 100us/steposs: 0.6642 - acc: 0.3817 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6645 - acc: 0.3813 - f1_sco\n",
      "37488/37488 [==============================] - 6s 165us/step - loss: 0.6644 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 5s 128us/step - loss: 0.6648 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      " 2176/37488 [>.............................] - ETA: 3s - loss: 0.6637 - acc: 0.3768 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 120us/step - loss: 0.6643 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6639 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6672 - acc: 0.6158 - f1_score: 0.6668 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 0.6639 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6642 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 176us/step - loss: 0.6640 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6636 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6654 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 0.6635 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6649 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6635 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6649 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6634 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6655 - acc: 0.6167 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6637 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6643 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6633 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6647 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6635 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6645 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 7s 176us/step - loss: 0.6635 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 1s 96us/steploss: 0.6643 - acc: 0.617\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6644 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 4s 101us/steps: 0.6633 - acc: 0.6203 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6645 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "29824/37489 [======================>.......] - ETA: 0s - loss: 0.6636 - acc: 0.6184 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 117us/step - loss: 0.6640 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 127us/step - loss: 0.6645 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6639 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6639 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6230 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6641 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6638 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6634 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "9372/9372 [==============================] - 1s 94us/steploss: 6.0522 - acc: 0.6245 - f1_score: 0.62\n",
      "37489/37489 [==============================] - 4s 101us/steps: 6.1225 - acc: 0.6202 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 157us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37248/37489 [============================>.] - ETA: 0s - loss: 6.1503 - acc: 0.6184 - f1_score: 0.6184Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 4s 119us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6662 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6644 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6648 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6644 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6638 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6641 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6639 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6634 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6633 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 1s 94us/steploss: 0.6633 - acc: 0.3816 - f1_score\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6633 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 4s 103us/steps: 0.6625 - acc: 0.3800 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6630 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "29952/37489 [======================>.......] - ETA: 0s - loss: 0.6635 - acc: 0.3819 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 117us/step - loss: 0.6632 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 125us/step - loss: 0.6632 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6627 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.6671 - acc: 0.3845 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6626 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6632 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6625 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6624 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6649 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "9372/9372 [==============================] - 1s 95us/steploss: 0.6677 - acc: 0.3897 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6643 - acc: 0.3815 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 6s 157us/step - loss: 0.6648 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "32768/37489 [=========================>....] - ETA: 0s - loss: 0.6649 - acc: 0.3830 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 121us/step - loss: 0.6647 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 0.6649 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6643 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 6.1283 - acc: 0.6177 - f1_score: 0.6177 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6640 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6642 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6639 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6643 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6638 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6637 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6635 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6633 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6630 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6630 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6631 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 105us/steposs: 6.0958 - acc: 0.6218 - f1_score: 0.\n",
      "37489/37489 [==============================] - 4s 103us/steps: 6.1369 - acc: 0.6193 - f1_score: 0.61\n",
      "37488/37488 [==============================] - 6s 162us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 4s 117us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      " 1152/37488 [..............................] - ETA: 4s - loss: 6.2262 - acc: 0.6137 - f1_score: 0.6137Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 4s 117us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 163us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 323us/step - loss: 6.1469 - acc: 0.6167 - f1_score: 0.6167 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 161us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9373/9373 [==============================] - 1s 101us/steposs: 6.1746 - acc: 0.6169 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 4s 100us/steps: 6.1789 - acc: 0.6166 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "23680/37489 [=================>............] - ETA: 1s - loss: 6.1784 - acc: 0.6167 - f1_score: 0.6167Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 120us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 5s 134us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 9.9278 - acc: 0.3840 - f1_score: 0.3778 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 1s 102us/steposs: 9.9559 - acc: 0.3823 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 4s 103us/steps: 10.3257 - acc: 0.3594 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 124us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      " 8576/37489 [=====>........................] - ETA: 3s - loss: 9.8708 - acc: 0.3876 - f1_score: 0.3876Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 120us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 12s 328us/step - loss: 0.7110 - acc: 0.6179 - f1_score: 0.6641 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6655 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 110us/steposs: 0.6651 - acc: 0.6188 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 4s 102us/steps: 0.6644 - acc: 0.6200 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 137us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "15232/37489 [===========>..................] - ETA: 2s - loss: 0.6644 - acc: 0.6199 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 123us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 331us/step - loss: 0.8834 - acc: 0.3834 - f1_score: 5.2491e-04 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6660 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6646 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6652 - acc: 0.5590 - f1_score: 0.4991 - val_loss: 0.6620 - val_acc: 0.3756 - val_f1_score: 0.0026\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0012 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6651 - acc: 0.4155 - f1_score: 0.1036 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 1.0346e-04 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 107us/steposs: 0.6657 - acc: 0.3827 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 4s 106us/steps: 0.6661 - acc: 0.3831 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 5s 133us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "19072/37489 [==============>...............] - ETA: 2s - loss: 0.6662 - acc: 0.3837 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 5s 134us/step - loss: 0.6657 - acc: 0.3832 - f1_score: 0.0023 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 13s 337us/step - loss: 0.6862 - acc: 0.3954 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6656 - acc: 0.3829 - f1_score: 0.0023 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6657 - acc: 0.5836 - f1_score: 0.5712 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 95us/steploss: 0.6656 - acc: 0.3828 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6653 - acc: 0.3820 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 6s 162us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 5s 123us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      " 1152/37488 [..............................] - ETA: 4s - loss: 0.6618 - acc: 0.3759 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 121us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 333us/step - loss: 1.4369 - acc: 0.5996 - f1_score: 0.6416 - val_loss: 0.6649 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6662 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 177us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 178us/step - loss: 0.6644 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6644 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 7s 178us/step - loss: 0.6643 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6645 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 7s 176us/step - loss: 0.6640 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6641 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6643 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6642 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 1s 102us/steposs: 0.6654 - acc: 0.6175 - f1_s\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 4s 101us/steps: 0.6654 - acc: 0.6181 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "31232/37489 [=======================>......] - ETA: 0s - loss: 0.6655 - acc: 0.6173 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 119us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 9.9501 - acc: 0.3817 - f1_score: 0.3805 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 106us/steposs: 9.9695 - acc: 0.3815 - f1\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 4s 104us/steps: 10.0175 - acc: 0.3785 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "31360/37489 [========================>.....] - ETA: 0s - loss: 9.9479 - acc: 0.3828 - f1_score: 0.3828Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 124us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 126us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 1.0624 - acc: 0.3901 - f1_score: 9.9370e-04 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6654 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6641 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6639 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6641 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 100us/steposs: 0.6641 - acc: 0.3810 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 4s 105us/steps: 0.6641 - acc: 0.3816 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 0.6641 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 121us/step - loss: 0.6638 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      " 4480/37489 [==>...........................] - ETA: 4s - loss: 0.6627 - acc: 0.3770 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 124us/step - loss: 0.6638 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6671 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 0.6641 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 13s 340us/step - loss: 0.6683 - acc: 0.3832 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6641 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6661 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6639 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6654 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6642 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 105us/steposs: 0.6653 - acc: 0.3822 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 4s 102us/steps: 0.6647 - acc: 0.3801 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 5s 134us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "17280/37489 [============>.................] - ETA: 2s - loss: 0.6654 - acc: 0.3815 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 121us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 333us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6651 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6643 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6653 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6653 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6650 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "13568/37488 [=========>....................] - ETA: 3s - loss: 6.1084 - acc: 0.6210 - f1_score: 0.6210Epoch 14/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6649 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6651 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 176us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6653 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6649 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 107us/steposs: 6.1389 - acc: 0.6191 - f1_score: 0.61\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 4s 103us/steps: 6.1110 - acc: 0.6209 - f1_score: 0.62\n",
      "37488/37488 [==============================] - 5s 130us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "17664/37488 [=============>................] - ETA: 2s - loss: 6.1301 - acc: 0.6197 - f1_score: 0.6197Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 4s 119us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 5s 142us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "14848/37489 [==========>...................] - ETA: 11s - loss: 0.6774 - acc: 0.6124 - f1_score: 0.6529Epoch 18/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 0.6705 - acc: 0.6163 - f1_score: 0.6612 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 164us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6661 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 6s 171us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0609 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9373/9373 [==============================] - 1s 102us/steposs: 0.6648 - acc: 0.6188 - f1_score: 0.\n",
      "37488/37488 [==============================] - 4s 104us/steps: 0.6653 - acc: 0.6177 - f1_s\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6654 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 5s 121us/step - loss: 0.6649 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      " 8576/37489 [=====>........................] - ETA: 3s - loss: 0.6587 - acc: 0.6300 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 125us/step - loss: 0.6646 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 0.6683 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6643 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6647 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6641 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6641 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6646 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6634 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6640 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6636 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6220 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6640 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6635 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6637 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6605 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6631 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6228 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6637 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6631 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6603 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6631 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6626 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6629 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6605 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6628 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6631 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6627 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6626 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6623 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6623 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6628 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 1s 101us/steposs: 0.6624 - acc: 0.3800 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6626 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3783 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 4s 104us/steps: 0.6649 - acc: 0.3854 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 5s 138us/step - loss: 0.6618 - acc: 0.3800 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "26112/37489 [===================>..........] - ETA: 1s - loss: 0.6628 - acc: 0.3827 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 118us/step - loss: 0.6623 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 5s 130us/step - loss: 0.6621 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 160us/step - loss: 0.6616 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 340us/step - loss: 0.6692 - acc: 0.3833 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6616 - acc: 0.3800 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6616 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "9372/9372 [==============================] - 1s 101us/steposs: 0.6684 - acc: 0.3900 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 4s 103us/steps: 0.6649 - acc: 0.3818 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 0.6642 - acc: 0.3814 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 124us/step - loss: 0.6641 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 0.6642 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6638 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 340us/step - loss: 1.5495 - acc: 0.6159 - f1_score: 0.6518 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6638 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6659 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6632 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6633 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3753 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6629 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6628 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6650 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6624 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6648 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6624 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6647 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6623 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6654 - val_acc: 0.3793 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 0.6643 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6620 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3783 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6642 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6619 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6643 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6659 - val_acc: 0.6217 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6620 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6639 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6617 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6637 - acc: 0.6169 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6615 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6634 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "9372/9372 [==============================] - 1s 109us/steposs: 0.6662 - acc: 0.6136 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 4s 107us/steps: 0.6641 - acc: 0.6160 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6636 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 5s 121us/step - loss: 0.6634 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6217 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 121us/step - loss: 0.6632 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6603 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6630 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6685 - val_acc: 0.6203 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 13s 347us/step - loss: 0.6658 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6630 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 178us/step - loss: 0.6652 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6626 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 102us/steposs: 0.6648 - acc: 0.3816 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6643 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 4s 101us/steps: 0.6639 - acc: 0.3805 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 5s 138us/step - loss: 0.6642 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "23296/37488 [=================>............] - ETA: 1s - loss: 0.6650 - acc: 0.3829 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 121us/step - loss: 0.6644 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 5s 136us/step - loss: 0.6640 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6653 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 340us/step - loss: 0.6984 - acc: 0.6161 - f1_score: 0.6568 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6639 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6636 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 177us/step - loss: 0.6637 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6650 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 0.6635 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6648 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6630 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6648 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6632 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6645 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6627 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6648 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 176us/step - loss: 0.6626 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6647 - val_acc: 0.3791 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6629 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6643 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6641 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6620 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6642 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 7s 176us/step - loss: 0.6618 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6639 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6623 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6642 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6617 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3793 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6640 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6617 - acc: 0.3800 - f1_score: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 1s 111us/steposs: 0.6639 - acc: 0.6174 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 4s 104us/steps: 0.6637 - acc: 0.6173 - \n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6636 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 4s 119us/step - loss: 0.6637 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "11008/37489 [=======>......................] - ETA: 3s - loss: 0.6597 - acc: 0.6234 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 120us/step - loss: 0.6635 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6634 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 345us/step - loss: 0.6837 - acc: 0.3832 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6629 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6631 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6234 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9372/9372 [==============================] - 1s 109us/steposs: 0.6647 - acc: 0.3815 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 4s 104us/steps: 0.6595 - acc: 0.3718 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 5s 131us/step - loss: 0.6648 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "13696/37489 [=========>....................] - ETA: 2s - loss: 0.6673 - acc: 0.3868 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 124us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 342us/step - loss: 0.7049 - acc: 0.6146 - f1_score: 0.6484 - val_loss: 0.6638 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6647 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6655 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6647 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6643 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6645 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6639 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6637 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6645 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6636 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6642 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6634 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6640 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6633 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6642 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6645 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6635 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6644 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6631 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6645 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6629 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6640 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6627 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6641 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6624 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 111us/steposs: 0.6629 - acc: 0.6200 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6636 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 4s 105us/steps: 0.6662 - acc: 0.6130 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 132us/step - loss: 0.6636 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "19072/37489 [==============>...............] - ETA: 2s - loss: 0.6646 - acc: 0.6162 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 121us/step - loss: 0.6636 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 5s 136us/step - loss: 0.6635 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 350us/step - loss: 0.6680 - acc: 0.3832 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6636 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6630 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 97us/steploss: 0.6648 - acc: 0.3812 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 4s 103us/steps: 0.6656 - acc: 0.3829 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 5s 126us/step - loss: 0.6650 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      " 3200/37489 [=>............................] - ETA: 3s - loss: 0.6635 - acc: 0.3803 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 0.6649 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 160us/step - loss: 0.6648 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 13s 342us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6642 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6643 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6640 - acc: 0.3829 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6640 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6640 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6637 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6634 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6637 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6637 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6634 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6632 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6630 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6631 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6628 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 107us/steposs: 6.1468 - acc: 0.3814 - f1_sco\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 4s 105us/steps: 6.1097 - acc: 0.3791 - f1_score: 0.37\n",
      "37488/37488 [==============================] - 6s 148us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 17/20\n",
      "36480/37488 [============================>.] - ETA: 0s - loss: 6.1322 - acc: 0.3805 - f1_score: 0.3799Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 123us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 5s 121us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 350us/step - loss: 0.6683 - acc: 0.6164 - f1_score: 0.6665 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 161us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0516 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "9373/9373 [==============================] - 1s 111us/steposs: 0.6654 - acc: 0.6187 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6659 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 4s 103us/steps: 0.6682 - acc: 0.6120 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 143us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "27648/37489 [=====================>........] - ETA: 1s - loss: 0.6660 - acc: 0.6164 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 127us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6656 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 5s 125us/step - loss: 0.6653 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 0.6651 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 348us/step - loss: 9.0653 - acc: 0.3817 - f1_score: 0.2914 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6814 - acc: 0.6166 - f1_score: 0.6580 - val_loss: 0.6615 - val_acc: 0.6244 - val_f1_score: 0.6666\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6887 - acc: 0.6164 - f1_score: 0.6633 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6661 - acc: 0.6161 - f1_score: 0.6621 - val_loss: 0.6638 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6749 - acc: 0.6173 - f1_score: 0.6647 - val_loss: 0.6621 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6829 - acc: 0.6173 - f1_score: 0.6644 - val_loss: 0.6618 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6652 - acc: 0.6172 - f1_score: 0.6645 - val_loss: 1.1981 - val_acc: 0.6230 - val_f1_score: 0.6394\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6661 - acc: 0.6116 - f1_score: 0.6484 - val_loss: 0.6615 - val_acc: 0.6236 - val_f1_score: 0.6665\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6702 - acc: 0.6153 - f1_score: 0.6631 - val_loss: 0.6615 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6675 - acc: 0.6159 - f1_score: 0.6631 - val_loss: 0.6612 - val_acc: 0.6228 - val_f1_score: 0.6665\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6702 - acc: 0.6154 - f1_score: 0.6615 - val_loss: 0.6618 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6907 - acc: 0.4931 - f1_score: 0.3036 - val_loss: 0.6660 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6671 - acc: 0.5423 - f1_score: 0.4528 - val_loss: 0.6613 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6693 - acc: 0.4733 - f1_score: 0.2621 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 115us/steposs: 9.8768 - acc: 0.3870 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 4s 105us/steps: 9.9656 - acc: 0.3815 - f1_score\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "11136/37489 [=======>......................] - ETA: 2s - loss: 10.0593 - acc: 0.3756 - f1_score: 0.3756Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 119us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 9.9421 - acc: 0.3818 - f1_score: 0.3818 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 9.9618 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 114us/steposs: 10.0023 - acc: 0.3794 - f1_score: 0.\n",
      "37489/37489 [==============================] - 4s 102us/steps: 9.9661 - acc: 0\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 5s 126us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "11392/37489 [========>.....................] - ETA: 3s - loss: 10.0738 - acc: 0.3750 - f1_score: 0.3750Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 126us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 1.0716 - acc: 0.3846 - f1_score: 0.0040 - val_loss: 0.6644 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 180us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 180us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6653 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6652 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6651 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6645 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6660 - val_acc: 0.3785 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6649 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6646 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 180us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6646 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 9.9704 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 104us/steposs: 0.6646 - acc: 0.3829 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6645 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6871 - val_acc: 0.5216 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 4s 106us/steps: 0.6639 - acc: 0.3813 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 5s 136us/step - loss: 0.6646 - acc: 0.3829 - f1_score: 0.0000e+00 - val_loss: 0.6660 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "36096/37489 [===========================>..] - ETA: 0s - loss: 0.6640 - acc: 0.3810 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 125us/step - loss: 0.6644 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 0.6643 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6643 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 118us/steposs: 9.4419 - acc: 0.6195 - f1_score: 0.\n",
      "37488/37488 [==============================] - 14s 371us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0432 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 93us/stepss: 9.5194 - acc: 0.6197 - f1_score: 0.03\n",
      "37488/37488 [==============================] - 5s 143us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 3/20\n",
      "23168/37488 [=================>............] - ETA: 1s - loss: 9.3746 - acc: 0.6155 - f1_score: 0.0403Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 126us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0432 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 5s 131us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.7001 - acc: 0.3833 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 180us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6651 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 180us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 176us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 7s 178us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0432 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6649 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 7s 179us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0432 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6647 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 7s 179us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6648 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 182us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6648 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 7s 177us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6647 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 7s 176us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6641 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 7s 179us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6647 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 7s 180us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      " 8448/37489 [=====>........................] - ETA: 4s - loss: 0.6667 - acc: 0.3872 - f1_score: 0.0000e+00Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6646 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 7s 178us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6642 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6656 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 7s 180us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0432 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6641 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0432 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6641 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 180us/step - loss: 9.4370 - acc: 0.6188 - f1_score: 0.0433 - val_loss: 9.5033 - val_acc: 0.6242 - val_f1_score: 0.0436\n",
      "9373/9373 [==============================] - 1s 114us/steposs: 0.6666 - acc: 0.3878 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6643 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 4s 106us/steps: 0.6753 - acc: 0.3975 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 5s 132us/step - loss: 0.6642 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "18560/37489 [=============>................] - ETA: 2s - loss: 0.6627 - acc: 0.3830 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 122us/step - loss: 0.6634 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 5s 132us/step - loss: 0.6636 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 115us/steploss: 9.9942 - acc: 0.3799 - f1_score: 0.\n",
      "37489/37489 [==============================] - 4s 103us/steps: 9.9695 - acc: 0.3815 - f1_score: \n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 5s 125us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      " 3968/37489 [==>...........................] - ETA: 4s - loss: 9.9519 - acc: 0.3826 - f1_score: 0.3826Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 5s 127us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.7021 - acc: 0.6168 - f1_score: 0.6641 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6643 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6644 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6643 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6643 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6642 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6667 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6640 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6644 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6641 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6646 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6639 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6643 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6639 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3818 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6636 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6638 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6642 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 105us/steposs: 0.6641 - acc: 0.6177 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6637 - acc: 0.6185 - f1_score: 0.6666 - val_loss: 0.6621 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 4s 106us/steps: 0.6631 - acc: 0.6191 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 0.6632 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "35328/37489 [===========================>..] - ETA: 0s - loss: 0.6629 - acc: 0.6198 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 4s 119us/step - loss: 0.6634 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6711 - val_acc: 0.6209 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 5s 123us/step - loss: 0.6637 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 79us/step\n",
      "37489/37489 [==============================] - 4s 98us/stepss: 6.1142 - acc: 0.6207 - f1_score: 0.\n",
      "37489/37489 [==============================] - 13s 339us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "25600/37489 [===================>..........] - ETA: 1s - loss: 6.1859 - acc: 0.6162 - f1_score: 0.6162Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 128us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 5s 130us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 360us/step - loss: 0.8245 - acc: 0.3878 - f1_score: 2.1093e-04 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 7s 177us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 176us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6650 - acc: 0.5017 - f1_score: 0.3425 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6649 - acc: 0.5431 - f1_score: 0.4546 - val_loss: 0.6620 - val_acc: 0.3749 - val_f1_score: 0.0057\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0579 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 1s 104us/steposs: 0.6642 - acc: 0.3860 - f1_score: 0.\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6650 - acc: 0.3971 - f1_score: 0.0483 - val_loss: 0.6627 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 4s 105us/steps: 0.6584 - acc: 0.6321 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 5s 129us/step - loss: 0.6648 - acc: 0.5905 - f1_score: 0.5956 - val_loss: 0.6627 - val_acc: 0.6236 - val_f1_score: 0.6665\n",
      "Epoch 20/20\n",
      "17920/37488 [=============>................] - ETA: 2s - loss: 0.6674 - acc: 0.6140 - f1_score: 0.6666Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 124us/step - loss: 0.6649 - acc: 0.6189 - f1_score: 0.6666 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 1s 66us/step\n",
      "37488/37488 [==============================] - 3s 70us/step\n",
      "37489/37489 [==============================] - 12s 310us/step - loss: 0.6692 - acc: 0.3838 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "13184/37489 [=========>....................] - ETA: 3s - loss: 0.6612 - acc: 0.3730 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 128us/step - loss: 0.6658 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 0.6658 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6967 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6655 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      " 8960/37489 [======>.......................] - ETA: 4s - loss: 0.6650 - acc: 0.3808 - f1_score: 0.0000e+00Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6653 - acc: 0.5158 - f1_score: 0.3814 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 5.2528e-05 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 109us/steposs: 0.6640 - acc: 0.5978 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6652 - acc: 0.5072 - f1_score: 0.3389 - val_loss: 0.6625 - val_acc: 0.3756 - val_f1_score: 3.7819e-04\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 4s 105us/steps: 0.6595 - acc: 0.3703 - f1_score: 6.5466\n",
      "37489/37489 [==============================] - 5s 134us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 2.1011e-04 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "21888/37489 [================>.............] - ETA: 1s - loss: 0.6648 - acc: 0.3811 - f1_score: 8.1095e-04Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 124us/step - loss: 0.6652 - acc: 0.3818 - f1_score: 4.7347e-04 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 65us/step\n",
      "37489/37489 [==============================] - 3s 73us/step\n",
      "37489/37489 [==============================] - 12s 310us/step - loss: 0.7010 - acc: 0.3846 - f1_score: 0.0014 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      " 1664/37489 [>.............................] - ETA: 4s - loss: 0.6729 - acc: 0.3972 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 126us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 158us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6896 - acc: 0.6164 - f1_score: 0.6664 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6660 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6659 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6666 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6650 - acc: 0.3821 - f1_score: 0.0021 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 101us/steposs: 0.6655 - acc: 0.6175 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 4s 106us/steps: 0.6637 - acc: 0.6216 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 147us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "33152/37489 [=========================>....] - ETA: 0s - loss: 0.6654 - acc: 0.6177 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 120us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 81us/step\n",
      "37489/37489 [==============================] - 3s 69us/step\n",
      "36992/37488 [============================>.] - ETA: 0s - loss: 0.6885 - acc: 0.6185 - f1_score: 0.6663Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 12s 309us/step - loss: 0.6882 - acc: 0.6184 - f1_score: 0.6663 - val_loss: 0.6651 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 5s 128us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6734 - acc: 0.6167 - f1_score: 0.6645 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 0.6662 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 178us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 179us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 7s 176us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 7s 177us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 177us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 7s 176us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6646 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6648 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 7s 178us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6647 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 7s 177us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6647 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 7s 179us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6647 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6653 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 7s 177us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6647 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6691 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6642 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 180us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6641 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 180us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6642 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 179us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 1s 100us/steposs: 0.6603 - acc: 0.6237 - f1_score: 0.\n",
      "37488/37488 [==============================] - 4s 108us/steps: 0.6636 - acc: 0.6182 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6639 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 5s 123us/step - loss: 0.6638 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 70us/step\n",
      " 8576/37489 [=====>........................] - ETA: 2sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 74us/step\n",
      "19456/37489 [==============>...............] - ETA: 7s - loss: 0.6800 - acc: 0.6164 - f1_score: 0.6625Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 301us/step - loss: 0.6729 - acc: 0.6175 - f1_score: 0.6645 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 147us/step - loss: 0.6656 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6680 - acc: 0.6176 - f1_score: 0.6654 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6650 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6654 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6651 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6647 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6645 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6645 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6658 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6642 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6641 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6638 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6638 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6635 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 0.6637 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6645 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6636 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6690 - val_acc: 0.6211 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6634 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6644 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6632 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 114us/steposs: 0.6660 - acc: 0.6159 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 4s 108us/steps: 0.6649 - acc: 0.6180 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 82us/step\n",
      "33408/37489 [=========================>....] - ETA: 0sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 74us/step\n",
      " 1664/37489 [>.............................] - ETA: 2:04 - loss: 0.7203 - acc: 0.5938 - f1_score: 0.6424Train on 37488 samples, validate on 5207 samples\n",
      " 2176/37489 [>.............................] - ETA: 1:34 - loss: 0.7087 - acc: 0.6002 - f1_score: 0.6481Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 294us/step - loss: 0.6686 - acc: 0.6164 - f1_score: 0.6656 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 11s 282us/step - loss: 9.1490 - acc: 0.3812 - f1_score: 0.3766 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 157us/step - loss: 0.6660 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 180us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16640/37489 [============>.................] - ETA: 3s - loss: 0.6646 - acc: 0.6189 - f1_score: 0.6667Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6658 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 87us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 87us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1449 - acc: 0.3812 - f1_score: 0.3810 - val_loss: 6.0671 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "9373/9373 [==============================] - 1s 61us/steploss: 0.6659 - acc: 0.6165 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 2s 56us/stepss: 0.6660 - acc: 0.6163 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 126us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "11264/37489 [========>.....................] - ETA: 3s - loss: 0.6658 - acc: 0.6166 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 127us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 11s 293us/step - loss: 0.7168 - acc: 0.3893 - f1_score: 0.0000e+00 - val_loss: 0.6698 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6663 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6670 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6652 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6651 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6657 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6647 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 180us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6644 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6644 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6641 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6639 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 119us/steposs: 0.6636 - acc: 0.3816 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6639 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6696 - val_acc: 0.3789 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 4s 110us/steps: 0.6635 - acc: 0.3823 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6635 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6636 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 2s 61us/step - loss: 0.6634 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "25088/37489 [===================>..........] - ETA: 0s - loss: 0.6633 - acc: 0.3815 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6634 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6633 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 0.6630 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 81us/step - loss: 0.6628 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6638 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 11s 291us/step - loss: 9.9497 - acc: 0.3817 - f1_score: 0.3803 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 82us/step - loss: 0.6629 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6685 - val_acc: 0.3801 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6629 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6714 - val_acc: 0.3814 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 55us/steploss: 10.0455 - acc: 0.3767 - f1_score: 0.37\n",
      "37489/37489 [==============================] - 2s 53us/stepss: 9.9656 - acc: 0.3815 - f1_s\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "31744/37489 [========================>.....] - ETA: 0s - loss: 9.9413 - acc: 0.3830 - f1_score: 0.3830Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 77us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 11s 292us/step - loss: 0.6674 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6642 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6706 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6638 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6637 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6631 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6656 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6633 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6632 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9622 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 0s 51us/steploss: 0.6629 - acc: 0.3818 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6627 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 2s 52us/stepss: 0.6579 - acc: 0.3713 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6625 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 0.6625 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 2s 61us/step - loss: 0.6622 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "  256/37489 [..............................] - ETA: 1s - loss: 0.6785 - acc: 0.4062 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6620 - acc: 0.3797 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6618 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6617 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 84us/step - loss: 0.6615 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 11s 293us/step - loss: 0.6698 - acc: 0.3885 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 84us/step - loss: 0.6610 - acc: 0.3799 - f1_score: 0.0000e+00 - val_loss: 0.6643 - val_acc: 0.3799 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 0s 52us/steploss: 0.6662 - acc: 0.3831 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6659 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 54us/stepss: 0.6649 - acc: 0.3809 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 3s 76us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6653 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 2s 61us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "19200/37489 [==============>...............] - ETA: 1s - loss: 0.6650 - acc: 0.3831 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6650 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6648 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6647 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 82us/step - loss: 0.6644 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 11s 293us/step - loss: 0.6670 - acc: 0.6182 - f1_score: 0.6662 - val_loss: 0.6623 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 81us/step - loss: 0.6644 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "13056/37488 [=========>....................] - ETA: 1s - loss: 0.6626 - acc: 0.6225 - f1_score: 0.6667Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 87us/step - loss: 0.6644 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6641 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 86us/step - loss: 0.6644 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6637 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 0.6641 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6639 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 87us/step - loss: 0.6636 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6637 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 0.6638 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6637 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 0.6642 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6635 - acc: 0.3832 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6634 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6633 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6631 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6631 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6655 - val_acc: 0.3803 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6633 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6632 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6629 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6228 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6629 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6604 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 0s 51us/steploss: 0.6628 - acc: 0.6198 - f1_score: 0.\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 0.6632 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6234 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 2s 56us/stepss: 0.6579 - acc: 0.6242 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6633 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 2s 64us/step - loss: 0.6629 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6685 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 2s 64us/step - loss: 0.6630 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      " 5888/37488 [===>..........................] - ETA: 2s - loss: 0.6671 - acc: 0.6102 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 2s 62us/step - loss: 0.6629 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6628 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 2s 64us/step - loss: 0.6631 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 0.6621 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 11s 297us/step - loss: 0.6674 - acc: 0.3845 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 3s 81us/step - loss: 0.6622 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6228 - val_f1_score: 0.6668\n",
      "9373/9373 [==============================] - 1s 57us/steploss: 0.6657 - acc: 0.3827 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 2s 52us/stepss: 0.6661 - acc: 0.3841 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 72us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6648 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      " 7424/37489 [====>.........................] - ETA: 1s - loss: 0.6629 - acc: 0.3749 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      " 8448/37489 [=====>........................] - ETA: 1s - loss: 0.6637 - acc: 0.3772 - f1_score: 0.0000e+00Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6649 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6645 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6646 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 11s 297us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 84us/step - loss: 0.6641 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6643 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6638 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6634 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6635 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6635 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6631 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6630 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6626 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6635 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6624 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 0s 52us/steploss: 9.9641 - acc: 0.3817 - f1_score: \n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 2s 54us/stepss: 9.9882 - acc: 0.3802 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 78us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 2s 61us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "20736/37489 [===============>..............] - ETA: 1s - loss: 9.9922 - acc: 0.3801 - f1_score: 0.3801Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 11s 297us/step - loss: 0.6673 - acc: 0.6153 - f1_score: 0.6660 - val_loss: 0.6659 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 81us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 54us/steploss: 0.6657 - acc: 0.6185 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 53us/step\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6641 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "36608/37489 [============================>.] - ETA: 0s - loss: 0.6639 - acc: 0.6192 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6643 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6644 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6639 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 72us/step - loss: 0.6640 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 83us/step - loss: 0.6638 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 11s 300us/step - loss: 0.7099 - acc: 0.6156 - f1_score: 0.6502 - val_loss: 0.6625 - val_acc: 0.6240 - val_f1_score: 0.6666\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6636 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6666 - val_loss: 0.6627 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6632 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6666 - val_loss: 0.6625 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6634 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6666 - val_loss: 0.6623 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6631 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6666\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6634 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6650 - acc: 0.6176 - f1_score: 0.6666 - val_loss: 0.6622 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6635 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6648 - acc: 0.6176 - f1_score: 0.6666 - val_loss: 0.6635 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6629 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6647 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6648 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6631 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6627 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6240 - val_f1_score: 0.6666\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6648 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6628 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6644 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6236 - val_f1_score: 0.6666\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6621 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6222 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 1s 58us/steploss: 0.6626 - acc: 0.6215 - f1_score: 0.\n",
      "37489/37489 [==============================] - 2s 53us/stepss: 0.6639 - acc: 0.6182 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 84us/step - loss: 0.6643 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6234 - val_f1_score: 0.6666\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6646 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6638 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6648 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "26624/37489 [====================>.........] - ETA: 0s - loss: 0.6645 - acc: 0.6171 - f1_score: 0.6666Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6642 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6236 - val_f1_score: 0.6666\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6644 - acc: 0.6171 - f1_score: 0.6666 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6666\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 67us/step - loss: 0.6640 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6234 - val_f1_score: 0.6666\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 76us/step - loss: 0.6643 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 11s 303us/step - loss: 9.9569 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 79us/step - loss: 0.6639 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6234 - val_f1_score: 0.6666\n",
      "9372/9372 [==============================] - 1s 64us/steploss: 10.0523 - acc: 0.6238 - f1_score: 0.\n",
      "37489/37489 [==============================] - 2s 55us/stepss: 9.9543 - acc: 0.6176 - f1_score: 0.\n",
      "37488/37488 [==============================] - 3s 87us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 70us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "29696/37488 [======================>.......] - ETA: 0s - loss: 9.9647 - acc: 0.6183 - f1_score: 0.6183Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 2s 63us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 68us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 74us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 11s 303us/step - loss: 0.9942 - acc: 0.3851 - f1_score: 0.0000e+00 - val_loss: 0.6770 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 3s 80us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6665 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6648 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6645 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6642 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6645 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6642 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6645 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6658 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 9.9741 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9373/9373 [==============================] - 1s 58us/steploss: 0.6617 - acc: 0.3774 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 2s 55us/stepss: 0.6636 - acc: 0.3814 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6640 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6638 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6639 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "30464/37489 [=======================>......] - ETA: 0s - loss: 0.6639 - acc: 0.3827 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 0.6636 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6646 - val_acc: 0.3789 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6636 - acc: 0.3829 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3783 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6638 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 71us/step - loss: 0.6632 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 81us/step - loss: 0.6633 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 11s 304us/step - loss: 0.8566 - acc: 0.3870 - f1_score: 0.0014 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "9372/9372 [==============================] - 0s 51us/steploss: 0.6692 - acc: 0.3875 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 2s 58us/stepss: 0.6663 - acc: 0.3833 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 84us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "27392/37489 [====================>.........] - ETA: 0s - loss: 0.6661 - acc: 0.3842 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6648 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 75us/step - loss: 0.6645 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 11s 305us/step - loss: 6.1161 - acc: 0.6182 - f1_score: 0.6142 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 81us/step - loss: 0.6654 - acc: 0.4968 - f1_score: 0.3343 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6650 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6650 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 0s 52us/steploss: 6.3071 - acc: 0.6087 - f1_score: 0.60\n",
      "37489/37489 [==============================] - 2s 58us/stepss: 6.1396 - acc: 0.6191 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "35840/37489 [===========================>..] - ETA: 0s - loss: 6.1653 - acc: 0.6175 - f1_score: 0.6175Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 60us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 84us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0557 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 0s 43us/step\n",
      "37489/37489 [==============================] - 11s 303us/step - loss: 3.1955 - acc: 0.5516 - f1_score: 0.5825 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 2s 51us/stepss: 0.6668 - acc: 0.6167 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 0.6663 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 61us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "20480/37489 [===============>..............] - ETA: 1s - loss: 0.6658 - acc: 0.6172 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6650 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 79us/step - loss: 0.6651 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6643 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 12s 310us/step - loss: 0.7332 - acc: 0.3862 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 82us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6647 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6655 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6642 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6646 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6638 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6680 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6647 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6640 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6715 - val_acc: 0.6207 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6641 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6644 - acc: 0.6160 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6636 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6642 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6633 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6640 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6632 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6639 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 0.6632 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6641 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6629 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6662 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 0s 50us/steploss: 0.6632 - acc: 0.3805 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 3s 87us/step - loss: 0.6637 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 2s 58us/stepss: 0.6641 - acc: 0.3832 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 3s 70us/step - loss: 0.6632 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6632 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 3s 67us/step - loss: 0.6628 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      " 3840/37488 [==>...........................] - ETA: 2s - loss: 0.6603 - acc: 0.3745 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 2s 61us/step - loss: 0.6628 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 2s 65us/step - loss: 0.6630 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6630 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6627 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 0s 47us/steploss: 0.6730 - acc: 0.6086 - \n",
      "37489/37489 [==============================] - 12s 308us/step - loss: 0.6729 - acc: 0.6086 - f1_score: 0.6628 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 2s 47us/stepss: 0.6664 - acc: 0.6153 - f1_score: 0.66\n",
      "14336/37489 [==========>...................] - ETA: 1s - loss: 0.6673 - acc: 0.6134 - f1_score: 0.6667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed: 306.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 3s 77us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      " 9984/37489 [======>.......................] - ETA: 1s - loss: 0.6653 - acc: 0.6171 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6651 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6650 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 311us/step - loss: 0.7278 - acc: 0.3838 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 82us/step - loss: 0.6649 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6655 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6649 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6647 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6651 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6655 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6647 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6652 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6653 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6645 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6646 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6646 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6646 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6645 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6646 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6645 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6644 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6646 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6642 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6646 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 0s 53us/steploss: 0.6640 - acc: 0.3820 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6640 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 2s 58us/stepss: 0.6628 - acc: 0.3794 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 0.6637 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6636 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6635 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "19968/37489 [==============>...............] - ETA: 1s - loss: 0.6626 - acc: 0.3815 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6637 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6639 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6633 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 78us/step - loss: 0.6630 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 59us/steploss: 0.6702 - acc: 0.3885 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 2s 46us/stepss: 0.6689 \n",
      "37489/37489 [==============================] - 12s 308us/step - loss: 0.6687 - acc: 0.3864 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 72us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "35072/37489 [===========================>..] - ETA: 0s - loss: 0.6636 - acc: 0.3794 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6694 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6641 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6643 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6642 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.7253 - acc: 0.6147 - f1_score: 0.6570 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6637 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6634 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6636 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6644 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6632 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6633 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 0.6628 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6629 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6653 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6651 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6629 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6651 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6627 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6651 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6625 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6648 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6627 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6653 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6645 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6620 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6644 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "9372/9372 [==============================] - 1s 59us/steploss: 0.6635 - acc: 0.6233 - f1_score: 0.\n",
      "37489/37489 [==============================] - 2s 57us/stepss: 0.6633 - acc: 0.6195 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 83us/step - loss: 0.6644 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6638 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6217 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6639 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "29184/37489 [======================>.......] - ETA: 0s - loss: 0.6638 - acc: 0.6168 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6635 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6633 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6632 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 73us/step - loss: 0.6632 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 60us/step loss: 0.7619 - acc: 0.6123 - f1_score: 0.\n",
      "37489/37489 [==============================] - 2s 50us/stepss: 0.7106 - acc: 0.6162 - f1\n",
      "37488/37488 [==============================] - 12s 312us/step - loss: 0.7097 - acc: 0.6167 - f1_score: 0.6658 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6654 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6651 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6644 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "30720/37488 [=======================>......] - ETA: 0s - loss: 0.6644 - acc: 0.6198 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 2s 65us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 2s 65us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 74us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 84us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.7089 - acc: 0.6160 - f1_score: 0.6648 - val_loss: 0.6669 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6669 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6655 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6660 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 4s 93us/step - loss: 0.6649 - acc: 0.6152 - f1_score: 0.6578 - val_loss: 0.6623 - val_acc: 0.6251 - val_f1_score: 0.6662\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.4381 - f1_score: 0.1615 - val_loss: 0.6624 - val_acc: 0.3762 - val_f1_score: 0.0015\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 2.6468e-04 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "9373/9373 [==============================] - 1s 62us/steploss: 0.6651 - acc: 0.6182 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 2s 55us/stepss: 0.6650 - acc: 0.6186 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6656 - acc: 0.4271 - f1_score: 0.1242 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "32256/37489 [========================>.....] - ETA: 0s - loss: 0.6656 - acc: 0.3828 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "33280/37489 [=========================>....] - ETA: 0s - loss: 0.6659 - acc: 0.3834 - f1_score: 0.0000e+00Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 67us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 57us/step loss: 9.8618 - acc: 0.6120 - f1_score: 0.59\n",
      "37489/37489 [==============================] - 2s 53us/stepss: 9.9248 - acc: 0.6158 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 309us/step - loss: 9.9231 - acc: 0.6157 - f1_score: 0.6101 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "27904/37489 [=====================>........] - ETA: 0s - loss: 9.9901 - acc: 0.6198 - f1_score: 0.6198Train on 37489 samples, validate on 5207 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 76us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 81us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 6.1147 - acc: 0.6166 - f1_score: 0.6142 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6182 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 0s 53us/steploss: 6.2030 - acc: 0.6152 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 2s 55us/stepss: 6.1518 - acc: 0.6183 - f1_score\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37120/37489 [============================>.] - ETA: 0s - loss: 6.1494 - acc: 0.6185 - f1_score: 0.6185Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 61us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 0s 49us/step- loss: 9.1734 - acc: 0.6025 - f1_score: 0.\n",
      "37489/37489 [==============================] - 2s 54us/stepss: 9.8756 - acc: 0.6165 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 12s 310us/step - loss: 9.8969 - acc: 0.6170 - f1_score: 0.6134 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 4/20\n",
      "16384/37489 [============>.................] - ETA: 1s - loss: 9.9715 - acc: 0.6187 - f1_score: 0.6184Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 78us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 12s 321us/step - loss: 4.6234 - acc: 0.4842 - f1_score: 1.0629e-04 - val_loss: 0.6644 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 83us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6171 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "9372/9372 [==============================] - 1s 54us/steploss: 0.6614 - acc: 0.3745 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 2s 57us/stepss: 0.6646 - acc: 0.3810 - f1_score: 0.00\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 2s 64us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 2s 65us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 67us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      " 2048/37488 [>.............................] - ETA: 2s - loss: 0.6723 - acc: 0.3965 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 2s 61us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 2s 67us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 0s 41us/step\n",
      "37488/37488 [==============================] - 2s 50us/stepss: 0.6720 - acc: 0.6134 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 12s 310us/step - loss: 0.6689 - acc: 0.6162 - f1_score: 0.6650 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      " 9472/37489 [======>.......................] - ETA: 1s - loss: 0.6649 - acc: 0.6190 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6662 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 83us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.7114 - acc: 0.3856 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 82us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6650 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6648 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6651 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6648 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6653 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6648 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6650 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6646 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6648 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6645 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6652 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6644 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6645 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6643 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6648 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 61us/steploss: 0.6628 - acc: 0.3799 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6639 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 2s 56us/stepss: 0.6632 - acc: 0.3812 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 3s 71us/step - loss: 0.6644 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 0.6638 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6634 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "33280/37489 [=========================>....] - ETA: 0s - loss: 0.6641 - acc: 0.3822 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6639 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6632 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6644 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 0s 34us/step\n",
      "37489/37489 [==============================] - 2s 40us/step\n",
      "37489/37489 [==============================] - 11s 304us/step - loss: 9.7639 - acc: 0.6185 - f1_score: 0.6188 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "14336/37489 [==========>...................] - ETA: 1s - loss: 10.0019 - acc: 0.6207 - f1_score: 0.6207Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6706 - acc: 0.3845 - f1_score: 0.0000e+00 - val_loss: 0.6654 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 82us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6660 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6650 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6661 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6653 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6651 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9699 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 1s 59us/steploss: 0.6645 - acc: 0.3809 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6653 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 54us/stepss: 0.6679 - acc: 0.3883 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 73us/step - loss: 0.6650 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6649 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "16896/37489 [============>.................] - ETA: 1s - loss: 0.6641 - acc: 0.3810 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6650 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6650 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 0s 43us/step\n",
      "37489/37489 [==============================] - 1s 38us/step\n",
      "37488/37488 [==============================] - 11s 290us/step - loss: 0.6702 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37376/37488 [============================>.] - ETA: 0s - loss: 0.6654 - acc: 0.3813 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6653 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 2s 67us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 2s 64us/step - loss: 0.6644 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6669 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6642 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 12s 329us/step - loss: 0.6687 - acc: 0.6175 - f1_score: 0.6660 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 3s 83us/step - loss: 0.6637 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6661 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6658 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6635 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6632 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6653 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6634 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6651 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6632 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6701 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6648 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6629 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6604 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6648 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6625 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6643 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6653 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6627 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6657 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6640 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6696 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 0.6624 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6641 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6623 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6637 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6622 - acc: 0.3800 - f1_score: 0.0000e+00 - val_loss: 0.6604 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6635 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6622 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6602 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6634 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6682 - val_acc: 0.6207 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6623 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6633 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6649 - val_acc: 0.6228 - val_f1_score: 0.6669\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 0.6618 - acc: 0.3797 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6632 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "9373/9373 [==============================] - 0s 50us/steploss: 0.6731 - acc: 0.5820 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 2s 57us/stepss: 0.6638 - acc: 0.6161 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 81us/step - loss: 0.6631 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6702 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6630 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6670 - val_acc: 0.6197 - val_f1_score: 0.6666\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 60us/step - loss: 0.6627 - acc: 0.6174 - f1_score: 0.6668 - val_loss: 0.6630 - val_acc: 0.6213 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 0.6624 - acc: 0.6178 - f1_score: 0.6668Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6624 - acc: 0.6179 - f1_score: 0.6668 - val_loss: 0.6617 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6625 - acc: 0.6182 - f1_score: 0.6668 - val_loss: 0.6626 - val_acc: 0.6211 - val_f1_score: 0.6666\n",
      "9372/9372 [==============================] - 0s 38us/step\n",
      "37489/37489 [==============================] - 1s 35us/step\n",
      "37489/37489 [==============================] - 11s 291us/step - loss: 0.6668 - acc: 0.6178 - f1_score: 0.6663 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "29696/37489 [======================>.......] - ETA: 0s - loss: 0.6664 - acc: 0.6165 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6647 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6647 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6642 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 344us/step - loss: 7.8912 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 82us/step - loss: 0.6640 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6637 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6635 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6630 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6634 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6629 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6629 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6629 - acc: 0.6198 - f1_score: 0.6666 - val_loss: 0.6611 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6622 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6603 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6623 - acc: 0.6197 - f1_score: 0.6667 - val_loss: 0.6654 - val_acc: 0.6217 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6618 - acc: 0.6201 - f1_score: 0.6667 - val_loss: 0.6693 - val_acc: 0.6242 - val_f1_score: 0.6666\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6618 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6691 - val_acc: 0.6232 - val_f1_score: 0.6665\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6613 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6669 - val_acc: 0.6234 - val_f1_score: 0.6665\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6618 - acc: 0.6200 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 56us/steploss: 7.8444 - acc: 0.6182 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 55us/stepss: 7.8516 - acc: 0.6163 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 3s 74us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "27136/37489 [====================>.........] - ETA: 0s - loss: 7.8648 - acc: 0.6184 - f1_score: 0.6184Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 7.8980 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 7.6922 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 0s 45us/step\n",
      "37489/37489 [==============================] - 1s 36us/step\n",
      "37489/37489 [==============================] - 11s 293us/step - loss: 0.7733 - acc: 0.6118 - f1_score: 0.6318 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "28416/37489 [=====================>........] - ETA: 0s - loss: 0.6658 - acc: 0.6176 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6659 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6644 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6649 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6657 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 13s 351us/step - loss: 0.6823 - acc: 0.3843 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 78us/step - loss: 0.6648 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6657 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6646 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6654 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6644 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6653 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6641 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6640 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6638 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6642 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6636 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6643 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6635 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6641 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6635 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6249 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6639 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6632 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6247 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6636 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6630 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6637 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6627 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6636 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6630 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6635 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6627 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 1s 59us/steploss: 0.6625 - acc: 0.3806 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6635 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 54us/stepss: 0.6632 - acc: 0.3809 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 3s 73us/step - loss: 0.6631 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 2s 64us/step - loss: 0.6633 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6629 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "21504/37488 [================>.............] - ETA: 0s - loss: 0.6620 - acc: 0.3790 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 3s 68us/step - loss: 0.6635 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 2s 62us/step - loss: 0.6630 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 0s 42us/step\n",
      "37488/37488 [==============================] - 1s 39us/step\n",
      "37489/37489 [==============================] - 11s 296us/step - loss: 0.7494 - acc: 0.5880 - f1_score: 0.6420 - val_loss: 0.6624 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 0.6654 - acc: 0.6177 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6654 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6652 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6651 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6649 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 85us/step - loss: 0.6649 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 0.7110 - acc: 0.6098 - f1_score: 0.6181 - val_loss: 0.6654 - val_acc: 0.6242 - val_f1_score: 0.6656\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 83us/step - loss: 0.6648 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6656 - acc: 0.6183 - f1_score: 0.6658 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6652\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6650 - acc: 0.6183 - f1_score: 0.6661 - val_loss: 0.6647 - val_acc: 0.6240 - val_f1_score: 0.6663\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6646 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6648 - acc: 0.6182 - f1_score: 0.6666 - val_loss: 0.6623 - val_acc: 0.6238 - val_f1_score: 0.6656\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6643 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6226 - val_f1_score: 0.6666\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6646 - acc: 0.6182 - f1_score: 0.6665 - val_loss: 0.6622 - val_acc: 0.6238 - val_f1_score: 0.6659\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6643 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6641 - acc: 0.6182 - f1_score: 0.6664 - val_loss: 0.6636 - val_acc: 0.6242 - val_f1_score: 0.6665\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6642 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6230 - val_f1_score: 0.6666\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6646 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6645 - val_acc: 0.6236 - val_f1_score: 0.6656\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6642 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6232 - val_f1_score: 0.6666\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6639 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6234 - val_f1_score: 0.6665\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6644 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6230 - val_f1_score: 0.6666\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6637 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6234 - val_f1_score: 0.6666\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6646 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6226 - val_f1_score: 0.6666\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6639 - acc: 0.6184 - f1_score: 0.6666 - val_loss: 0.6620 - val_acc: 0.6236 - val_f1_score: 0.6665\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6644 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6224 - val_f1_score: 0.6666\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6636 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6232 - val_f1_score: 0.6666\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6639 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6638 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6232 - val_f1_score: 0.6665\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6638 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6226 - val_f1_score: 0.6666\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6635 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6232 - val_f1_score: 0.6665\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6639 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6637 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6232 - val_f1_score: 0.6664\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6640 - acc: 0.6168 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6228 - val_f1_score: 0.6666\n",
      "9372/9372 [==============================] - 1s 54us/steploss: 0.6637 - acc: 0.6179 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6636 - acc: 0.6183 - f1_score: 0.6668 - val_loss: 0.6621 - val_acc: 0.6232 - val_f1_score: 0.6666\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 58us/stepss: 0.6624 - acc: 0.6192 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 72us/step - loss: 0.6635 - acc: 0.6180 - f1_score: 0.6668 - val_loss: 0.6623 - val_acc: 0.6230 - val_f1_score: 0.6666\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6637 - acc: 0.6182 - f1_score: 0.6668 - val_loss: 0.6628 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6632 - acc: 0.6184 - f1_score: 0.6669 - val_loss: 0.6619 - val_acc: 0.6232 - val_f1_score: 0.6665\n",
      "Epoch 19/20\n",
      "27136/37489 [====================>.........] - ETA: 0s - loss: 0.6621 - acc: 0.6199 - f1_score: 0.6668Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6631 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6230 - val_f1_score: 0.6666\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6629 - acc: 0.6180 - f1_score: 0.6668 - val_loss: 0.6619 - val_acc: 0.6228 - val_f1_score: 0.6662\n",
      "9372/9372 [==============================] - 0s 36us/step\n",
      "37489/37489 [==============================] - 2s 43us/step\n",
      "37489/37489 [==============================] - 11s 300us/step - loss: 0.6654 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "29440/37489 [======================>.......] - ETA: 0s - loss: 0.6644 - acc: 0.3804 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6641 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6640 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 82us/step - loss: 0.6639 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6652 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6637 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6630 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6634 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6627 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6626 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6625 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6620 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6630 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6623 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6613 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6661 - val_acc: 0.3789 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6619 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3785 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6618 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6613 - acc: 0.3801 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3787 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 54us/steploss: 9.9399 - acc: 0.6168 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 58us/stepss: 9.9915 - acc: 0.6200 - f1_score: 0.019\n",
      "37489/37489 [==============================] - 3s 75us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 19/20\n",
      "24832/37489 [==================>...........] - ETA: 0s - loss: 9.9304 - acc: 0.6162 - f1_score: 0.0196Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 9.9497 - acc: 0.6174 - f1_score: 0.0183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0174\n",
      "9372/9372 [==============================] - 0s 38us/step\n",
      "37489/37489 [==============================] - 2s 44us/step\n",
      "37488/37488 [==============================] - 11s 298us/step - loss: 6.1103 - acc: 0.3829 - f1_score: 0.3780 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 2/20\n",
      "34560/37488 [==========================>...] - ETA: 0s - loss: 6.1455 - acc: 0.3812 - f1_score: 0.3807Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 3s 68us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 69us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 2s 64us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 2s 67us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 86us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 6.1894 - acc: 0.6175 - f1_score: 0.6134 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 3s 82us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "26112/37488 [===================>..........] - ETA: 0s - loss: 6.1332 - acc: 0.3804 - f1_score: 0.3798Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 87us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1453 - acc: 0.3812 - f1_score: 0.3806 - val_loss: 6.0558 - val_acc: 0.3758 - val_f1_score: 0.3745\n",
      "9373/9373 [==============================] - 0s 53us/steploss: 6.1588 - acc: 0.6179 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 2s 57us/stepss: 6.1116 - acc: 0.6208 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 75us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "26880/37489 [====================>.........] - ETA: 0s - loss: 6.1294 - acc: 0.6197 - f1_score: 0.6197Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 6.1645 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 0s 40us/step\n",
      "37489/37489 [==============================] - 1s 36us/step\n",
      "37489/37489 [==============================] - 11s 300us/step - loss: 7.0493 - acc: 0.3817 - f1_score: 0.3776 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "24576/37489 [==================>...........] - ETA: 0s - loss: 6.1354 - acc: 0.3806 - f1_score: 0.3806Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 348us/step - loss: 7.1882 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 79us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 6.1538 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 60us/steploss: 6.5146 - acc: 0.3829 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 53us/stepss: 6.4756 - acc: 0.3838 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 76us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "27648/37489 [=====================>........] - ETA: 0s - loss: 6.5445 - acc: 0.3831 - f1_score: 0.3831Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 6.5076 - acc: 0.3814 - f1_score: 0.3814 - val_loss: 6.5036 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 0s 49us/step\n",
      "37489/37489 [==============================] - 1s 37us/step\n",
      "37489/37489 [==============================] - 11s 301us/step - loss: 0.6711 - acc: 0.3842 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "28928/37489 [======================>.......] - ETA: 0s - loss: 0.6662 - acc: 0.3826 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6662 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6659 - acc: 0.3848 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 13s 358us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 82us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6651 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6649 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6674 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6650 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6645 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6646 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6643 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6638 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6640 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6638 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6634 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6639 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6635 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6634 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 58us/steploss: 6.1402 - acc: 0.3809 - f1_score: 0.\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 54us/stepss: 6.1072 - acc: 0.3789 - f1_score: 0.\n",
      "37488/37488 [==============================] - 3s 73us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 2s 63us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 19/20\n",
      "25088/37488 [===================>..........] - ETA: 0s - loss: 6.1297 - acc: 0.3803 - f1_score: 0.3780Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 3s 68us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 2s 63us/step - loss: 6.1440 - acc: 0.3812 - f1_score: 0.3789 - val_loss: 6.0579 - val_acc: 0.3758 - val_f1_score: 0.3720\n",
      "9373/9373 [==============================] - 0s 45us/step\n",
      "37488/37488 [==============================] - 1s 37us/step\n",
      "37489/37489 [==============================] - 12s 307us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0926 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 2/20\n",
      "27392/37489 [====================>.........] - ETA: 0s - loss: 10.0056 - acc: 0.6208 - f1_score: 0.0902Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 85us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6720 - acc: 0.6095 - f1_score: 0.6659 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6649 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0928 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0928 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6642 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6244 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0926 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6643 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6643 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6640 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6642 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0928 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6634 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6634 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0927 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6636 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.0928 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0941\n",
      "9372/9372 [==============================] - 1s 63us/steploss: 0.6627 - acc: 0.6190 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6631 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6211 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 55us/stepss: 0.6591 - acc: 0.6240 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 0.6628 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6632 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6627 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6215 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "35584/37489 [===========================>..] - ETA: 0s - loss: 0.6623 - acc: 0.6199 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6625 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6625 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 0s 47us/step\n",
      "37489/37489 [==============================] - 1s 39us/step\n",
      "37489/37489 [==============================] - 11s 304us/step - loss: 0.7369 - acc: 0.3953 - f1_score: 5.3141e-05 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "19712/37489 [==============>...............] - ETA: 1s - loss: 0.6649 - acc: 0.3811 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6701 - acc: 0.3840 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6651 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6648 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6646 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6644 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6649 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6642 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6646 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6643 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6641 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6640 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6641 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6640 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "21760/37489 [================>.............] - ETA: 1s - loss: 0.6643 - acc: 0.3839 - f1_score: 0.0000e+00Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6638 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6637 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6641 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6632 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6637 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6634 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6639 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6635 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6635 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6628 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 57us/steploss: 0.6634 - acc: 0.3821 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6635 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 53us/stepss: 0.6625 - acc: 0.3822 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 79us/step - loss: 0.6629 - acc: 0.3829 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6625 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6629 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3793 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "35328/37489 [===========================>..] - ETA: 0s - loss: 0.6619 - acc: 0.3812 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6623 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 63us/step - loss: 0.6632 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 0s 43us/step\n",
      "37489/37489 [==============================] - 1s 38us/step\n",
      "37488/37488 [==============================] - 11s 305us/step - loss: 6.1814 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "17408/37488 [============>.................] - ETA: 1s - loss: 6.0943 - acc: 0.3781 - f1_score: 0.3781Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 3s 68us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 2s 63us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 68us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.8916 - acc: 0.6161 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 3s 79us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "22784/37488 [=================>............] - ETA: 1s - loss: 6.1681 - acc: 0.3827 - f1_score: 0.3827Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 4s 100us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 4s 101us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 4s 102us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 4s 102us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 4s 105us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 4s 97us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9373/9373 [==============================] - 1s 54us/steploss: 9.9548 - acc: 0.6176 - f1_score: 1.3190e-\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 2s 56us/stepss: 9.9854 - acc: 0.6195 - f1_score: 4.0958e-\n",
      "37489/37489 [==============================] - 3s 77us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 19/20\n",
      "36352/37489 [============================>.] - ETA: 0s - loss: 9.9479 - acc: 0.6172 - f1_score: 1.6441e-04Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 1.5942e-04 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.0011\n",
      "9372/9372 [==============================] - 0s 37us/step\n",
      "37489/37489 [==============================] - 1s 38us/step\n",
      "37489/37489 [==============================] - 12s 309us/step - loss: 0.7887 - acc: 0.3833 - f1_score: 1.0628e-04 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "16128/37489 [===========>..................] - ETA: 1s - loss: 0.6654 - acc: 0.3806 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6659 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6798 - acc: 0.6064 - f1_score: 0.6666 - val_loss: 0.6688 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 81us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6657 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6649 - acc: 0.6147 - f1_score: 0.6580 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 0s 52us/steploss: 0.6652 - acc: 0.5134 - f1_score: 0.36\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6650 - acc: 0.4974 - f1_score: 0.3242 - val_loss: 0.6622 - val_acc: 0.3760 - val_f1_score: 3.8112e-04\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 58us/stepss: 0.6634 - acc: 0.3778 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 3s 78us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      " 1024/37489 [..............................] - ETA: 2s - loss: 0.6637 - acc: 0.3779 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 0s 39us/step\n",
      "37489/37489 [==============================] - 2s 43us/step\n",
      "37489/37489 [==============================] - 12s 311us/step - loss: 0.6711 - acc: 0.6160 - f1_score: 0.6663 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "16384/37489 [============>.................] - ETA: 1s - loss: 0.6667 - acc: 0.6165 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6659 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 0.6921 - acc: 0.6173 - f1_score: 0.6613 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 83us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 4s 95us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 4s 100us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 4s 97us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6645 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6645 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6650 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6644 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6641 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6642 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6644 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6643 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 58us/steploss: 0.6633 - acc: 0.6206 - f1_score: 0.\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6641 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6648 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 56us/stepss: 0.6647 - acc: 0.6176 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 3s 81us/step - loss: 0.6638 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6641 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 2s 65us/step - loss: 0.6644 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37120/37488 [============================>.] - ETA: 0s - loss: 0.6640 - acc: 0.6190 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 3s 71us/step - loss: 0.6640 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 3s 67us/step - loss: 0.6639 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 0s 43us/step\n",
      "37488/37488 [==============================] - 1s 38us/step\n",
      "37489/37489 [==============================] - 12s 314us/step - loss: 0.6693 - acc: 0.6099 - f1_score: 0.6620 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "13056/37489 [=========>....................] - ETA: 1s - loss: 0.6637 - acc: 0.6212 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 0.6660 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6658 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.8713 - acc: 0.6182 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6656 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6653 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6650 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6652 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6649 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6649 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6647 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6645 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 0s 52us/steploss: 9.9660 - acc: 0.6183 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      " 4864/37489 [==>...........................] - ETA: 1sEpoch 16/20\n",
      "37489/37489 [==============================] - 2s 58us/stepss: 9.9811 - acc: 0.6193 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 3s 83us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 67us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      " 5376/37489 [===>..........................] - ETA: 1s - loss: 9.8729 - acc: 0.6125 - f1_score: 0.6125Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9652 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 0s 38us/step\n",
      "37489/37489 [==============================] - 1s 39us/step\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 2/20\n",
      " 6912/37489 [====>.........................] - ETA: 2s - loss: 6.2332 - acc: 0.3851 - f1_score: 0.3832Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 85us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "25856/37489 [===================>..........] - ETA: 0s - loss: 9.9392 - acc: 0.6189 - f1_score: 0.6178Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "15104/37489 [===========>..................] - ETA: 1s - loss: 6.1553 - acc: 0.3803 - f1_score: 0.3789Epoch 4/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1688 - acc: 0.3814 - f1_score: 0.3798 - val_loss: 6.0485 - val_acc: 0.3758 - val_f1_score: 0.3739\n",
      "9372/9372 [==============================] - 1s 59us/steploss: 9.9152 - acc: 0.6165 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 55us/stepss: 10.0784 - acc: 0.6263 - f1_score: 0.62\n",
      "37489/37489 [==============================] - 3s 76us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "Epoch 20/20\n",
      "  256/37489 [..............................] - ETA: 2s - loss: 9.5072 - acc: 0.5938 - f1_score: 0.5910Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 9.9269 - acc: 0.6174 - f1_score: 0.6163 - val_loss: 10.0696 - val_acc: 0.6242 - val_f1_score: 0.6222\n",
      "9372/9372 [==============================] - 0s 45us/step\n",
      "37489/37489 [==============================] - 2s 41us/step\n",
      "37488/37488 [==============================] - 12s 314us/step - loss: 0.7970 - acc: 0.6177 - f1_score: 0.6438 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "12800/37488 [=========>....................] - ETA: 1s - loss: 0.6617 - acc: 0.6263 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 3s 70us/step - loss: 0.6652 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 2s 65us/step - loss: 0.6646 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6733 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6646 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 68us/step - loss: 0.6643 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6639 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 3s 80us/step - loss: 0.6637 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6657 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6635 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 3s 88us/step - loss: 0.6631 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6232 - val_f1_score: 0.6666\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6630 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6232 - val_f1_score: 0.6666\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6629 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6232 - val_f1_score: 0.6666\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6625 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6624 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6234 - val_f1_score: 0.6666\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6625 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6708 - val_acc: 0.6238 - val_f1_score: 0.6665\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6624 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6220 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "18944/37488 [==============>...............] - ETA: 1s - loss: 0.6639 - acc: 0.6161 - f1_score: 0.6667Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6623 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6238 - val_f1_score: 0.6666\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "18432/37488 [=============>................] - ETA: 1s - loss: 0.6614 - acc: 0.6190 - f1_score: 0.6666Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6620 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6616 - acc: 0.6198 - f1_score: 0.6668 - val_loss: 0.6664 - val_acc: 0.6236 - val_f1_score: 0.6666\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6615 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6651 - val_acc: 0.6230 - val_f1_score: 0.6666\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6616 - acc: 0.6192 - f1_score: 0.6668 - val_loss: 0.6637 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "9373/9373 [==============================] - 1s 59us/steploss: 9.9303 - acc: 0.3839 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 2s 55us/stepss: 9.9601 - acc: 0.3821 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 3s 74us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "  256/37489 [..............................] - ETA: 2s - loss: 10.1997 - acc: 0.3672 - f1_score: 0.3672Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 0s 50us/step\n",
      "37489/37489 [==============================] - 2s 42us/step\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "11776/37489 [========>.....................] - ETA: 1s - loss: 9.9342 - acc: 0.3835 - f1_score: 0.3835Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 1.0447 - acc: 0.6074 - f1_score: 0.6369 - val_loss: 0.6702 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 82us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6654 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "19968/37489 [==============>...............] - ETA: 1s - loss: 9.9689 - acc: 0.3814 - f1_score: 0.3814Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6642 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6643 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6638 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6646 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6635 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6636 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6634 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6658 - val_acc: 0.6203 - val_f1_score: 0.6668\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6631 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6649 - val_acc: 0.6240 - val_f1_score: 0.6668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6627 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6624 - acc: 0.6190 - f1_score: 0.6666 - val_loss: 0.6611 - val_acc: 0.6242 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "22272/37489 [================>.............] - ETA: 1s - loss: 0.6629 - acc: 0.6181 - f1_score: 0.6667Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6624 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6661 - val_acc: 0.6213 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9639 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 54us/steploss: 0.6629 - acc: 0.6186 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6624 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 57us/stepss: 0.6620 - acc: 0.6204 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 77us/step - loss: 0.6621 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6661 - val_acc: 0.6236 - val_f1_score: 0.6665\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6620 - acc: 0.6201 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6244 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6618 - acc: 0.6197 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 71us/step - loss: 0.6618 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6199 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "  256/37489 [..............................] - ETA: 2s - loss: 0.6485 - acc: 0.6445 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6617 - acc: 0.6202 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 0s 40us/step\n",
      "37489/37489 [==============================] - 1s 38us/step\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 0.6669 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "10496/37489 [=======>......................] - ETA: 1s - loss: 0.6671 - acc: 0.3851 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6650 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6647 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 381us/step - loss: 0.6673 - acc: 0.6189 - f1_score: 0.6529 - val_loss: 0.6683 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 83us/step - loss: 0.6648 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6653 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6643 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6642 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6645 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6639 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6639 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6636 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6645 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6636 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6641 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6637 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6604 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6639 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6632 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6636 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6629 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6637 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6627 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6633 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6626 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6604 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6633 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6623 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6643 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6629 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6625 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6604 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 57us/steploss: 0.6648 - acc: 0.6157 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 3s 89us/step - loss: 0.6631 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 57us/stepss: 0.6628 - acc: 0.6176 - f1_score: 0.\n",
      "37488/37488 [==============================] - 3s 71us/step - loss: 0.6623 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6230 - val_f1_score: 0.6666\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 0.6621 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 3s 68us/step - loss: 0.6621 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6647 - val_acc: 0.6196 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 67us/step - loss: 0.6628 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      " 2560/37488 [=>............................] - ETA: 2s - loss: 0.6664 - acc: 0.6098 - f1_score: 0.6668Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 2s 64us/step - loss: 0.6616 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 0s 41us/step\n",
      "37488/37488 [==============================] - 2s 43us/step\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6961 - acc: 0.6058 - f1_score: 0.6490 - val_loss: 0.6642 - val_acc: 0.6240 - val_f1_score: 0.6658\n",
      "Epoch 2/20\n",
      " 7424/37489 [====>.........................] - ETA: 1s - loss: 0.6647 - acc: 0.6189 - f1_score: 0.6665Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 0.6655 - acc: 0.6176 - f1_score: 0.6663 - val_loss: 0.6642 - val_acc: 0.6240 - val_f1_score: 0.6649\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6654 - acc: 0.6176 - f1_score: 0.6665 - val_loss: 0.6638 - val_acc: 0.6240 - val_f1_score: 0.6663\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6650 - acc: 0.6176 - f1_score: 0.6665 - val_loss: 0.6639 - val_acc: 0.6238 - val_f1_score: 0.6662\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 71us/step - loss: 0.6651 - acc: 0.6176 - f1_score: 0.6664 - val_loss: 0.6634 - val_acc: 0.6238 - val_f1_score: 0.6663\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6650 - acc: 0.6176 - f1_score: 0.6665 - val_loss: 0.6632 - val_acc: 0.6236 - val_f1_score: 0.6662\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 384us/step - loss: 4.8811 - acc: 0.5043 - f1_score: 0.5169 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 81us/step - loss: 0.6648 - acc: 0.6177 - f1_score: 0.6664 - val_loss: 0.6631 - val_acc: 0.6236 - val_f1_score: 0.6662\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6653 - acc: 0.6182 - f1_score: 0.6666 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6647 - acc: 0.6175 - f1_score: 0.6665 - val_loss: 0.6629 - val_acc: 0.6234 - val_f1_score: 0.6663\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6652 - acc: 0.6182 - f1_score: 0.6666 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6665 - val_loss: 0.6631 - val_acc: 0.6232 - val_f1_score: 0.6665\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6650 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6647 - acc: 0.6176 - f1_score: 0.6666 - val_loss: 0.6626 - val_acc: 0.6232 - val_f1_score: 0.6664\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6642 - acc: 0.6174 - f1_score: 0.6665 - val_loss: 0.6630 - val_acc: 0.6232 - val_f1_score: 0.6664\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6643 - acc: 0.6176 - f1_score: 0.6666 - val_loss: 0.6634 - val_acc: 0.6238 - val_f1_score: 0.6665\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6649 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "17920/37489 [=============>................] - ETA: 1s - loss: 0.6623 - acc: 0.6216 - f1_score: 0.6666Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6641 - acc: 0.6174 - f1_score: 0.6666 - val_loss: 0.6625 - val_acc: 0.6238 - val_f1_score: 0.6665\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6645 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6240 - val_f1_score: 0.6666\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6639 - acc: 0.6172 - f1_score: 0.6666 - val_loss: 0.6626 - val_acc: 0.6232 - val_f1_score: 0.6665\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6644 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6640 - acc: 0.6172 - f1_score: 0.6666 - val_loss: 0.6629 - val_acc: 0.6236 - val_f1_score: 0.6665\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6644 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6639 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6234 - val_f1_score: 0.6664\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6644 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6641 - acc: 0.6174 - f1_score: 0.6666 - val_loss: 0.6626 - val_acc: 0.6232 - val_f1_score: 0.6664\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6642 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6666\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6638 - acc: 0.6172 - f1_score: 0.6666 - val_loss: 0.6625 - val_acc: 0.6234 - val_f1_score: 0.6664\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6640 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6638 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6664 - val_acc: 0.6215 - val_f1_score: 0.6665\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6642 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6236 - val_f1_score: 0.6666\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6639 - acc: 0.6175 - f1_score: 0.6666 - val_loss: 0.6626 - val_acc: 0.6238 - val_f1_score: 0.6665\n",
      "9372/9372 [==============================] - 1s 56us/steploss: 0.6635 - acc: 0.6196 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6641 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 57us/stepss: 0.6646 - acc: 0.6171 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 78us/step - loss: 0.6641 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6234 - val_f1_score: 0.6666\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6637 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6232 - val_f1_score: 0.6666\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6638 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6639 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 71us/step - loss: 0.6639 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6234 - val_f1_score: 0.6666\n",
      "Epoch 20/20\n",
      " 3328/37489 [=>............................] - ETA: 2s - loss: 0.6621 - acc: 0.6217 - f1_score: 0.6668Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 78us/step - loss: 0.6638 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6236 - val_f1_score: 0.6666\n",
      "9372/9372 [==============================] - 0s 42us/step\n",
      "37489/37489 [==============================] - 2s 49us/step\n",
      "37489/37489 [==============================] - 13s 345us/step - loss: 0.6746 - acc: 0.3869 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "10752/37489 [=======>......................] - ETA: 1s - loss: 0.6650 - acc: 0.3807 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 73us/step - loss: 0.6649 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 71us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 72us/step - loss: 0.6644 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 4s 96us/step - loss: 0.6642 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 15s 391us/step - loss: 0.6741 - acc: 0.6068 - f1_score: 0.6650 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 4s 97us/step - loss: 0.6640 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 4s 102us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 4s 96us/step - loss: 0.6636 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6636 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6636 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6631 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6658 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6632 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6651 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6631 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6633 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6631 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6647 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6631 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6648 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 0.6626 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6647 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6629 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6644 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6618 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6647 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6625 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 0s 52us/steploss: 0.6645 - acc: 0.6174 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6645 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 57us/stepss: 0.6651 - acc: 0.6156 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 81us/step - loss: 0.6644 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6643 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6640 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6641 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      " 9216/37489 [======>.......................] - ETA: 1s - loss: 0.6617 - acc: 0.6203 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6636 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 0s 36us/step\n",
      "37489/37489 [==============================] - 1s 38us/step\n",
      "37488/37488 [==============================] - 12s 326us/step - loss: 0.7198 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "  256/37488 [..............................] - ETA: 2s - loss: 0.6671 - acc: 0.3828 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 2s 65us/step - loss: 0.6661 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 68us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 3s 69us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 72us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 87us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 386us/step - loss: 6.8980 - acc: 0.3825 - f1_score: 0.3784 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 3s 86us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3821 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6640 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6641 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 0.6672 - acc: 0.3826 - f1_score: 5.2732e-05 - val_loss: 0.6619 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 0.6635 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6634 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 0.6631 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 4s 95us/step - loss: 0.6633 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 0.6635 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 0.6627 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6602 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 4s 96us/step - loss: 0.6626 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 0.6626 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3821 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 4s 95us/step - loss: 0.6624 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 4s 96us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 4s 98us/step - loss: 0.6623 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 16/20\n",
      "9373/9373 [==============================] - 1s 54us/steploss: 6.1230 - acc: 0.3799 - f1_score: 0.\n",
      "37488/37488 [==============================] - 2s 57us/stepss: 6.1580 - acc: 0.3821 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "Epoch 20/20\n",
      "16640/37489 [============>.................] - ETA: 1s - loss: 6.2516 - acc: 0.3879 - f1_score: 0.3876Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3822 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3755\n",
      "9372/9372 [==============================] - 0s 42us/step\n",
      "37489/37489 [==============================] - 2s 41us/step\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 0.7103 - acc: 0.3913 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 326us/step - loss: 0.7104 - acc: 0.3916 - f1_score: 0.0000e+00 - val_loss: 0.6746 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6659 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 73us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6669 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6651 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 387us/step - loss: 0.6940 - acc: 0.6170 - f1_score: 0.6647 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6664 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6655 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6646 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6648 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6646 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6686 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6644 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6643 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6645 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6643 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6673 - val_acc: 0.3753 - val_f1_score: 0.0000e+00\n",
      "31488/37489 [========================>.....] - ETA: 0s - loss: 0.6655 - acc: 0.6163 - f1_score: 0.6667Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6642 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6640 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6639 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6640 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6635 - acc: 0.6189 - f1_score: 0.6666 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6639 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6681 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6632 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6657 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 0.6637 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6634 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6648 - val_acc: 0.6213 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6634 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6631 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6692 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6634 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6627 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6681 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 0.6631 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6634 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "9372/9372 [==============================] - 1s 60us/steploss: 0.6623 - acc: 0.6166 - f1_score: 0.\n",
      "37489/37489 [==============================] - 2s 53us/stepss: 0.6614 - acc: 0.6212 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 84us/step - loss: 0.6625 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6823 - val_acc: 0.6101 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 62us/step - loss: 0.6623 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6687 - val_acc: 0.6217 - val_f1_score: 0.6666\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6620 - acc: 0.6198 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6625 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "19200/37489 [==============>...............] - ETA: 1s - loss: 0.6602 - acc: 0.6223 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6616 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 0s 43us/step\n",
      "37489/37489 [==============================] - 2s 41us/step\n",
      "36608/37489 [============================>.] - ETA: 0s - loss: 0.6698 - acc: 0.6149 - f1_score: 0.6662Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6698 - acc: 0.6151 - f1_score: 0.6663 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6661 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 86us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 15s 397us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 85us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6644 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6824 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6648 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6644 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6641 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6645 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6641 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6230 - val_f1_score: 0.6666\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6638 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6653 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6884 - acc: 0.6152 - f1_score: 0.6663 - val_loss: 0.6610 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6635 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6635 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6636 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6213 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 0s 52us/steploss: 6.1374 - acc: 0.6192 - f1_score: 0.\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 58us/stepss: 6.2204 - acc: 0.6135 - f1_score: 0.61\n",
      "37488/37488 [==============================] - 3s 78us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 68us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 3s 70us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 2s 66us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 20/20\n",
      " 9216/37488 [======>.......................] - ETA: 1s - loss: 6.1982 - acc: 0.6151 - f1_score: 0.6151Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 3s 67us/step - loss: 6.1427 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0733 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "9373/9373 [==============================] - 0s 39us/step\n",
      "37488/37488 [==============================] - 2s 44us/step\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 6.6435 - acc: 0.3825 - f1_score: 0.1689 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 2/20\n",
      " 1280/37489 [>.............................] - ETA: 2s - loss: 6.1198 - acc: 0.3797 - f1_score: 0.1741Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 15s 398us/step - loss: 0.6746 - acc: 0.6142 - f1_score: 0.6632 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 83us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1737 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 0.6651 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6660 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6647 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6645 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1737 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6643 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1737 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6642 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6640 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6642 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1737 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6636 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6637 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.1736 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.1669\n",
      "9372/9372 [==============================] - 1s 55us/steploss: 0.6636 - acc: 0.6183 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6636 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 2s 59us/stepss: 0.6610 - acc: 0.6244 - f1_score: 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 3s 78us/step - loss: 0.6640 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6633 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6636 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6636 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "12032/37489 [========>.....................] - ETA: 1s - loss: 0.6608 - acc: 0.6229 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6631 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 0s 39us/step\n",
      "37489/37489 [==============================] - 2s 40us/step\n",
      "36864/37489 [============================>.] - ETA: 0s - loss: 0.6729 - acc: 0.3838 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 14s 381us/step - loss: 0.6727 - acc: 0.3836 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 2s 67us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 71us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 15s 392us/step - loss: 0.7781 - acc: 0.6150 - f1_score: 0.6514 - val_loss: 0.6609 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 0.6644 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6658 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 0.6645 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6658 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6640 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6655 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6643 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 96us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 4s 96us/step - loss: 0.6641 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6651 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6651 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6640 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 0.6640 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6647 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6634 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6647 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 0.6633 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6646 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6634 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6645 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 0.6627 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6644 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 0.6632 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6641 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6625 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6642 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6623 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6653 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 56us/steploss: 0.6627 - acc: 0.6196 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6638 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 59us/stepss: 0.6644 - acc: 0.6142 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 3s 79us/step - loss: 0.6640 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 0.6640 - acc: 0.6167 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 2s 67us/step - loss: 0.6638 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 65us/step - loss: 0.6635 - acc: 0.6174 - f1_score: 0.6668 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 0s 41us/step\n",
      "11520/37489 [========>.....................] - ETA: 1sTrain on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 45us/step\n",
      "10240/37488 [=======>......................] - ETA: 25s - loss: 9.9621 - acc: 0.6147 - f1_score: 0.6045Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 13s 340us/step - loss: 9.9689 - acc: 0.6176 - f1_score: 0.6148 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 3s 69us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 68us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 3s 72us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 86us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 15s 398us/step - loss: 6.1213 - acc: 0.3832 - f1_score: 0.0043 - val_loss: 0.7828 - val_acc: 0.6242 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 0.6679 - acc: 0.3837 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6659 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 4s 93us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6655 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 4s 95us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 9.9745 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9373/9373 [==============================] - 1s 59us/steploss: 0.6611 - acc: 0.3745 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 2s 56us/stepss: 0.6660 - acc: 0.3846 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 0.6649 - acc: 0.3872 - f1_score: 0.0112 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 64us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 0s 47us/step\n",
      "37489/37489 [==============================] - 2s 41us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "16640/37489 [============>.................] - ETA: 12s - loss: 9.0567 - acc: 0.3832 - f1_score: 0.3825Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 13s 338us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 16s 419us/step - loss: 9.9102 - acc: 0.6174 - f1_score: 0.6146 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 79us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.0524 - acc: 0.3817 - f1_score: 0.3811 - val_loss: 9.0480 - val_acc: 0.3758 - val_f1_score: 0.3748\n",
      "9372/9372 [==============================] - 1s 54us/steploss: 9.9380 - acc: 0.6166 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 2s 57us/stepss: 9.8220 - acc: 0.6094 - f1_score: 0.60\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9372/9372 [==============================] - 0s 47us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 2s 42us/step\n",
      "23296/37489 [=================>............] - ETA: 6s - loss: 6.0767 - acc: 0.6192 - f1_score: 0.6128Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 13s 344us/step - loss: 6.1318 - acc: 0.6172 - f1_score: 0.6132 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 16s 421us/step - loss: 0.6729 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 3s 93us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 4s 95us/step - loss: 0.6645 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 3s 90us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 4s 94us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 4s 96us/step - loss: 0.6643 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6643 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 4s 95us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 3s 92us/step - loss: 0.6642 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 1s 57us/steploss: 0.6616 - acc: 0.3760 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 2s 59us/stepss: 0.6643 - acc: 0.3808 - f1_score: 0.\n",
      "37488/37488 [==============================] - 3s 91us/step - loss: 0.6644 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 3s 71us/step - loss: 0.6637 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 2s 64us/step - loss: 0.6638 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6681 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 2s 67us/step - loss: 0.6638 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 3s 71us/step - loss: 0.6631 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6667 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "1792/9373 [====>.........................] - ETA: 0sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "9373/9373 [==============================] - 0s 40us/step\n",
      "37488/37488 [==============================] - 1s 38us/step\n",
      "27648/37489 [=====================>........] - ETA: 3s - loss: 0.7409 - acc: 0.6129 - f1_score: 0.6629Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 13s 348us/step - loss: 0.7209 - acc: 0.6145 - f1_score: 0.6639 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 78us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 16s 423us/step - loss: 9.3666 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      " 4864/37489 [==>...........................] - ETA: 2s - loss: 0.6653 - acc: 0.6176 - f1_score: 0.6667Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6650 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 89us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6649 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6649 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6650 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6650 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6648 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6647 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 0.6646 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6645 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6644 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6643 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6675 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 56us/steploss: 9.9337 - acc: 0.6162 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 2s 55us/stepss: 9.9683 - acc: 0.6185 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 3s 87us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 69us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 67us/step - loss: 9.9648 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      " 256/9372 [..............................] - ETA: 0sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "9372/9372 [==============================] - 0s 46us/step\n",
      "37489/37489 [==============================] - 2s 41us/step\n",
      "27648/37489 [=====================>........] - ETA: 4s - loss: 0.7506 - acc: 0.6106 - f1_score: 0.6638Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 0.7291 - acc: 0.6109 - f1_score: 0.6646 - val_loss: 0.6644 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 3s 71us/step - loss: 0.6657 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 3s 68us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 3s 83us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 80us/step - loss: 0.6658 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 16s 421us/step - loss: 9.7373 - acc: 0.3826 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 4s 93us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "  256/37489 [..............................] - ETA: 2s - loss: 10.7664 - acc: 0.3320 - f1_score: 0.3320Epoch 11/20\n",
      "37489/37489 [==============================] - 4s 94us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 90us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6645 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 3s 91us/step - loss: 0.6644 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 3s 93us/step - loss: 0.6642 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 3s 92us/step - loss: 0.6646 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 62us/steploss: 10.0371 - acc: 0.3773 - f1_score: 0.\n",
      "37489/37489 [==============================] - 2s 58us/stepss: 9.9592 - acc: 0.3821 - f1_score: 0.\n",
      "37489/37489 [==============================] - 3s 88us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 3s 70us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 2s 66us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 2s 67us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "36864/37489 [============================>.] - ETA: 0s - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 3s 71us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 0s 40us/step\n",
      "37489/37489 [==============================] - 1s 38us/step\n",
      " 7744/37488 [=====>........................] - ETA: 42s - loss: 0.6949 - acc: 0.6011 - f1_score: 0.6558Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 20s 546us/step - loss: 0.6720 - acc: 0.6148 - f1_score: 0.6644 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 344us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 26s 688us/step - loss: 0.6676 - acc: 0.6170 - f1_score: 0.6665 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 343us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6639 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 0.6658 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 13s 353us/step - loss: 0.6647 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 0.6653 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 13s 353us/step - loss: 0.6647 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 349us/step - loss: 0.6648 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 13s 356us/step - loss: 0.6639 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 0.6646 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 13s 355us/step - loss: 0.6636 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 348us/step - loss: 0.6641 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 0.6635 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 0.6634 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 0.6634 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6603 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6640 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      " 9856/37488 [======>.......................] - ETA: 8s - loss: 0.6613 - acc: 0.6217 - f1_score: 0.6667Epoch 9/20\n",
      "37488/37488 [==============================] - 13s 354us/step - loss: 0.6630 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6602 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 0.6636 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6643 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 0.6628 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6600 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 0.6637 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 13s 358us/step - loss: 0.6623 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 349us/step - loss: 0.6637 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 13s 354us/step - loss: 0.6622 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 0.6634 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 0.6623 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 0.6635 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 0.6622 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6710 - val_acc: 0.6178 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 0.6635 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 0.6616 - acc: 0.6201 - f1_score: 0.6667 - val_loss: 0.6600 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 0.6631 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 0.6618 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6599 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 0.6629 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 0.6615 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6600 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "35264/37489 [===========================>..] - ETA: 0s - loss: 0.6634 - acc: 0.6184 - f1_score: 0.6667Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 0.6633 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 13s 355us/step - loss: 0.6615 - acc: 0.6197 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6209 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6631 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6230 - val_f1_score: 0.6666\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 13s 355us/step - loss: 0.6613 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6601 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "37489/37489 [==============================] - 13s 349us/step - loss: 0.6626 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6675 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "9373/9373 [==============================] - 2s 212us/steploss: 0.6808 - acc: 0.5962 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 8s 221us/steps: 0.6633 - acc: 0.6179 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6626 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6209 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 1s 158us/step\n",
      "37489/37489 [==============================] - 6s 155us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 20s 536us/step - loss: 6.3640 - acc: 0.3817 - f1_score: 0.2801 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 349us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 26s 691us/step - loss: 0.6678 - acc: 0.6179 - f1_score: 0.6656 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6642 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 0.6638 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 345us/step - loss: 0.6635 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 0.6630 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 350us/step - loss: 0.6632 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6222 - val_f1_score: 0.6668\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 0.6632 - acc: 0.6194 - f1_score: 0.6666 - val_loss: 0.6608 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 350us/step - loss: 0.6672 - acc: 0.6191 - f1_score: 0.6665 - val_loss: 0.6608 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 0.6622 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 0.6620 - acc: 0.6197 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 0.6621 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6814 - val_acc: 0.6101 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6622 - acc: 0.6198 - f1_score: 0.6668 - val_loss: 0.6644 - val_acc: 0.6219 - val_f1_score: 0.6666\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 0.6620 - acc: 0.6198 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 0.6616 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6614 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6680 - val_acc: 0.6199 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 348us/step - loss: 0.6612 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6226 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 6.4294 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.4045 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 218us/steposs: 0.6600 - acc: 0.6232 - f1_score: 0.\n",
      "37489/37489 [==============================] - 8s 225us/steps: 0.6611 - acc: 0.6202 - f1_score: 0.\n",
      "37489/37489 [==============================] - 13s 335us/step - loss: 0.6613 - acc: 0.6201 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 1s 136us/step\n",
      "37489/37489 [==============================] - 6s 157us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 21s 565us/step - loss: 0.6718 - acc: 0.3884 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 26s 685us/step - loss: 9.5110 - acc: 0.6188 - f1_score: 0.6187 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6649 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6646 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6645 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 13s 358us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6640 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6640 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6639 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6635 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6602 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6633 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 0.6632 - acc: 0.3821 - f1_score: 0.0000e+00Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6633 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6632 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6604 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6627 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6599 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6628 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3783 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 361us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6625 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3785 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6627 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6630 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      " 3904/37488 [==>...........................] - ETA: 10s - loss: 9.8922 - acc: 0.6140 - f1_score: 0.6138Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6627 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6634 - acc: 0.3818 - f1_score: 5.2528e-05 - val_loss: 0.6604 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 223us/steposs: 10.0754 - acc: 0.6251 - f1_score: 0.\n",
      "37489/37489 [==============================] - 8s 222us/steps: 9.9806 - acc: 0.6193 - f1_score: 0.\n",
      "37488/37488 [==============================] - 13s 344us/step - loss: 9.9732 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 10.0634 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9373/9373 [==============================] - 1s 156us/step\n",
      "37488/37488 [==============================] - 6s 158us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 21s 565us/step - loss: 0.6668 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 26s 688us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 0.6658 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6651 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6649 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6648 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6646 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6641 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6640 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6638 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6640 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6637 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6636 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6652 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6632 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6634 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6632 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6633 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6629 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6624 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 215us/steposs: 10.1802 - acc: 0.3683 - f1_score: 0.\n",
      "37489/37489 [==============================] - 8s 224us/steps: 9.9595 - acc: 0.3\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 9.9609 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0510 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 143us/step\n",
      "37489/37489 [==============================] - 6s 159us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 22s 579us/step - loss: 0.6669 - acc: 0.3833 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 26s 683us/step - loss: 0.6667 - acc: 0.6174 - f1_score: 0.6664 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 347us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6650 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6644 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6641 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6649 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6637 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6649 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6637 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6643 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6637 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6641 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6636 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6643 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6638 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6640 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6632 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6635 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6632 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 0.6632 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6627 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6633 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6626 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6627 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6602 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6626 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6628 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6622 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6624 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6599 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6621 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6626 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6616 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6652 - val_acc: 0.3791 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 231us/steposs: 0.6631 - acc: 0.6168 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6624 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "37489/37489 [==============================] - 8s 219us/step\n",
      "9372/9372 [==============================] - 2s 209us/step\n",
      "37489/37489 [==============================] - 6s 160us/step\n",
      "Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 22s 580us/step - loss: 0.6681 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6660 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 25s 679us/step - loss: 0.6759 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 353us/step - loss: 0.6655 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6659 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6648 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6643 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6645 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 0.6654 - acc: 0.5545 - f1_score: 0.4878 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6651 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 0.6651 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 13s 356us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6654 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 361us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6649 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "17280/37489 [============>.................] - ETA: 6s - loss: 0.6659 - acc: 0.3848 - f1_score: 0.0000e+00Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6647 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6644 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6672 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 361us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6646 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 0.6646 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 0.6645 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 0.6645 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 13s 358us/step - loss: 0.6645 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6646 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 0.6646 - acc: 0.3990 - f1_score: 0.0446 - val_loss: 0.6611 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6640 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6644 - acc: 0.3827 - f1_score: 3.0153e-04 - val_loss: 0.6622 - val_acc: 0.3774 - val_f1_score: 7.4492e-04\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6639 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0021 - val_loss: 0.6638 - val_acc: 0.3766 - val_f1_score: 0.0030\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 0.6641 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 2s 231us/steposs: 0.6665 - acc: 0.5279 - f1_score: 0.42\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 0.6664 - acc: 0.5533 - f1_score: 0.4910 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 227us/step\n",
      "37488/37488 [==============================] - 8s 218us/step\n",
      "37489/37489 [==============================] - 6s 172us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 23s 605us/step - loss: 0.6674 - acc: 0.3829 - f1_score: 0.0000e+00 - val_loss: 0.6664 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 25s 672us/step - loss: 6.1388 - acc: 0.6183 - f1_score: 0.6176 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 349us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "20672/37489 [===============>..............] - ETA: 5s - loss: 6.1379 - acc: 0.6192 - f1_score: 0.6192Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "19712/37489 [==============>...............] - ETA: 5s - loss: 0.6653 - acc: 0.3832 - f1_score: 0.0000e+00Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6647 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6683 - acc: 0.3817 - f1_score: 1.9236e-04 - val_loss: 0.6605 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6674 - acc: 0.5556 - f1_score: 0.4966 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6649 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6647 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6646 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6658 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6645 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6643 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6642 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6641 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 212us/steposs: 6.1493 - acc: 0.6185 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 6.1477 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 207us/step\n",
      "37489/37489 [==============================] - 8s 220us/step\n",
      "37489/37489 [==============================] - 7s 193us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 23s 623us/step - loss: 0.6694 - acc: 0.3837 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 25s 668us/step - loss: 0.6663 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 0.6660 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6663 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 14s 361us/step - loss: 0.6652 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6663 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "26752/37488 [====================>.........] - ETA: 3s - loss: 0.6656 - acc: 0.6176 - f1_score: 0.6667Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 361us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 361us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6654 - acc: 0.3823 - f1_score: 0.0051 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6650 - acc: 0.3826 - f1_score: 4.1082e-04 - val_loss: 0.6621 - val_acc: 0.3753 - val_f1_score: 0.0026\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0010 - val_loss: 0.6632 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 13s 358us/step - loss: 0.6645 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0017 - val_loss: 0.6618 - val_acc: 0.3756 - val_f1_score: 0.0030\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 0.6647 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6651 - acc: 0.4102 - f1_score: 0.0829 - val_loss: 0.6639 - val_acc: 0.6228 - val_f1_score: 0.6658\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6666 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6658 - acc: 0.6170 - f1_score: 0.6664 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 0.6648 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 0.6643 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6653 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 0.6642 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6640 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 0.6640 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 230us/steposs: 0.6636 - acc: 0.6194 - f1_score: 0.\n",
      "37488/37488 [==============================] - 13s 355us/step - loss: 0.6638 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 2s 231us/step\n",
      "37489/37489 [==============================] - 8s 221us/step\n",
      "37488/37488 [==============================] - 7s 199us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 24s 630us/step - loss: 0.6824 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 25s 668us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 0.6657 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6651 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6653 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6649 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6646 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6646 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6653 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 0.6645 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6641 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6645 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "32448/37489 [========================>.....] - ETA: 1s - loss: 6.1615 - acc: 0.3823 - f1_score: 0.3773Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6644 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6651 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6640 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6647 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6656 - acc: 0.5213 - f1_score: 0.3954 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6660 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 222us/steposs: 6.1499 \n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3770 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3728\n",
      "9372/9372 [==============================] - 2s 228us/step\n",
      "37489/37489 [==============================] - 8s 219us/step\n",
      "37489/37489 [==============================] - 8s 206us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 24s 641us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 25s 670us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3807 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 350us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3807 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3807 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3756 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3807 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "31872/37489 [========================>.....] - ETA: 1s - loss: 9.3441 - acc: 0.3803 - f1_score: 0.3784Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3807 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3807 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3807 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3756 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3807 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 6.1482 - acc: 0.3814 - f1_score: 0.3757 - val_loss: 6.0609 - val_acc: 0.3758 - val_f1_score: 0.3691\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 9.3100 - acc: 0.3826 - f1_score: 0.3806 - val_loss: 9.4319 - val_acc: 0.3758 - val_f1_score: 0.3744\n",
      "9372/9372 [==============================] - 2s 233us/step\n",
      "9372/9372 [==============================] - 2s 221us/step\n",
      "37489/37489 [==============================] - 8s 217us/step\n",
      "37489/37489 [==============================] - 8s 207us/step\n",
      "Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 24s 644us/step - loss: 6.1442 - acc: 0.3820 - f1_score: 0.3798 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 25s 668us/step - loss: 9.3896 - acc: 0.3829 - f1_score: 0.3212 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 345us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 13s 358us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 360us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 360us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 361us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 361us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 13s 358us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 6.1436 - acc: 0.3812 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 9.9527 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9373/9373 [==============================] - 2s 215us/step\n",
      "9372/9372 [==============================] - 2s 229us/step\n",
      "37488/37488 [==============================] - 8s 221us/step\n",
      "37489/37489 [==============================] - 8s 212us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 24s 649us/step - loss: 9.6307 - acc: 0.3817 - f1_score: 0.3445 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 25s 666us/step - loss: 0.6785 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6654 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6654 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6663 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.9652 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 226us/step\n",
      "9372/9372 [==============================] - 2s 220us/step\n",
      "37489/37489 [==============================] - 8s 215us/step\n",
      "37489/37489 [==============================] - 8s 217us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 25s 662us/step - loss: 0.6847 - acc: 0.3831 - f1_score: 5.2528e-05 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 25s 663us/step - loss: 0.8012 - acc: 0.3902 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 354us/step - loss: 0.6660 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6659 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6659 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6648 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6670 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 370us/step - loss: 0.6646 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6645 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 0.6647 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6638 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 371us/step - loss: 0.6662 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 370us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 3.4143e-04 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6655 - acc: 0.3870 - f1_score: 0.0127 - val_loss: 0.6625 - val_acc: 0.6238 - val_f1_score: 0.6663\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6658 - acc: 0.6175 - f1_score: 0.6666 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 228us/steposs: 0.6651 - acc: 0.3821 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 238us/step\n",
      "37489/37489 [==============================] - 8s 219us/step\n",
      "37488/37488 [==============================] - 7s 194us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 25s 659us/step - loss: 9.9351 - acc: 0.6175 - f1_score: 0.6136 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 25s 675us/step - loss: 0.6834 - acc: 0.3842 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 348us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6657 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6638 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6175 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 231us/steposs: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 229us/step\n",
      "37489/37489 [==============================] - 8s 221us/step\n",
      "37489/37489 [==============================] - 7s 183us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 24s 648us/step - loss: 0.6666 - acc: 0.6180 - f1_score: 0.6650 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 26s 687us/step - loss: 6.3635 - acc: 0.6043 - f1_score: 0.6046 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 350us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6657 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6650 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 217us/steposs: 6.1236 - acc: 0.6201 - f1_score: 0.\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 214us/step\n",
      "37489/37489 [==============================] - 8s 224us/step\n",
      "37489/37489 [==============================] - 6s 172us/step\n",
      "Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 24s 641us/step - loss: 0.6810 - acc: 0.6165 - f1_score: 0.6663 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 25s 678us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 347us/step - loss: 0.6652 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 0.6649 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 13s 356us/step - loss: 0.6646 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6166 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 361us/step - loss: 0.6644 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6651 - acc: 0.5850 - f1_score: 0.5718 - val_loss: 0.6637 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 13s 358us/step - loss: 0.6659 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6166 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6644 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 0.6640 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6637 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 0.6634 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6602 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 0.6634 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6600 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6632 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6597 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 0.6629 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6596 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 0.6626 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 214us/steposs: 6.1427 - acc: 0.6199 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 6.1791 - acc: 0.6175 - f1_score: 0.6165 - val_loss: 6.0734 - val_acc: 0.6242 - val_f1_score: 0.6225\n",
      "9372/9372 [==============================] - 2s 222us/step\n",
      "37488/37488 [==============================] - 8s 225us/step\n",
      "37489/37489 [==============================] - 6s 163us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 24s 638us/step - loss: 0.6710 - acc: 0.6179 - f1_score: 0.6625 - val_loss: 0.6648 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 26s 689us/step - loss: 0.6708 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 343us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6661 - acc: 0.5931 - f1_score: 0.5963 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6656 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6661 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6646 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6643 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6640 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6637 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6647 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6632 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6641 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6663 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6629 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6640 - acc: 0.3815 - f1_score: 0.0029 - val_loss: 0.6608 - val_acc: 0.3770 - val_f1_score: 3.7246e-04\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6627 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6644 - acc: 0.4324 - f1_score: 0.1398 - val_loss: 0.6630 - val_acc: 0.6234 - val_f1_score: 0.6662\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6628 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6654 - acc: 0.6180 - f1_score: 0.6666 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6626 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6649 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6622 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6645 - acc: 0.6180 - f1_score: 0.6661 - val_loss: 0.6623 - val_acc: 0.6240 - val_f1_score: 0.6662\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6622 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6646 - acc: 0.6116 - f1_score: 0.6496 - val_loss: 0.6616 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6620 - acc: 0.3800 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6639 - acc: 0.5996 - f1_score: 0.6145 - val_loss: 0.6608 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6617 - acc: 0.3801 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6640 - acc: 0.4974 - f1_score: 0.3202 - val_loss: 0.6656 - val_acc: 0.3756 - val_f1_score: 3.7246e-04\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6616 - acc: 0.3798 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6635 - acc: 0.3845 - f1_score: 0.0178 - val_loss: 0.6649 - val_acc: 0.3770 - val_f1_score: 0.0096\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6617 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6638 - acc: 0.3830 - f1_score: 0.0136 - val_loss: 0.6606 - val_acc: 0.3770 - val_f1_score: 0.0103\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6612 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6635 - acc: 0.3820 - f1_score: 0.0029 - val_loss: 0.6603 - val_acc: 0.3770 - val_f1_score: 0.0033\n",
      "9372/9372 [==============================] - 2s 227us/steposs: 0.6609 - acc: 0.3795 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6617 - acc: 0.3795 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 8s 224us/step\n",
      "9372/9372 [==============================] - 2s 224us/step\n",
      "37489/37489 [==============================] - 6s 166us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 24s 630us/step - loss: 0.6671 - acc: 0.6171 - f1_score: 0.6666 - val_loss: 0.6651 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 26s 701us/step - loss: 0.7029 - acc: 0.3832 - f1_score: 1.0506e-04 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 347us/step - loss: 0.6659 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6653 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6647 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6651 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6651 - acc: 0.6168 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6647 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6646 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6640 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6645 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6637 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 0.6644 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6634 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6653 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 0.6645 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6633 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 371us/step - loss: 0.6642 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6630 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6638 - val_acc: 0.6217 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 0.6642 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6630 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 371us/step - loss: 0.6639 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6626 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 0.6638 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6629 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6639 - val_acc: 0.6207 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 0.6636 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6623 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6603 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 0.6637 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6621 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6226 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 0.6631 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6623 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 0.6630 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6605 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6620 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6215 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 370us/step - loss: 0.6629 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6617 - acc: 0.6186 - f1_score: 0.6668 - val_loss: 0.6622 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 0.6626 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6602 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6616 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6650 - val_acc: 0.6215 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 2s 226us/steposs: 0.6643 - acc: 0.3851 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 8s 222us/steps: 0.6620 - acc: 0.3797 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 13s 349us/step - loss: 0.6623 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 1s 151us/step\n",
      "37488/37488 [==============================] - 6s 164us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 23s 609us/step - loss: 3.4645 - acc: 0.5456 - f1_score: 0.5781 - val_loss: 0.6633 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 26s 706us/step - loss: 0.6662 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6646 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 0.6656 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6646 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6654 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6650 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6658 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6646 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6649 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6659 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6644 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6646 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      " 5760/37489 [===>..........................] - ETA: 10s - loss: 0.6600 - acc: 0.3724 - f1_score: 0.0000e+00Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6645 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6645 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6643 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6643 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6645 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6638 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6643 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6641 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6639 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6634 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6712 - val_acc: 0.6201 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6638 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6637 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6670 - val_acc: 0.6213 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6638 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6637 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6220 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6636 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6634 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6631 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6639 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6632 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6633 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6631 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6633 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6644 - val_acc: 0.6209 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6626 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6631 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6217 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6625 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6627 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6626 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6628 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6226 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9372/9372 [==============================] - 2s 228us/steploss: 0.6620 - acc: 0.3802 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 8s 222us/steps: 0.6620 - acc: 0.3800 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 0.6624 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 159us/step\n",
      "37489/37489 [==============================] - 6s 163us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 23s 611us/step - loss: 0.6798 - acc: 0.6178 - f1_score: 0.6611 - val_loss: 0.6617 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 27s 717us/step - loss: 0.6669 - acc: 0.6163 - f1_score: 0.6666 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 0.6654 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6647 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6645 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6644 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6649 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6643 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6649 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6641 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6648 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6642 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6643 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6647 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6639 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6645 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6641 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6640 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6638 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6636 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6643 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6633 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6638 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6633 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6635 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6631 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6634 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6627 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6633 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6626 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6665 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6629 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6626 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6209 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6630 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6623 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6645 - val_acc: 0.6215 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6627 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6220 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6621 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6625 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "9372/9372 [==============================] - 2s 216us/steploss: 0.6570 - acc: 0.6282 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 9s 228us/steps: 0.6632 - acc: 0.6165 - f1_score: 0.\n",
      "37489/37489 [==============================] - 13s 334us/step - loss: 0.6626 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6220 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 2s 181us/step\n",
      "37489/37489 [==============================] - 6s 165us/step\n",
      "Train on 37488 samples, validate on 5207 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 23s 604us/step - loss: 9.6270 - acc: 0.6186 - f1_score: 0.6189 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 349us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 27s 729us/step - loss: 6.1553 - acc: 0.3825 - f1_score: 0.3778 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 13s 353us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3784 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 13s 352us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 361us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3784 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3784 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3784 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 360us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 13s 359us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 9.6434 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 9.7229 - val_acc: 0.6242 - val_f1_score: 0.6241\n",
      "9373/9373 [==============================] - 2s 228us/steposs: 6.1648 - acc: 0.382\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 8s 224us/steps: 6.1582 - acc: 0.3821 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 320us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3785 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3722\n",
      "9372/9372 [==============================] - 2s 173us/step\n",
      "37489/37489 [==============================] - 6s 162us/step\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 23s 605us/step - loss: 0.6685 - acc: 0.6180 - f1_score: 0.6661 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 28s 741us/step - loss: 0.6735 - acc: 0.6165 - f1_score: 0.6655 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 352us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6654 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6650 - acc: 0.5822 - f1_score: 0.5730 - val_loss: 0.6615 - val_acc: 0.6244 - val_f1_score: 0.6645\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6650 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6653 - acc: 0.5530 - f1_score: 0.4800 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6646 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6645 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6644 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6638 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6649 - acc: 0.5106 - f1_score: 0.3609 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6646 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6655 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 0.6646 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6644 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6642 - acc: 0.3817 - f1_score: 1.0346e-04 - val_loss: 0.6622 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6644 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6643 - acc: 0.3816 - f1_score: 5.1732e-05 - val_loss: 0.6605 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 242us/steposs: 0.6646 - acc: 0.3816 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6644 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 8s 224us/steps: 0.6638 - acc: 0.3801 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 12s 317us/step - loss: 0.6643 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 168us/step\n",
      "35008/37489 [===========================>..] - ETA: 0sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 167us/step\n",
      "Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 23s 603us/step - loss: 6.6603 - acc: 0.4132 - f1_score: 0.3274 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 28s 752us/step - loss: 2.3010 - acc: 0.6186 - f1_score: 0.6523 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 13s 353us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6653 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 370us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 375us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6645 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 0.6645 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6646 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 371us/step - loss: 0.6647 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6645 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 13s 360us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 0.6643 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 375us/step - loss: 0.6642 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3823 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 14s 376us/step - loss: 0.6641 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1654 - acc: 0.3826 - f1_score: 0.3822 - val_loss: 6.0552 - val_acc: 0.3758 - val_f1_score: 0.3756\n",
      "9372/9372 [==============================] - 2s 215us/steposs: 0.6637 - acc: 0.6195 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 14s 370us/step - loss: 0.6639 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 9s 229us/steps: 0.6648 - acc: 0.6182 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 11s 299us/step - loss: 0.6639 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 1s 156us/step\n",
      "20352/37488 [===============>..............] - ETA: 2sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 170us/step\n",
      " 8384/37489 [=====>........................] - ETA: 47s - loss: 0.6742 - acc: 0.3868 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 23s 623us/step - loss: 0.6679 - acc: 0.3838 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 344us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "28288/37489 [=====================>........] - ETA: 7s - loss: 6.3856 - acc: 0.3845 - f1_score: 0.3842Epoch 3/20\n",
      "37489/37489 [==============================] - 28s 759us/step - loss: 6.2944 - acc: 0.3817 - f1_score: 0.3815 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6660 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6650 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6649 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6648 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6648 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6648 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6647 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6646 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6659 - acc: 0.3826 - f1_score: 0.0013 - val_loss: 0.6633 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6938 - acc: 0.3843 - f1_score: 0.0070 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6651 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 217us/steposs: 6.1564 - acc: 0.3820 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 9s 229us/stepss: 6.2254 - acc: 0.3862 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 11s 287us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3757\n",
      "9372/9372 [==============================] - 1s 158us/step\n",
      "17216/37489 [============>.................] - ETA: 3sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 166us/step\n",
      "10176/37489 [=======>......................] - ETA: 38s - loss: 0.6956 - acc: 0.3865 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 23s 625us/step - loss: 0.6738 - acc: 0.3829 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 336us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 29s 763us/step - loss: 0.6843 - acc: 0.3841 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6659 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6647 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6645 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6645 - acc: 0.3813 - f1_score: 0.0011 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6651 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6643 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6653 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6642 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6651 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6641 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6643 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6650 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6639 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6694 - acc: 0.3836 - f1_score: 0.0024 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6640 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 0.6652 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6646 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 228us/steposs: 0.6667 - acc: 0.3858 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 0.6651 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 8s 225us/stepss: 0.6663 - acc: 0.3853 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 11s 284us/step - loss: 0.6651 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 174us/step\n",
      "12480/37489 [========>.....................] - ETA: 4sTrain on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 166us/step\n",
      "13312/37488 [=========>....................] - ETA: 27s - loss: 9.2605 - acc: 0.6053 - f1_score: 0.0453Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 23s 624us/step - loss: 9.7407 - acc: 0.4595 - f1_score: 0.2607 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 12s 322us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 29s 761us/step - loss: 6.1549 - acc: 0.3827 - f1_score: 0.3803 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 353us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 13s 358us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9373/9373 [==============================] - 2s 233us/steposs: 6.0867 - acc: 0.3776 - f1_score: 0.37\n",
      "37488/37488 [==============================] - 9s 227us/steps: 6.1668 - acc: 0.3826 - \n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3810 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 10s 273us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3811 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3741\n",
      "9372/9372 [==============================] - 2s 172us/step\n",
      " 2688/37489 [=>............................] - ETA: 6sTrain on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 166us/step\n",
      "27456/37489 [====================>.........] - ETA: 7s - loss: 0.6692 - acc: 0.6164 - f1_score: 0.6661Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 24s 646us/step - loss: 0.6678 - acc: 0.6180 - f1_score: 0.6662 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 10s 279us/step - loss: 0.6656 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6639 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 0.6656 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 30s 801us/step - loss: 0.6737 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6654 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6655 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6643 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6653 - acc: 0.3819 - f1_score: 0.0013 - val_loss: 0.6620 - val_acc: 0.3756 - val_f1_score: 3.7246e-04\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6653 - acc: 0.6020 - f1_score: 0.6220 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6651 - acc: 0.3948 - f1_score: 0.0366 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6651 - acc: 0.5468 - f1_score: 0.4684 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 224us/steposs: 0.6646 - acc: 0.4422 - f1_score: 0.\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6652 - acc: 0.4370 - f1_score: 0.1616 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 8s 227us/steps: 0.6946 - acc: 0.5371 - f1_score: 0.45\n",
      "37489/37489 [==============================] - 12s 316us/step - loss: 0.6797 - acc: 0.5785 - f1_score: 0.5608 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "28032/37489 [=====================>........] - ETA: 2s - loss: 0.6639 - acc: 0.6211 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 271us/step - loss: 0.6878 - acc: 0.6186 - f1_score: 0.6665 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 159us/step\n",
      "37489/37489 [==============================] - 6s 167us/step\n",
      "37248/37489 [============================>.] - ETA: 0s - loss: 9.9553 - acc: 0.3822 - f1_score: 0.3820Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 25s 661us/step - loss: 9.9523 - acc: 0.3824 - f1_score: 0.3822 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 10s 271us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 345us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 30s 799us/step - loss: 0.6755 - acc: 0.3840 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 376us/step - loss: 0.6653 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 376us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 14s 370us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 0.6653 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 375us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 375us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 376us/step - loss: 0.6649 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 0.6649 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 377us/step - loss: 0.6647 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 376us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "10624/37488 [=======>......................] - ETA: 9s - loss: 0.6620 - acc: 0.3758 - f1_score: 0.0000e+00Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 376us/step - loss: 0.6649 - acc: 0.3811 - f1_score: 1.0347e-04 - val_loss: 0.6626 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 0.6764 - acc: 0.5669 - f1_score: 0.5291 - val_loss: 0.6624 - val_acc: 0.6244 - val_f1_score: 0.6666\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 0.6648 - acc: 0.6187 - f1_score: 0.6666 - val_loss: 0.6624 - val_acc: 0.6244 - val_f1_score: 0.6666\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 9.9514 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 230us/steposs: 0.6657 - acc: 0.6168 - f1_score: 0.\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 0.6649 - acc: 0.6187 - f1_score: 0.6666 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 9s 230us/step\n",
      "37488/37488 [==============================] - 11s 281us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6666 - val_loss: 0.6645 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "10304/37488 [=======>......................] - ETA: 6s - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 11s 281us/step - loss: 0.6650 - acc: 0.6187 - f1_score: 0.6666 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 1s 157us/step\n",
      "37488/37488 [==============================] - 6s 169us/step\n",
      "37489/37489 [==============================] - 29s 763us/step - loss: 0.6691 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "   64/37489 [..............................] - ETA: 11s - loss: 0.6611 - acc: 0.3750 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 277us/step - loss: 0.6660 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 341us/step - loss: 0.6660 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 30s 802us/step - loss: 6.1439 - acc: 0.6178 - f1_score: 0.6178 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6659 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "22528/37489 [=================>............] - ETA: 5s - loss: 0.6662 - acc: 0.3836 - f1_score: 0.0000e+00Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "18624/37489 [=============>................] - ETA: 6s - loss: 6.1049 - acc: 0.6212 - f1_score: 0.6212Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6654 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6661 - acc: 0.3825 - f1_score: 1.0426e-04 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 379us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6658 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 243us/steposs: 6.1523 - acc: 0.6183 - f1_score: 0.\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 8s 224us/stepss: 6.1101 - acc: 0.6209 - f1_score: 0.62\n",
      "37489/37489 [==============================] - 11s 292us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "17408/37489 [============>.................] - ETA: 5s - loss: 6.1721 - acc: 0.6171 - f1_score: 0.6171Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 280us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 161us/step\n",
      "37489/37489 [==============================] - 7s 174us/step\n",
      "37489/37489 [==============================] - 26s 701us/step - loss: 0.6675 - acc: 0.6174 - f1_score: 0.6651 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      " 2624/37489 [=>............................] - ETA: 10s - loss: 0.6674 - acc: 0.6136 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 275us/step - loss: 0.6656 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 13s 340us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 30s 802us/step - loss: 0.6676 - acc: 0.3842 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 349us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6660 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 0.6654 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "15936/37489 [===========>..................] - ETA: 7s - loss: 0.6661 - acc: 0.3827 - f1_score: 0.0000e+00Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6653 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "27328/37489 [====================>.........] - ETA: 3s - loss: 0.6658 - acc: 0.6168 - f1_score: 0.6667Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6647 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 223us/steposs: 0.6663 - acc: 0.3839 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 9s 229us/stepss: 0.6665 - acc: 0.3837 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 11s 281us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "16256/37489 [============>.................] - ETA: 5s - loss: 0.6641 - acc: 0.3795 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 278us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 164us/step\n",
      "37489/37489 [==============================] - 6s 169us/step\n",
      "37488/37488 [==============================] - 27s 708us/step - loss: 0.6666 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6671 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      " 1664/37488 [>.............................] - ETA: 8s - loss: 0.6641 - acc: 0.3792 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 10s 273us/step - loss: 0.6654 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6647 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 12s 331us/step - loss: 0.6649 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 30s 796us/step - loss: 1.7543 - acc: 0.6170 - f1_score: 0.6513 - val_loss: 0.6625 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 357us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6658 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6643 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6651 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6640 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6648 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6647 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6647 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6636 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6604 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6641 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6632 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "15040/37489 [===========>..................] - ETA: 7s - loss: 0.6653 - acc: 0.6157 - f1_score: 0.6667Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6640 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6630 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6639 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6626 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6639 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6226 - val_f1_score: 0.6668\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6630 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6702 - val_acc: 0.3795 - val_f1_score: 0.0000e+00\n",
      "13632/37489 [=========>....................] - ETA: 8s - loss: 0.6659 - acc: 0.6122 - f1_score: 0.6667Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6634 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 362us/step - loss: 0.6624 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6631 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6215 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 0.6626 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6632 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6686 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6622 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6668 - val_acc: 0.3766 - val_f1_score: 3.7819e-04\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6630 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 370us/step - loss: 0.6621 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6601 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6629 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6641 - acc: 0.3806 - f1_score: 5.2530e-05 - val_loss: 0.6640 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6632 - acc: 0.6178 - f1_score: 0.6668 - val_loss: 0.6617 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6634 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6652 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6641 - acc: 0.6181 - f1_score: 0.6668 - val_loss: 0.6628 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 0.6622 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6634 - acc: 0.6182 - f1_score: 0.6668 - val_loss: 0.6617 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6615 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6739 - val_acc: 0.3806 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 227us/steposs: 0.6636 - acc: 0.6186 - f1_score: 0.\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6635 - acc: 0.6183 - f1_score: 0.6668 - val_loss: 0.6700 - val_acc: 0.6205 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 8s 227us/stepss: 0.6678 - acc: 0.6028 - f1_score: 0.\n",
      "37489/37489 [==============================] - 10s 279us/step - loss: 0.6631 - acc: 0.6182 - f1_score: 0.6668 - val_loss: 0.6632 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "15360/37489 [===========>..................] - ETA: 5s - loss: 0.6616 - acc: 0.6238 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 276us/step - loss: 0.6628 - acc: 0.6188 - f1_score: 0.6668 - val_loss: 0.6616 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 2s 170us/step\n",
      "37489/37489 [==============================] - 6s 173us/step\n",
      "37489/37489 [==============================] - 27s 709us/step - loss: 0.6677 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      " 4352/37489 [==>...........................] - ETA: 8s - loss: 0.6684 - acc: 0.3883 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 271us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 322us/step - loss: 0.6651 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 30s 804us/step - loss: 0.6699 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 348us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6654 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6643 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6701 - val_acc: 0.3801 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6647 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6643 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6648 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6637 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6642 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "30656/37489 [=======================>......] - ETA: 2s - loss: 0.6634 - acc: 0.3816 - f1_score: 0.0000e+00Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6635 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6658 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6641 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6637 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6637 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6631 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6635 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6630 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3753 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6632 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6628 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6632 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "33408/37489 [=========================>....] - ETA: 1s - loss: 0.6630 - acc: 0.3809 - f1_score: 0.0000e+00Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6628 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6632 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6626 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6633 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6621 - acc: 0.3800 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6628 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6601 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6622 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6623 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6621 - acc: 0.3801 - f1_score: 0.0000e+00 - val_loss: 0.6652 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6624 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6642 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6619 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6623 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6602 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6617 - acc: 0.3801 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3785 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6619 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6616 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 237us/steposs: 0.6644 - acc: 0.3829 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 9s 229us/steps: 0.6624 - acc: 0.3800 - f1\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 0.6625 - acc: 0.3801 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 10s 273us/step - loss: 0.6618 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "11136/37489 [=======>......................] - ETA: 6s - loss: 0.6628 - acc: 0.3820 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 276us/step - loss: 0.6616 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 186us/step\n",
      "37489/37489 [==============================] - 7s 178us/steposs: 9.7100 - acc: 0.6149 - f1_score: 0.60\n",
      "37489/37489 [==============================] - 27s 721us/step - loss: 9.9338 - acc: 0.6174 - f1_score: 0.6102 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 2/20\n",
      " 8384/37489 [=====>........................] - ETA: 7s - loss: 9.9162 - acc: 0.6151 - f1_score: 0.6068Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 277us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 12s 315us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 30s 808us/step - loss: 6.2588 - acc: 0.3812 - f1_score: 0.3773 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 353us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 370us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      " 3328/37488 [=>............................] - ETA: 11s - loss: 6.1266 - acc: 0.3777 - f1_score: 0.3777Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 375us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 377us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6103 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9493 - acc: 0.6174 - f1_score: 0.6104 - val_loss: 10.0541 - val_acc: 0.6242 - val_f1_score: 0.6172\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "9372/9372 [==============================] - 2s 238us/steploss: 6.1967 - acc: 0.3746 - f1_score: 0.37\n",
      "37489/37489 [==============================] - 9s 229us/steps: 6.2495 - acc: 0.3800 - f1_score: 0.\n",
      "37488/37488 [==============================] - 13s 342us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 10s 277us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      " 3392/37488 [=>............................] - ETA: 8s - loss: 6.3151 - acc: 0.3889 - f1_score: 0.3889Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 10s 276us/step - loss: 6.2666 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 6.1724 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9373/9373 [==============================] - 1s 159us/step\n",
      "37488/37488 [==============================] - 7s 198us/stepss: 0.7590 - acc: 0.6146 - f1_score: 0.\n",
      "37489/37489 [==============================] - 28s 736us/step - loss: 0.6934 - acc: 0.6157 - f1_score: 0.6577 - val_loss: 0.6638 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "15808/37489 [===========>..................] - ETA: 5s - loss: 0.6687 - acc: 0.6106 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 278us/step - loss: 0.6653 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 11s 302us/step - loss: 0.6650 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 30s 810us/step - loss: 0.6667 - acc: 0.6178 - f1_score: 0.6615 - val_loss: 0.6616 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 0.6647 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6650 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6646 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6238 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6648 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6666 - val_loss: 0.6627 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6642 - acc: 0.6171 - f1_score: 0.6666 - val_loss: 0.6626 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6643 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6643 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6640 - acc: 0.6172 - f1_score: 0.6666 - val_loss: 0.6618 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6645 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6640 - acc: 0.6173 - f1_score: 0.6666 - val_loss: 0.6621 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6639 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6641 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6640 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6640 - acc: 0.6175 - f1_score: 0.6666 - val_loss: 0.6619 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6636 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6641 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6638 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6639 - acc: 0.6176 - f1_score: 0.6666 - val_loss: 0.6624 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6634 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6637 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6632 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6638 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6630 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 0.6639 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6634 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6639 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6626 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6691 - val_acc: 0.6209 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6638 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6626 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6637 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6630 - acc: 0.6198 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "9372/9372 [==============================] - 2s 223us/steploss: 0.6659 - acc: 0.6147 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 9s 229us/steps: 0.6630 - acc: 0.6185 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 13s 341us/step - loss: 0.6625 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6234 - val_f1_score: 0.6666\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 11s 286us/step - loss: 0.6628 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "   64/37489 [..............................] - ETA: 11s - loss: 0.6929 - acc: 0.5312 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 283us/step - loss: 0.6622 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 163us/step\n",
      "37489/37489 [==============================] - 8s 210us/stepss: 0.8739 - acc: 0.6141 - f1_score: 0.64\n",
      "37489/37489 [==============================] - 28s 755us/step - loss: 0.7512 - acc: 0.6151 - f1_score: 0.6570 - val_loss: 0.6644 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "19968/37489 [==============>...............] - ETA: 4s - loss: 0.6667 - acc: 0.6162 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 277us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6650 - val_acc: 0.6242 - val_f1_score: 0.6666\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 11s 291us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 13s 350us/step - loss: 0.6644 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 31s 816us/step - loss: 0.8917 - acc: 0.6136 - f1_score: 0.6649 - val_loss: 0.6621 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6645 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6645 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6643 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6642 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6641 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6649 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6646 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6641 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6649 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6641 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6647 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6639 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6645 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6638 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6666 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6645 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6637 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 0.6643 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6652 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6638 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6643 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 0.6637 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6640 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6639 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 0.6641 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6635 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 380us/step - loss: 0.6636 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6634 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 379us/step - loss: 0.6634 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6631 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 227us/steposs: 0.6629 - acc: 0.6189 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6633 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 9s 234us/steps: 0.6643 - acc: 0.6168 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 319us/step - loss: 0.6633 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "33728/37489 [=========================>....] - ETA: 0s - loss: 0.6630 - acc: 0.6178 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 279us/step - loss: 0.6629 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 10s 275us/step - loss: 0.6626 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6677 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 157us/step\n",
      "37489/37489 [==============================] - 8s 223us/stepss: 0.6885 - acc: 0.3848 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 29s 768us/step - loss: 0.6777 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "25920/37488 [===================>..........] - ETA: 2s - loss: 0.6653 - acc: 0.3812 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 10s 271us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 10s 277us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 31s 821us/step - loss: 0.6693 - acc: 0.3832 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 358us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6661 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 0.6643 - acc: 0.3811 - f1_score: 5.1734e-05 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6642 - acc: 0.3814 - f1_score: 1.0347e-04 - val_loss: 0.6610 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6651 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6637 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6667 - acc: 0.6017 - f1_score: 0.6186 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 371us/step - loss: 0.6638 - acc: 0.3812 - f1_score: 0.0012 - val_loss: 0.6609 - val_acc: 0.3764 - val_f1_score: 0.0026\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 376us/step - loss: 0.6636 - acc: 0.3808 - f1_score: 2.0693e-04 - val_loss: 0.6603 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6639 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6635 - acc: 0.3814 - f1_score: 9.2816e-04 - val_loss: 0.6613 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6634 - acc: 0.3806 - f1_score: 1.0347e-04 - val_loss: 0.6609 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6638 - acc: 0.3812 - f1_score: 5.1734e-05 - val_loss: 0.6643 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6637 - acc: 0.3829 - f1_score: 0.0153 - val_loss: 0.6607 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 367us/step - loss: 0.6631 - acc: 0.3807 - f1_score: 1.5520e-04 - val_loss: 0.6612 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 366us/step - loss: 0.6681 - acc: 0.4745 - f1_score: 0.2994 - val_loss: 0.6620 - val_acc: 0.6236 - val_f1_score: 0.6665\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6650 - acc: 0.6189 - f1_score: 0.6666 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6645 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 369us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 2s 243us/steposs: 0.6655 - acc: 0.6172 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 9s 229us/steps: 0.6642 - acc: 0.6197 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 310us/step - loss: 0.6650 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "29696/37489 [======================>.......] - ETA: 1s - loss: 0.6649 - acc: 0.6170 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 276us/step - loss: 0.6646 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 10s 276us/step - loss: 0.6647 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 172us/step\n",
      "37489/37489 [==============================] - 9s 236us/stepss: 7.9757 - acc: 0.3825 - f1_score: 0.\n",
      "37489/37489 [==============================] - 29s 775us/step - loss: 7.4045 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "31552/37489 [========================>.....] - ETA: 1s - loss: 6.1383 - acc: 0.3808 - f1_score: 0.3808Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 276us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 10s 275us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 31s 820us/step - loss: 1.2157 - acc: 0.3983 - f1_score: 1.0506e-04 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6658 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6654 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6655 - acc: 0.5059 - f1_score: 0.3595 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 362us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "23360/37489 [=================>............] - ETA: 4s - loss: 6.1616 - acc: 0.3823 - f1_score: 0.3823Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 360us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6644 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1529 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 242us/steposs: 0.6626 - acc: 0.6226 - f1_score: 0.\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6644 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 9s 228us/steps: 0.6695 - acc: 0.6085 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 11s 298us/step - loss: 0.6644 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "22528/37489 [=================>............] - ETA: 3s - loss: 0.6640 - acc: 0.6188 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 277us/step - loss: 0.6641 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 10s 275us/step - loss: 0.6640 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 240us/step loss: 6.1494 - acc: 0.3826 - f1_score: 0.\n",
      "37489/37489 [==============================] - 9s 235us/steps: 6.1824 - acc: 0.3838 - f1_score: 0.31\n",
      "37489/37489 [==============================] - 30s 798us/step - loss: 6.1699 - acc: 0.3830 - f1_score: 0.3228 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37312/37489 [============================>.] - ETA: 0s - loss: 6.1691 - acc: 0.3827 - f1_score: 0.3827Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 278us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 10s 272us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 13s 337us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 31s 831us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 347us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 375us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 377us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 370us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 375us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 371us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 377us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 376us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 376us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 14s 379us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 226us/steposs: 9.7782 - acc: 0.3887 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 9s 234us/steps: 9.9105 - acc: 0.3812 - f1\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 11s 284us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      " 9856/37488 [======>.......................] - ETA: 7s - loss: 9.9234 - acc: 0.3806 - f1_score: 0.3806Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 11s 281us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 12s 311us/step - loss: 9.9117 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0231 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9373/9373 [==============================] - 2s 247us/steploss: 0.6647 - acc: 0.3775 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 8s 215us/step\n",
      "37489/37489 [==============================] - 31s 820us/step - loss: 0.6666 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 10s 274us/step - loss: 0.6658 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6650 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "11776/37489 [========>.....................] - ETA: 6s - loss: 0.6634 - acc: 0.3775 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 276us/step - loss: 0.6660 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 12s 307us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 31s 832us/step - loss: 9.7814 - acc: 0.3817 - f1_score: 0.3625 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 358us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6657 - acc: 0.3832 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 379us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 379us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6651 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 379us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6650 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6651 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3755 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6651 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6649 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6646 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6642 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "9372/9372 [==============================] - 2s 230us/steploss: 9.9899 - acc: 0.3802 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 9s 231us/steps: 9.9841 - acc: 0.3805 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 13s 341us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 11s 285us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      " 1024/37489 [..............................] - ETA: 9s - loss: 10.0738 - acc: 0.3750 - f1_score: 0.3750Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 281us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 340us/step - loss: 9.9630 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 245us/steposs: 0.6695 - acc: 0.6138 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 32s 841us/step - loss: 0.6688 - acc: 0.6147 - f1_score: 0.6648 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 8s 220us/stepss: 0.6633 - acc: 0.6231 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 11s 298us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "19904/37489 [==============>...............] - ETA: 4s - loss: 0.6647 - acc: 0.6196 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 281us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6648 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 11s 286us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 31s 839us/step - loss: 0.6673 - acc: 0.6163 - f1_score: 0.6665 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6652 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 379us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6645 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6684 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6682 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6645 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6644 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6650 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6644 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6646 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6645 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6642 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6649 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 0.6639 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6649 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6638 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 383us/step - loss: 0.6650 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6636 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6638 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 232us/steposs: 0.6650 - acc: 0.6172 - f1_score: 0.\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6648 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 9s 229us/steps: 0.6657 - acc: 0.6162 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 12s 321us/step - loss: 0.6649 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "34688/37489 [==========================>...] - ETA: 0s - loss: 0.6643 - acc: 0.6182 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 278us/step - loss: 0.6647 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 10s 274us/step - loss: 0.6645 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 357us/step - loss: 0.6647 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 232us/steposs: 0.7152 - acc: 0.3806 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 31s 839us/step - loss: 0.7119 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 8s 216us/steps: 0.6656 - acc: 0.3815 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 11s 302us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "27008/37488 [====================>.........] - ETA: 2s - loss: 0.6656 - acc: 0.3820 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 10s 275us/step - loss: 0.6653 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 10s 277us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 31s 825us/step - loss: 6.1735 - acc: 0.3825 - f1_score: 0.3806 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 356us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 14s 370us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 14s 361us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "14912/37488 [==========>...................] - ETA: 7s - loss: 0.6646 - acc: 0.3803 - f1_score: 0.0000e+00Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 364us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 14s 370us/step - loss: 0.6650 - acc: 0.4231 - f1_score: 0.1183 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 363us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 365us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 371us/step - loss: 0.6650 - acc: 0.4868 - f1_score: 0.3065 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 368us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 1.5216e-04 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 229us/steposs: 6.2170 - acc: 0.3857 - f1_score: 0.\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 9s 236us/steps: 6.1872 - acc: 0.3839 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 12s 310us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "31936/37489 [========================>.....] - ETA: 1s - loss: 6.2007 - acc: 0.3847 - f1_score: 0.3847Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 274us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 10s 277us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 13s 347us/step - loss: 6.1645 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 2s 221us/steposs: 6.1544 - acc: 0.6188 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 31s 825us/step - loss: 6.1632 - acc: 0.6183 - f1_score: 0.6162 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 8s 216us/steps: 6.1639 - acc: 0.6176 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 11s 306us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "29056/37489 [======================>.......] - ETA: 2s - loss: 6.1513 - acc: 0.6184 - f1_score: 0.6184Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 272us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 10s 275us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 13s 359us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 31s 834us/step - loss: 0.8096 - acc: 0.6146 - f1_score: 0.6623 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 350us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 2s 237us/steposs: 0.6652 - acc: 0.6183 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 8s 226us/steps: 0.6626 - acc: 0.6230 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 11s 302us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "24000/37489 [==================>...........] - ETA: 3s - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6662Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 280us/step - loss: 0.6649 - acc: 0.6185 - f1_score: 0.6662 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 10s 279us/step - loss: 0.6652 - acc: 0.3896 - f1_score: 0.0240 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 369us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 196us/step\n",
      "37489/37489 [==============================] - 31s 836us/step - loss: 9.8952 - acc: 0.6139 - f1_score: 0.6079 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 9s 234us/steps: 9.9523 - acc: 0.6175 - f1_score: 0.\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 3/20\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 9.9539 - acc: 0.6176 - f1_score: 0.6175Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 279us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 10s 271us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 12s 330us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 32s 843us/step - loss: 0.6770 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 355us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 14s 379us/step - loss: 0.6653 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 14s 378us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6642 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 14s 375us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 14s 374us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6679 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 365us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 14s 374us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 0.6647 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 366us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 14s 375us/step - loss: 0.6648 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6656 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 14s 370us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 14s 377us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 364us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 14s 372us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 14s 378us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 14s 375us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 14s 373us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 9.9514 - acc: 0.6174 - f1_score: 0.6173 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6239\n",
      "9372/9372 [==============================] - 2s 227us/steposs: 0.6638 - acc: 0.3797 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 9s 233us/steps: 0.6650 - acc: 0.3813 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 13s 355us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 10s 278us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "10432/37488 [=======>......................] - ETA: 7s - loss: 0.6665 - acc: 0.3842 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 10s 280us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 11s 303us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 32s 845us/step - loss: 9.9390 - acc: 0.3825 - f1_score: 0.3821 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 13s 360us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 2s 223us/steposs: 9.8840 - acc: 0.3868 - f1_score: 0.\n",
      "37488/37488 [==============================] - 9s 237us/steps: 9.9572 - acc: 0.3822 - f1_score: 0.\n",
      "37489/37489 [==============================] - 13s 351us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 10s 277us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "10496/37489 [=======>......................] - ETA: 7s - loss: 10.0738 - acc: 0.3750 - f1_score: 0.3750Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 277us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 11s 301us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 31s 840us/step - loss: 0.6670 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 13s 356us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 383us/step - loss: 0.6658 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 0.6655 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6650 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 379us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 371us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6654 - acc: 0.5124 - f1_score: 0.3711 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 9.9536 - acc: 0.3825 - f1_score: 0.3825 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "9372/9372 [==============================] - 2s 238us/steploss: 0.6596 - acc: 0.6293 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 9s 231us/steps: 0.6645 - acc: 0.6200 - f1_score: 0.\n",
      "37489/37489 [==============================] - 13s 343us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 11s 284us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      " 3392/37489 [=>............................] - ETA: 8s - loss: 0.6657 - acc: 0.6176 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 282us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 324us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 32s 849us/step - loss: 0.9183 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 14s 361us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 2s 233us/steposs: 0.6676 - acc: 0.3860 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6656 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 9s 235us/stepss: 0.6670 - acc: 0.3850 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 11s 290us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "17088/37489 [============>.................] - ETA: 5s - loss: 0.6650 - acc: 0.3807 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 10s 280us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 11s 292us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 363us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 32s 846us/step - loss: 0.6702 - acc: 0.6168 - f1_score: 0.6662 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 382us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 380us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "35008/37489 [===========================>..] - ETA: 0s - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 381us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 14s 370us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6652 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 14s 367us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 380us/step - loss: 0.6650 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 14s 376us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 14s 377us/step - loss: 0.6652 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 14s 373us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 14s 379us/step - loss: 0.6652 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 14s 374us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 14s 379us/step - loss: 0.6649 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 14s 375us/step - loss: 0.6650 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6666 - val_loss: 0.6616 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 14s 372us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 2s 244us/steposs: 0.6657 - acc: 0.6171 - f1_score: 0.\n",
      "37489/37489 [==============================] - 14s 378us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 9s 229us/steps: 0.6658 - acc: 0.6167 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 12s 332us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37184/37489 [============================>.] - ETA: 0s - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 11s 285us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 11s 284us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 12s 327us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 25s 661us/step - loss: 0.6694 - acc: 0.6174 - f1_score: 0.6653 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 7s 187us/step - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 14s 368us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "37488/37488 [==============================] - 7s 182us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "9372/9372 [==============================] - 2s 222us/steposs: 0.6645 - acc: 0.6179 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 7s 183us/step - loss: 0.6641 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 9s 238us/steps: 0.6610 - acc: 0.6249 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 6s 159us/step - loss: 0.6640 - acc: 0.6189 - f1_score: 0.6666 - val_loss: 0.6619 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 5s 137us/step - loss: 0.6639 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 5s 136us/step - loss: 0.6641 - acc: 0.6180 - f1_score: 0.6666 - val_loss: 0.6603 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 8/20\n",
      "12288/37488 [========>.....................] - ETA: 3s - loss: 0.6621 - acc: 0.6216 - f1_score: 0.6666Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 141us/step - loss: 0.6634 - acc: 0.6193 - f1_score: 0.6666 - val_loss: 0.6601 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 5s 136us/step - loss: 0.6633 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 5s 141us/step - loss: 0.6630 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6627 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6220 - val_f1_score: 0.6668\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 25s 656us/step - loss: 0.6995 - acc: 0.6160 - f1_score: 0.6620 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 168us/step - loss: 0.6622 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 183us/step - loss: 0.6621 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6228 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6653 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6644 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 181us/step - loss: 0.6619 - acc: 0.6197 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 0.6651 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 182us/step - loss: 0.6620 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6670 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6648 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6656 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 7s 184us/step - loss: 0.6618 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6597 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6647 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6643 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 7s 183us/step - loss: 0.6614 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6671 - val_acc: 0.6199 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6644 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6228 - val_f1_score: 0.6668\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 7s 182us/step - loss: 0.6617 - acc: 0.6200 - f1_score: 0.6667 - val_loss: 0.6602 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6641 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 186us/step - loss: 0.6614 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6639 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6224 - val_f1_score: 0.6666\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 7s 182us/step - loss: 0.6612 - acc: 0.6202 - f1_score: 0.6667 - val_loss: 0.6598 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "9373/9373 [==============================] - 1s 127us/steposs: 0.6636 - acc: 0.6197 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 180us/step - loss: 0.6644 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6656 - val_acc: 0.6226 - val_f1_score: 0.6665\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 4s 116us/steps: 0.6570 - acc: 0.6289 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 0.6674 - acc: 0.6173 - f1_score: 0.6662 - val_loss: 0.6668 - val_acc: 0.6220 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6640 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6228 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "33664/37489 [=========================>....] - ETA: 0s - loss: 0.6650 - acc: 0.6188 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6652 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6659 - val_acc: 0.6203 - val_f1_score: 0.6666\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 147us/step - loss: 0.6639 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6215 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 0.6663 - acc: 0.6181 - f1_score: 0.6666 - val_loss: 0.6620 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6631 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6664 - val_acc: 0.6211 - val_f1_score: 0.6665\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6637 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6211 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 25s 666us/step - loss: 0.6698 - acc: 0.3845 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6629 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6219 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6627 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6648 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6646 - acc: 0.6184 - f1_score: 0.6666 - val_loss: 0.6623 - val_acc: 0.6207 - val_f1_score: 0.6669\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "9372/9372 [==============================] - 1s 120us/steposs: 0.6666 - acc: 0.3860 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 4s 118us/steps: 0.6650 - acc: 0.3827 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6644 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 5s 138us/step - loss: 0.6643 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 0.6639 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6654 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "22144/37489 [================>.............] - ETA: 1s - loss: 0.6637 - acc: 0.3815 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 0.6637 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 0.6634 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3787 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6631 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6630 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 25s 661us/step - loss: 1.2384 - acc: 0.3833 - f1_score: 0.0194 - val_loss: 0.6647 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6629 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6656 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6625 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6625 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6623 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6655 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6643 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 0.6621 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6664 - val_acc: 0.3793 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6617 - acc: 0.3794 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6639 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6617 - acc: 0.3794 - f1_score: 0.0000e+00 - val_loss: 0.6682 - val_acc: 0.3789 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6636 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      " 1280/37489 [>.............................] - ETA: 5s - loss: 0.6615 - acc: 0.3820 - f1_score: 0.0000e+00Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6619 - acc: 0.3798 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6635 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6638 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6614 - acc: 0.3796 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6632 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "9372/9372 [==============================] - 1s 120us/steposs: 0.6619 - acc: 0.3786 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 4s 116us/steps: 0.6624 - acc: 0.3793 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6628 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 0.6628 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 0.6627 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3753 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "20608/37489 [===============>..............] - ETA: 2s - loss: 0.6628 - acc: 0.3805 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 0.6621 - acc: 0.3804 - f1_score: 0.0000e+00 - val_loss: 0.6717 - val_acc: 0.3812 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6622 - acc: 0.3801 - f1_score: 0.0000e+00 - val_loss: 0.6606 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6626 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3753 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6619 - acc: 0.3793 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 25s 673us/step - loss: 0.6691 - acc: 0.3840 - f1_score: 0.0000e+00 - val_loss: 0.6647 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6619 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3753 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6619 - acc: 0.3802 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6616 - acc: 0.3798 - f1_score: 0.0000e+00 - val_loss: 0.6659 - val_acc: 0.3803 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6650 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6611 - acc: 0.3796 - f1_score: 0.0000e+00 - val_loss: 0.6646 - val_acc: 0.3789 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 131us/steposs: 0.6698 - acc: 0.3924 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 4s 118us/steps: 0.6647 - acc: 0.3824 - f1\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6648 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6646 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6640 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "31232/37489 [=======================>......] - ETA: 0s - loss: 0.6645 - acc: 0.3833 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6641 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 143us/step - loss: 0.6634 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 143us/step - loss: 0.6635 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6631 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6628 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 25s 663us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0215 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6624 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 7s 190us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6626 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 7s 191us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6625 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.3783 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 7s 190us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6622 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6624 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 190us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6621 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6659 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 191us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6626 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "34944/37488 [==========================>...] - ETA: 0s - loss: 6.1804 - acc: 0.3826 - f1_score: 0.0216Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6623 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "37488/37488 [==============================] - 7s 193us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 10/20\n",
      "9372/9372 [==============================] - 1s 130us/steposs: 6.1702 - acc: 0.3828 - f1_score: 0.03\n",
      "37489/37489 [==============================] - 5s 120us/steps: 6.1702 - acc: 0.3817 - f1_score: 0.\n",
      "37488/37488 [==============================] - 6s 173us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 147us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0215 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 5s 144us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 13/20\n",
      "15616/37488 [===========>..................] - ETA: 2s - loss: 6.1960 - acc: 0.3833 - f1_score: 0.0207Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 146us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 5s 145us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 5s 144us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 7s 179us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 25s 670us/step - loss: 0.7017 - acc: 0.3852 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 7s 177us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 191us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6653 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 190us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6653 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 6.1591 - acc: 0.3812 - f1_score: 0.0214 - val_loss: 6.0826 - val_acc: 0.3758 - val_f1_score: 0.0220\n",
      "9373/9373 [==============================] - 1s 124us/steposs: 0.6666 - acc: 0.3854 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6649 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 4s 118us/steps: 0.6622 - acc: 0.3779 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6648 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 0.6651 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 0.6646 - acc: 0.3819 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 0.6649 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 0.6645 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 0.6643 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 0.6647 - acc: 0.3829 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6641 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6643 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 25s 673us/step - loss: 0.6669 - acc: 0.6159 - f1_score: 0.6661 - val_loss: 0.6663 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6643 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6645 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6641 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6642 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6641 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6641 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6637 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6640 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6672 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6642 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6637 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6637 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6634 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6641 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 123us/steposs: 0.6637 - acc: 0.6181 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6635 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 119us/steps: 0.6654 - acc: 0.6162 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 160us/step - loss: 0.6635 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 0.6631 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 0.6629 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      " 8320/37489 [=====>........................] - ETA: 4s - loss: 0.6635 - acc: 0.6143 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 147us/step - loss: 0.6625 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6630 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6220 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6627 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6622 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6647 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 25s 676us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "22784/37489 [=================>............] - ETA: 2s - loss: 0.6627 - acc: 0.6164 - f1_score: 0.6667Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6617 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6220 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6616 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6617 - acc: 0.6194 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6621 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6226 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 1s 111us/steposs: 10.0264 - acc: 0.6221 - f1_score: 0.01\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 5s 120us/steps: 9.9874 - acc: 0.6196 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 143us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 9/20\n",
      " 5120/37489 [===>..........................] - ETA: 4s - loss: 10.0329 - acc: 0.6223 - f1_score: 0.0176Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 143us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 25s 670us/step - loss: 0.6680 - acc: 0.6154 - f1_score: 0.6651 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6649 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6651 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6649 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 9.9712 - acc: 0.6186 - f1_score: 0.0198 - val_loss: 10.0572 - val_acc: 0.6242 - val_f1_score: 0.0236\n",
      "9372/9372 [==============================] - 1s 120us/steposs: 0.6663 - acc: 0.6141 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6645 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 4s 115us/steps: 0.6659 - acc: 0.6141 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6648 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 0.6647 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 0.6644 - acc: 0.6173 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6644 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6641 - acc: 0.6169 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 143us/step - loss: 0.6639 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6646 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6642 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 25s 677us/step - loss: 2.6341 - acc: 0.3827 - f1_score: 0.1239 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6642 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 185us/step - loss: 0.6656 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6636 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6635 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 187us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6633 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 124us/steposs: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 7s 183us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 4s 116us/steps: 0.6648 - acc: 0.3810 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 6s 163us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 5s 136us/step - loss: 0.6647 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 5s 142us/step - loss: 0.6643 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "13312/37488 [=========>....................] - ETA: 3s - loss: 0.6651 - acc: 0.3837 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 139us/step - loss: 0.6640 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 5s 142us/step - loss: 0.6988 - acc: 0.3834 - f1_score: 0.0167 - val_loss: 0.6623 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 5s 139us/step - loss: 0.6746 - acc: 0.3870 - f1_score: 0.0225 - val_loss: 0.6741 - val_acc: 0.6222 - val_f1_score: 0.6650\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6855 - acc: 0.4668 - f1_score: 0.2563 - val_loss: 0.6721 - val_acc: 0.6238 - val_f1_score: 0.6662\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 25s 666us/step - loss: 0.6696 - acc: 0.6164 - f1_score: 0.6655 - val_loss: 0.6651 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6736 - acc: 0.5355 - f1_score: 0.4268 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6661 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 183us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0018 - val_loss: 0.6626 - val_acc: 0.3755 - val_f1_score: 7.5366e-04\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 185us/step - loss: 0.6649 - acc: 0.3813 - f1_score: 2.5946e-04 - val_loss: 0.6617 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 181us/step - loss: 0.6676 - acc: 0.4844 - f1_score: 0.2830 - val_loss: 0.6657 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 7s 186us/step - loss: 0.6652 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6657 - acc: 0.6164 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 7s 184us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6650 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 7s 184us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 0.6649 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 183us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 1s 111us/steposs: 0.6651 - acc: 0.6170 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 4s 117us/steps: 0.6648 - acc: 0.6179 - \n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6648 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 0.6646 - acc: 0.6170 - f1_score: 0.6666 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6643 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "28544/37489 [=====================>........] - ETA: 1s - loss: 0.6649 - acc: 0.6168 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6641 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6640 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6749 - acc: 0.6179 - f1_score: 0.6665 - val_loss: 0.6610 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 0.6646 - acc: 0.6175 - f1_score: 0.6666 - val_loss: 0.6615 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6634 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 26s 684us/step - loss: 0.6705 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6634 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6657 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6632 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6213 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6654 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6836 - acc: 0.6168 - f1_score: 0.6632 - val_loss: 0.6678 - val_acc: 0.6232 - val_f1_score: 0.6665\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6662 - acc: 0.6158 - f1_score: 0.6621 - val_loss: 0.6614 - val_acc: 0.6226 - val_f1_score: 0.6665\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6838 - acc: 0.3821 - f1_score: 0.0067 - val_loss: 0.6621 - val_acc: 0.3751 - val_f1_score: 7.5638e-04\n",
      "Epoch 6/20\n",
      "9372/9372 [==============================] - 1s 118us/steposs: 0.6590 - acc: 0.3672 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 5s 123us/steps: 0.6867 - acc: 0.4135 - f1_score: 0.07\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6918 - acc: 0.4042 - f1_score: 0.0591 - val_loss: 0.6613 - val_acc: 0.3751 - val_f1_score: 7.5638e-04\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6670 - acc: 0.3848 - f1_score: 0.0044 - val_loss: 1.8773 - val_acc: 0.4287 - val_f1_score: 0.2408\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6790 - acc: 0.5250 - f1_score: 0.4096 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "17664/37489 [=============>................] - ETA: 2s - loss: 0.6847 - acc: 0.5815 - f1_score: 0.5553Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6972 - acc: 0.5348 - f1_score: 0.4327 - val_loss: 0.6637 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 138us/step - loss: 0.6673 - acc: 0.5311 - f1_score: 0.4207 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6805 - acc: 0.5926 - f1_score: 0.5945 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6662\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6702 - acc: 0.6164 - f1_score: 0.6622 - val_loss: 0.6621 - val_acc: 0.6238 - val_f1_score: 0.6665\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 25s 672us/step - loss: 0.6671 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6657 - acc: 0.5731 - f1_score: 0.5349 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6719 - acc: 0.5118 - f1_score: 0.3620 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6654 - acc: 0.4589 - f1_score: 0.2204 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6752 - acc: 0.3829 - f1_score: 0.0027 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6647 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6696 - acc: 0.4366 - f1_score: 0.1601 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6646 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6654 - acc: 0.5240 - f1_score: 0.4029 - val_loss: 6.8514 - val_acc: 0.6240 - val_f1_score: 0.3569\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6642 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 1.9777 - acc: 0.4452 - f1_score: 0.2464 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6637 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6656 - acc: 0.6039 - f1_score: 0.6214 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 118us/steposs: 0.6627 - acc: 0.3796 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 4s 115us/steps: 0.6636 - acc: 0.3820 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6635 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6636 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 137us/step - loss: 0.6634 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "32000/37489 [========================>.....] - ETA: 0s - loss: 0.6636 - acc: 0.3825 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6631 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 137us/step - loss: 0.6631 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6630 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6629 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6626 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 26s 686us/step - loss: 6.4048 - acc: 0.6174 - f1_score: 0.5793 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6625 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6625 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6650 - val_acc: 0.3793 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6626 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6621 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 112us/steposs: 6.1715 - acc: 0.6171 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 4s 117us/steps: 6.1850 - acc: 0.6163 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "15872/37489 [===========>..................] - ETA: 2s - loss: 6.1570 - acc: 0.6180 - f1_score: 0.6180Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 26s 688us/step - loss: 0.6708 - acc: 0.6148 - f1_score: 0.6655 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 7s 193us/step - loss: 0.6652 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 7s 191us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 7s 188us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 186us/step - loss: 0.6648 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 6.1667 - acc: 0.6174 - f1_score: 0.6174 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "37488/37488 [==============================] - 7s 187us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "9372/9372 [==============================] - 1s 137us/steposs: 0.6603 - acc: 0.6271 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 4s 120us/steps: 0.6641 - acc: 0.6191 - f1_score: 0.\n",
      "37488/37488 [==============================] - 7s 181us/step - loss: 0.6643 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 5s 145us/step - loss: 0.6642 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 5s 140us/step - loss: 0.6643 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "27648/37488 [=====================>........] - ETA: 1s - loss: 0.6640 - acc: 0.6195 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 151us/step - loss: 0.6640 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 5s 141us/step - loss: 0.6638 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 5s 144us/step - loss: 0.6637 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 155us/step - loss: 0.6639 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 7s 177us/step - loss: 0.6639 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 26s 696us/step - loss: 0.6666 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 0.6637 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 194us/step - loss: 0.6633 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6655 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 193us/step - loss: 0.6638 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6649 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 0.6636 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6639 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6654 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "9373/9373 [==============================] - 1s 118us/steposs: 0.6599 - acc: 0.3728 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 5s 122us/steps: 0.6632 - acc: 0.3795 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6646 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6644 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 5s 138us/step - loss: 0.6648 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "19328/37489 [==============>...............] - ETA: 2s - loss: 0.6659 - acc: 0.3863 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6643 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 0.6646 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 0.6643 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 0.6640 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 26s 683us/step - loss: 9.6935 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6638 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6638 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6633 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6640 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6637 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6639 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6636 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6634 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "9372/9372 [==============================] - 1s 114us/steposs: 9.8021 - acc: 0.3748 - f1_score: 0.\n",
      "37489/37489 [==============================] - 4s 116us/steps: 9.7171 - acc: 0.3804 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 143us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 148us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "23936/37489 [==================>...........] - ETA: 1s - loss: 9.7439 - acc: 0.3779 - f1_score: 0.3779Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 166us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 26s 697us/step - loss: 0.6659 - acc: 0.6185 - f1_score: 0.6663 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6645 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 9.6909 - acc: 0.3817 - f1_score: 0.3817 - val_loss: 9.8250 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 128us/steposs: 0.6648 - acc: 0.6182 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 4s 119us/steps: 0.6649 - acc: 0.6182 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6649 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6646 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "28928/37489 [======================>.......] - ETA: 1s - loss: 0.6639 - acc: 0.6196 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 0.6644 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 0.6638 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 143us/step - loss: 0.6637 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6633 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6637 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 26s 689us/step - loss: 0.6703 - acc: 0.3839 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6629 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6631 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6659 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6629 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6628 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6628 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6650 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6630 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6647 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6632 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 110us/steposs: 0.6652 - acc: 0.3836 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6646 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 4s 115us/steps: 0.6639 - acc: 0.3818 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 0.6643 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 147us/step - loss: 0.6644 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6640 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "11904/37489 [========>.....................] - ETA: 3s - loss: 0.6604 - acc: 0.3775 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6635 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6641 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6635 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6634 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 26s 691us/step - loss: 6.1250 - acc: 0.6181 - f1_score: 0.6181 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6638 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3787 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 190us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6636 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6634 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 196us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 8s 203us/step - loss: 0.6632 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 8s 225us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 9s 235us/step - loss: 0.6632 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6607 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 124us/steposs: 6.1575 - acc: 0.6180 - f1_score: 0.\n",
      "37488/37488 [==============================] - 8s 225us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 151us/steps: 6.3362 - acc: 0.6069 - f1_score: 0.60\n",
      "37488/37488 [==============================] - 6s 165us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 158us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "33536/37488 [=========================>....] - ETA: 0s - loss: 6.1077 - acc: 0.6211 - f1_score: 0.6211Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 147us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 5s 137us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 5s 138us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 6s 150us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 7s 190us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 26s 698us/step - loss: 0.6960 - acc: 0.6159 - f1_score: 0.6644 - val_loss: 0.6678 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 7s 198us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 9s 231us/step - loss: 0.6658 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 9s 232us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 8s 225us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 8s 215us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "25216/37489 [===================>..........] - ETA: 2s - loss: 0.6663 - acc: 0.6160 - f1_score: 0.6667Epoch 17/20\n",
      "37489/37489 [==============================] - 8s 208us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 198us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6657 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 8s 213us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 8s 223us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 8s 213us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 8s 207us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6637 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 7s 193us/step - loss: 6.1436 - acc: 0.6188 - f1_score: 0.6188 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9373/9373 [==============================] - 1s 121us/steposs: 0.6661 - acc: 0.6166 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 5s 132us/steps: 0.6656 - acc: 0.6177 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 148us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      " 4992/37489 [==>...........................] - ETA: 5s - loss: 0.6649 - acc: 0.6190 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 200us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 8s 223us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 29s 780us/step - loss: 0.6687 - acc: 0.6179 - f1_score: 0.6641 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 8s 202us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 8s 210us/step - loss: 0.6656 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 8s 218us/step - loss: 0.6654 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 9s 227us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 8s 215us/step - loss: 0.6652 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 8s 212us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6653 - acc: 0.6168 - f1_score: 0.6655 - val_loss: 0.6624 - val_acc: 0.6244 - val_f1_score: 0.6666\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6655 - acc: 0.4995 - f1_score: 0.3363 - val_loss: 0.6626 - val_acc: 0.3774 - val_f1_score: 0.0030\n",
      "9372/9372 [==============================] - 1s 120us/steposs: 0.6653 - acc: 0.6183 - f1_sco\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 124us/steps: 0.6662 - acc: 0.6164 - f1_score: 0.\n",
      "37489/37489 [==============================] - 9s 231us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 9s 238us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "35328/37489 [===========================>..] - ETA: 0s - loss: 0.6655 - acc: 0.6179 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 147us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 0.6651 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 8s 208us/step - loss: 0.6653 - acc: 0.4940 - f1_score: 0.3183 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 27s 724us/step - loss: 0.6841 - acc: 0.6134 - f1_score: 0.6666 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6654 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6658 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6642 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6651 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 126us/steposs: 0.6655 - acc: 0.6180 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 4s 116us/steps: 0.6639 - acc: 0.6201 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 160us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "11392/37489 [========>.....................] - ETA: 3s - loss: 0.6675 - acc: 0.6136 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 157us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 180us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 27s 730us/step - loss: 6.1533 - acc: 0.3840 - f1_score: 0.3816 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 8s 203us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 8s 206us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 8s 200us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6645 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6641 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "25600/37489 [===================>..........] - ETA: 1s - loss: 0.6631 - acc: 0.6209 - f1_score: 0.6667Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6643 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 113us/steposs: 6.1090 - acc: 0.3790 - f1_score: 0.37\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 4s 117us/steps: 6.2598 - acc: 0.3884 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 5s 133us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      " 7168/37489 [====>.........................] - ETA: 4s - loss: 6.1477 - acc: 0.3814 - f1_score: 0.3814Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 27s 717us/step - loss: 0.6848 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 7s 187us/step - loss: 0.6654 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 188us/step - loss: 0.6652 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 180us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 187us/step - loss: 0.6650 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 9s 236us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 9s 233us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 190us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 132us/steposs: 0.6646 - acc: 0.3800 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 4s 116us/steps: 0.6650 - acc: 0.3814 - f1_score: 0.0000\n",
      "37488/37488 [==============================] - 7s 190us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 148us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 6s 148us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "31488/37488 [========================>.....] - ETA: 0s - loss: 0.6650 - acc: 0.3822 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 167us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 6s 169us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 7s 184us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 28s 736us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 8s 205us/step - loss: 0.6646 - acc: 0.3812 - f1_score: 5.2530e-05 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      " 1152/37489 [..............................] - ETA: 7s - loss: 5.9883 - acc: 0.3707 - f1_score: 0.0235Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 8s 200us/step - loss: 0.6645 - acc: 0.3812 - f1_score: 2.1012e-04 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 8s 201us/step - loss: 0.6646 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 8s 202us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 5.2530e-05 - val_loss: 0.6646 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 7s 197us/step - loss: 0.6674 - acc: 0.4681 - f1_score: 0.2619 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 1s 134us/steposs: 6.2694 - acc: 0.3888 - f1_score: 0.\n",
      "37488/37488 [==============================] - 5s 133us/steps: 6.1624 - acc: 0.3822 - f1_score: \n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 158us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 10/20\n",
      "30336/37489 [=======================>......] - ETA: 1s - loss: 6.1883 - acc: 0.3838 - f1_score: 0.0199Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0204 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 27s 725us/step - loss: 0.6925 - acc: 0.6176 - f1_score: 0.6652 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 200us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 7s 183us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 6.1662 - acc: 0.3825 - f1_score: 0.0205 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.0234\n",
      "9372/9372 [==============================] - 1s 121us/steposs: 0.6648 - acc: 0.6183 - f1_score: \n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6647 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 4s 116us/steps: 0.6651 - acc: 0.6168 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6643 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 147us/step - loss: 0.6642 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 0.6637 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "19200/37489 [==============>...............] - ETA: 2s - loss: 0.6630 - acc: 0.6186 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6634 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6682 - val_acc: 0.6209 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 0.6639 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6683 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 143us/step - loss: 0.6637 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6633 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6215 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6633 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 26s 700us/step - loss: 9.9631 - acc: 0.6182 - f1_score: 0.6146 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6637 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 0.6635 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6637 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6634 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6635 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "9372/9372 [==============================] - 1s 114us/steposs: 10.1997 - acc: 0.6328 - f1_score: 0.\n",
      "37489/37489 [==============================] - 4s 114us/steps: 9.9677 - acc: 0.6184 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 167us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 5s 138us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 138us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "28800/37489 [======================>.......] - ETA: 1s - loss: 9.9423 - acc: 0.6168 - f1_score: 0.6168Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 138us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 138us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 26s 692us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3269 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3269 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3268 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 8s 206us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3269 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 8s 201us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 8s 210us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3267 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 8s 206us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3267 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 9.9704 - acc: 0.6186 - f1_score: 0.6186 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 1s 147us/steposs: 6.1713 - acc: 0.3821 - f1_score: 0.\n",
      "37489/37489 [==============================] - 8s 211us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3268 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 5s 133us/steps: 6.2118 - acc: 0.3850 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3267 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3267 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3268 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 11/20\n",
      " 3200/37489 [=>............................] - ETA: 5s - loss: 5.9637 - acc: 0.3691 - f1_score: 0.3167Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3269 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3267 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3267 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3267 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 28s 749us/step - loss: 9.9677 - acc: 0.3817 - f1_score: 0.3797 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3268 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3269 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3268 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 188us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3267 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 8s 203us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3267 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 186us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 6.1765 - acc: 0.3826 - f1_score: 0.3269 - val_loss: 6.0640 - val_acc: 0.3758 - val_f1_score: 0.3189\n",
      "9372/9372 [==============================] - 1s 115us/steposs: 9.9928 - acc: 0.3800 - f1_score: 0.38\n",
      "37488/37488 [==============================] - 7s 184us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 4s 117us/steps: 9.9567 - acc: 0.3823 - f1_score: 0.\n",
      "37488/37488 [==============================] - 6s 165us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 5s 143us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 5s 145us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "20992/37488 [===============>..............] - ETA: 2s - loss: 10.0208 - acc: 0.3783 - f1_score: 0.3783Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 5s 143us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 5s 144us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 5s 141us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 6s 157us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 170us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 26s 697us/step - loss: 0.7005 - acc: 0.6155 - f1_score: 0.6656 - val_loss: 0.6658 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 7s 184us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6655 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 183us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6652 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 185us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6650 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6647 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 184us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6647 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 7s 187us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0572 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9373/9373 [==============================] - 1s 121us/steposs: 0.6642 - acc: 0.6174 - \n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6639 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6694 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 4s 116us/steps: 0.6648 - acc: 0.6156 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6640 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 147us/step - loss: 0.6636 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 0.6635 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6228 - val_f1_score: 0.6668\n",
      "Epoch 10/20\n",
      "24320/37489 [==================>...........] - ETA: 1s - loss: 0.6626 - acc: 0.6188 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 0.6635 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 139us/step - loss: 0.6631 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6668 - val_acc: 0.6205 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 147us/step - loss: 0.6632 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 0.6628 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      " 4736/37489 [==>...........................] - ETA: 2:08 - loss: 6.1464 - acc: 0.3809 - f1_score: 0.3189Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6627 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6217 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 27s 720us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 0.6628 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6232 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6627 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 180us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6623 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6228 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3218 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6621 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6623 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6619 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 1s 119us/steposs: 6.1564 - acc: 0.3820 - f1_score\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3216 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 4s 117us/steps: 6.1729 - acc: 0.3830 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3218 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 136us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 11/20\n",
      "25472/37489 [===================>..........] - ETA: 1s - loss: 6.1860 - acc: 0.3838 - f1_score: 0.3243Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3218 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 143us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 137us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 27s 707us/step - loss: 1.8446 - acc: 0.3826 - f1_score: 0.0796 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3218 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6661 - acc: 0.3814 - f1_score: 5.2127e-05 - val_loss: 0.6660 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3216 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6654 - acc: 0.3815 - f1_score: 3.1558e-04 - val_loss: 0.6626 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6677 - acc: 0.5204 - f1_score: 0.3921 - val_loss: 0.6625 - val_acc: 0.6238 - val_f1_score: 0.6665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3217 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6656 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 6.1525 - acc: 0.3817 - f1_score: 0.3218 - val_loss: 6.0733 - val_acc: 0.3758 - val_f1_score: 0.3111\n",
      "9372/9372 [==============================] - 1s 109us/steposs: 0.6650 - acc: 0.6194 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6653 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 4s 115us/steps: 0.6631 - acc: 0.6226 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "14464/37489 [==========>...................] - ETA: 3s - loss: 0.6657 - acc: 0.6166 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 143us/step - loss: 0.6644 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 148us/step - loss: 0.6643 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6631 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6641 - acc: 0.6187 - f1_score: 0.6666 - val_loss: 0.6610 - val_acc: 0.6226 - val_f1_score: 0.6665\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 27s 712us/step - loss: 0.9742 - acc: 0.6078 - f1_score: 0.6567 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6634 - acc: 0.6169 - f1_score: 0.6637 - val_loss: 0.6606 - val_acc: 0.6234 - val_f1_score: 0.6663\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6659 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6635 - acc: 0.6187 - f1_score: 0.6664 - val_loss: 0.6604 - val_acc: 0.6232 - val_f1_score: 0.6664\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6638 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6632 - acc: 0.6186 - f1_score: 0.6666 - val_loss: 0.6605 - val_acc: 0.6228 - val_f1_score: 0.6665\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6632 - acc: 0.6186 - f1_score: 0.6666 - val_loss: 0.6602 - val_acc: 0.6236 - val_f1_score: 0.6665\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6650 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6630 - acc: 0.6190 - f1_score: 0.6666 - val_loss: 0.6615 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6647 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6629 - acc: 0.6191 - f1_score: 0.6666 - val_loss: 0.6621 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 0.6643 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6628 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6236 - val_f1_score: 0.6666\n",
      "9372/9372 [==============================] - 1s 114us/steposs: 0.6638 - acc: 0.6194 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 4s 119us/steps: 0.6644 - acc: 0.6172 - f1\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6643 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 0.6640 - acc: 0.6173 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 140us/step - loss: 0.6637 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6635 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "  128/37489 [..............................] - ETA: 4s - loss: 0.6495 - acc: 0.6406 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6636 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 0.6636 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 141us/step - loss: 0.6630 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6220 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6633 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 27s 714us/step - loss: 0.6654 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 0.6629 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 0.6645 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 0.6630 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 188us/step - loss: 0.6644 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6627 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 186us/step - loss: 0.6641 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 0.6627 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 190us/step - loss: 0.6642 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6624 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6219 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 126us/steposs: 0.6617 - acc: 0.3777 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 4s 116us/steps: 0.6636 - acc: 0.3809 - f1_s\n",
      "37488/37488 [==============================] - 7s 185us/step - loss: 0.6638 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 149us/step - loss: 0.6634 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 147us/step - loss: 0.6634 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3783 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37248/37488 [============================>.] - ETA: 0s - loss: 0.6632 - acc: 0.3815 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 152us/step - loss: 0.6632 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 5s 141us/step - loss: 0.6628 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 148us/step - loss: 0.6627 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 5s 145us/step - loss: 0.6624 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 7s 181us/step - loss: 0.6620 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "33408/37489 [=========================>....] - ETA: 2s - loss: 0.6679 - acc: 0.6141 - f1_score: 0.6628Epoch 14/20\n",
      "37489/37489 [==============================] - 27s 721us/step - loss: 0.6679 - acc: 0.6140 - f1_score: 0.6632 - val_loss: 0.6649 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 7s 175us/step - loss: 0.6621 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6656 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6642 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 190us/step - loss: 0.6619 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6652 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 0.6619 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6650 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 193us/step - loss: 0.6621 - acc: 0.3809 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6647 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 0.6616 - acc: 0.3808 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3804 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6644 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 0.6614 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6642 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 0.6611 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6602 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 1s 119us/steposs: 0.6650 - acc: 0.6164 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6646 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 4s 118us/steps: 0.6649 - acc: 0.6166 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 158us/step - loss: 0.6645 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 147us/step - loss: 0.6640 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6643 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      " 9856/37489 [======>.......................] - ETA: 5s - loss: 0.6623 - acc: 0.6202 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 0.6636 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6636 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6638 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6634 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 185us/step - loss: 0.6631 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6220 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 28s 752us/step - loss: 0.6666 - acc: 0.3836 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6634 - acc: 0.6170 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6646 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6632 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6644 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6651 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6627 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6648 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6627 - acc: 0.6171 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6644 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6627 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 111us/steposs: 0.6634 - acc: 0.3808 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6639 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 4s 118us/steps: 0.6647 - acc: 0.3841 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 6s 157us/step - loss: 0.6640 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 147us/step - loss: 0.6635 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6638 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      " 4608/37489 [==>...........................] - ETA: 4s - loss: 0.6584 - acc: 0.3702 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 0.6636 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6630 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6633 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6631 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 28s 736us/step - loss: 0.6718 - acc: 0.6138 - f1_score: 0.6639 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6628 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6624 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6621 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6643 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6624 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6641 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6620 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6616 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6649 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6623 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 119us/steposs: 0.6645 - acc: 0.6181 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6639 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 121us/steps: 0.6617 - acc: 0.6214 - f1_score: 0.\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 0.6638 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6637 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6634 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      " 2560/37489 [=>............................] - ETA: 6s - loss: 0.6557 - acc: 0.6324 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6632 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6631 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6624 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6628 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6644 - val_acc: 0.6220 - val_f1_score: 0.6668\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 28s 735us/step - loss: 1.4820 - acc: 0.4120 - f1_score: 0.0414 - val_loss: 0.6644 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6628 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6224 - val_f1_score: 0.6668\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6662 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6623 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6234 - val_f1_score: 0.6668\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6628 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6622 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6230 - val_f1_score: 0.6668\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6652 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6619 - acc: 0.6198 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6236 - val_f1_score: 0.6668\n",
      "9372/9372 [==============================] - 1s 120us/steposs: 0.6654 - acc: 0.3833 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 5s 123us/steps: 0.6649 - acc: 0.3828 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6651 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37120/37489 [============================>.] - ETA: 0s - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 0.6651 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 0.6647 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6645 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 0.6646 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6646 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 27s 732us/step - loss: 0.6716 - acc: 0.6180 - f1_score: 0.6657 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6644 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 7s 191us/step - loss: 0.6652 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6644 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 0.6651 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 0.6642 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 193us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6644 - acc: 0.3834 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 0.6648 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6628 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6643 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 195us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6641 - acc: 0.3832 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 0.6647 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6642 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 130us/steposs: 0.6643 - acc: 0.6194 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 7s 191us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 123us/steps: 0.6637 - acc: 0.6204 - f1_score: 0.\n",
      "37488/37488 [==============================] - 6s 165us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 6s 150us/step - loss: 0.6643 - acc: 0.6189 - f1_score: 0.6666 - val_loss: 0.6612 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 6s 148us/step - loss: 0.6642 - acc: 0.6189 - f1_score: 0.6666 - val_loss: 0.6612 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "35840/37488 [===========================>..] - ETA: 0s - loss: 0.6643 - acc: 0.6186 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 155us/step - loss: 0.6641 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 151us/step - loss: 0.6664 - acc: 0.4392 - f1_score: 0.1524 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 5s 146us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 6s 153us/step - loss: 0.6651 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 7s 179us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 30s 789us/step - loss: 0.6907 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6651 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 6s 171us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6661 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 195us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 194us/step - loss: 0.6649 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6656 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 7s 194us/step - loss: 0.6648 - acc: 0.3812 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9373/9373 [==============================] - 1s 144us/steposs: 0.6630 - acc: 0.3776 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 5s 121us/steps: 0.6656 - acc: 0.3828 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 157us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6655 - acc: 0.3834 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "33536/37489 [=========================>....] - ETA: 0s - loss: 0.6650 - acc: 0.3820 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 0.6652 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 0.6652 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6649 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 0.6648 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6646 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 28s 749us/step - loss: 6.1744 - acc: 0.6183 - f1_score: 0.6142 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6644 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6669 - val_acc: 0.3781 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6644 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6728 - val_acc: 0.3814 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 8s 202us/step - loss: 0.6640 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3791 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6639 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6640 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6639 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      " 9344/37489 [======>.......................] - ETA: 4s - loss: 0.6643 - acc: 0.3827 - f1_score: 0.0000e+00Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 200us/step - loss: 0.6639 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3787 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6636 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 130us/steposs: 6.1534 - acc: 0.6182 \n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 5s 122us/steps: 6.2109 - acc: 0.6147 - f1_score: 0.61\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 13/20\n",
      "29440/37489 [======================>.......] - ETA: 1s - loss: 6.1478 - acc: 0.6186 - f1_score: 0.6186Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 29s 785us/step - loss: 0.6673 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6653 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6642 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 8s 201us/step - loss: 0.6652 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 6.1529 - acc: 0.6183 - f1_score: 0.6183 - val_loss: 6.0578 - val_acc: 0.6242 - val_f1_score: 0.6242\n",
      "9372/9372 [==============================] - 1s 125us/steposs: 0.6660 - acc: 0.3833 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 5s 127us/steps: 0.6643 - acc: 0.3802 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6651 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "33664/37489 [=========================>....] - ETA: 0s - loss: 0.6650 - acc: 0.3818 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6649 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6645 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6643 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6643 - acc: 0.3814 - f1_score: 5.2528e-05 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 28s 740us/step - loss: 0.6736 - acc: 0.6173 - f1_score: 0.6659 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 173us/step - loss: 0.6640 - acc: 0.3815 - f1_score: 1.0506e-04 - val_loss: 0.6611 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6662 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6640 - acc: 0.3816 - f1_score: 1.0506e-04 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6658 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6641 - acc: 0.3816 - f1_score: 2.0852e-04 - val_loss: 0.6610 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6654 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6639 - acc: 0.3818 - f1_score: 1.0506e-04 - val_loss: 0.6615 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6655 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6635 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6650 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6631 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6725 - val_acc: 0.3797 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6647 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "16768/37489 [============>.................] - ETA: 3s - loss: 0.6644 - acc: 0.3824 - f1_score: 0.0000e+00Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6636 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6653 - acc: 0.6156 - f1_score: 0.6666 - val_loss: 0.6611 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6633 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6646 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 0.6634 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 111us/steposs: 0.6642 - acc: 0.6179 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6642 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 5s 125us/steps: 0.6648 - acc: 0.6153 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6641 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6642 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 144us/step - loss: 0.6638 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6649 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "23936/37489 [==================>...........] - ETA: 1s - loss: 0.6648 - acc: 0.6153 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 147us/step - loss: 0.6638 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6628 - acc: 0.6179 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 5s 147us/step - loss: 0.6636 - acc: 0.6173 - f1_score: 0.6662 - val_loss: 0.6611 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 0.6629 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6634 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 29s 773us/step - loss: 0.6924 - acc: 0.6175 - f1_score: 0.6619 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6632 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 196us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6678 - acc: 0.6172 - f1_score: 0.6661 - val_loss: 0.6629 - val_acc: 0.6217 - val_f1_score: 0.6666\n",
      "9372/9372 [==============================] - 1s 126us/steposs: 0.6648 - acc: 0.6197 - f1_score: 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 7s 191us/step - loss: 0.6650 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 5s 120us/steps: 0.6615 - acc: 0.6271 - f1_score: 0.\n",
      "37488/37488 [==============================] - 6s 163us/step - loss: 0.6647 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 153us/step - loss: 0.6643 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 150us/step - loss: 0.6642 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "10752/37488 [=======>......................] - ETA: 3s - loss: 0.6619 - acc: 0.6238 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 155us/step - loss: 0.6644 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 5s 141us/step - loss: 0.6642 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 154us/step - loss: 0.6639 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 6s 172us/step - loss: 0.6637 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 28s 760us/step - loss: 0.6903 - acc: 0.3915 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 7s 182us/step - loss: 0.6633 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 0.6662 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 191us/step - loss: 0.6631 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "  768/37489 [..............................] - ETA: 7s - loss: 0.6588 - acc: 0.3685 - f1_score: 0.0000e+00Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 8s 200us/step - loss: 0.6632 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 0.6628 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 7s 196us/step - loss: 0.6632 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 7s 199us/step - loss: 0.6632 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6654 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 7s 196us/step - loss: 0.6632 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 199us/step - loss: 0.6631 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6653 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 7s 194us/step - loss: 0.6629 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6653 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 7s 200us/step - loss: 0.6625 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 1s 128us/steposs: 0.6630 - acc: 0.3784 - f1_score: 0.0000e+\n",
      "37488/37488 [==============================] - 5s 124us/steps: 0.6650 - acc: 0.3\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6650 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 0.6645 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 142us/step - loss: 0.6645 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6639 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      " 7296/37489 [====>.........................] - ETA: 4s - loss: 0.6611 - acc: 0.3772 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 148us/step - loss: 0.6644 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6676 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6643 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 0.6642 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6639 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 174us/step - loss: 0.6636 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 29s 770us/step - loss: 0.7251 - acc: 0.6162 - f1_score: 0.6618 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6642 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6654 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "9372/9372 [==============================] - 1s 110us/steposs: 0.6681 - acc: 0.6133 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 123us/steps: 0.6654 - acc: 0.6168 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 0.6646 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6646 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 162us/step - loss: 0.6648 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      " 7040/37489 [====>.........................] - ETA: 4s - loss: 0.6625 - acc: 0.6224 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6645 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 0.6641 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 0.6643 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 170us/step - loss: 0.6640 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 0.6637 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 30s 805us/step - loss: 0.6665 - acc: 0.6173 - f1_score: 0.6659 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6631 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 8s 201us/step - loss: 0.6656 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 8s 201us/step - loss: 0.6637 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6634 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6635 - val_acc: 0.6220 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 8s 202us/step - loss: 0.6633 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6641 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6635 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 200us/step - loss: 0.6632 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6632 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 0.6633 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6644 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 8s 204us/step - loss: 0.6630 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 8s 202us/step - loss: 0.6645 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6629 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6647 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "9372/9372 [==============================] - 1s 150us/steposs: 0.6629 - acc: 0.6229 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 124us/steps: 0.6650 - acc: 0.6177 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 0.6642 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 0.6645 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "34560/37489 [==========================>...] - ETA: 0s - loss: 0.6642 - acc: 0.6182 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6641 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6644 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6638 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6642 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 0.6640 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6636 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 29s 786us/step - loss: 0.6676 - acc: 0.3840 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6637 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6653 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6638 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 126us/steposs: 0.6641 - acc: 0.3795 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 5s 121us/steps: 0.6661 - acc: 0.3838 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6648 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 0.6647 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 157us/step - loss: 0.6648 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6656 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      " 7936/37489 [=====>........................] - ETA: 3s - loss: 0.6631 - acc: 0.3783 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6646 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 0.6644 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 0.6644 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6642 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6640 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6662 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 30s 788us/step - loss: 9.9424 - acc: 0.3821 - f1_score: 0.3821 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 0.6643 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 8s 201us/step - loss: 0.6641 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 7s 200us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 195us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 0.6639 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3787 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6633 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6635 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 195us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 0.6636 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 193us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6632 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 190us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6633 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6610 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 195us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6631 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 143us/steposs: 9.9189 - acc: 0.3846 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 121us/steps: 9.9716 - acc: 0.3813 - f1_score\n",
      "37488/37488 [==============================] - 7s 185us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 6s 154us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 147us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 6s 152us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      " 3200/37488 [=>............................] - ETA: 4s - loss: 9.8774 - acc: 0.3872 - f1_score: 0.3872Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 147us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 153us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 5s 145us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 177us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 29s 768us/step - loss: 9.9229 - acc: 0.6168 - f1_score: 0.6094 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 7s 173us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 193us/step - loss: 9.9745 - acc: 0.3812 - f1_score: 0.3812 - val_loss: 10.0603 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9373/9373 [==============================] - 1s 125us/steposs: 9.9383 - acc: 0.6166 - f1_score: 0.61\n",
      "37488/37488 [==============================] - 5s 123us/steps: 9.9470 - acc: 0.6171 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 7/20\n",
      " 5120/37489 [===>..........................] - ETA: 4s - loss: 9.7747 - acc: 0.6064 - f1_score: 0.6049Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 30s 797us/step - loss: 1.4230 - acc: 0.6169 - f1_score: 0.6563 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6656 - acc: 0.6176 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6654 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6653 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 187us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      " 1792/37489 [>.............................] - ETA: 6s - loss: 9.7950 - acc: 0.6077 - f1_score: 0.6070Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6653 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 9.9536 - acc: 0.6175 - f1_score: 0.6157 - val_loss: 10.0603 - val_acc: 0.6242 - val_f1_score: 0.6220\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6652 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6633 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "9372/9372 [==============================] - 1s 130us/steposs: 0.6654 - acc: 0.6180 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 124us/steps: 0.6654 - acc: 0.6181 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 181us/step - loss: 0.6654 - acc: 0.6109 - f1_score: 0.6439 - val_loss: 0.6627 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 1.0506e-04 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 147us/step - loss: 0.6653 - acc: 0.3818 - f1_score: 3.1517e-04 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "36992/37489 [============================>.] - ETA: 0s - loss: 0.6651 - acc: 0.5945 - f1_score: 0.5962Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6652 - acc: 0.5945 - f1_score: 0.5971 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 145us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6652 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6651 - acc: 0.4160 - f1_score: 0.0938 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 29s 775us/step - loss: 0.7614 - acc: 0.6157 - f1_score: 0.6593 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 178us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 0.6655 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 127us/steposs: 0.6662 - acc: 0.6164 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 124us/steps: 0.6650 - acc: 0.6191 - \n",
      "37489/37489 [==============================] - 7s 188us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6629 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      " 7296/37489 [====>.........................] - ETA: 3s - loss: 0.6628 - acc: 0.6235 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 148us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 0.6651 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 6s 169us/step - loss: 0.6652 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 182us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 30s 795us/step - loss: 6.1777 - acc: 0.3834 - f1_score: 0.3813 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6650 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6649 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 189us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6640 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 0.6648 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6647 - acc: 0.6185 - f1_score: 0.6666 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6646 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6649 - acc: 0.5741 - f1_score: 0.5520 - val_loss: 0.6623 - val_acc: 0.3776 - val_f1_score: 0.0064\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 11/20\n",
      "9372/9372 [==============================] - 1s 123us/steposs: 6.3206 - acc: 0.3921 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 122us/steps: 6.1788 - acc: 0.3833 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 7s 184us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 14/20\n",
      "36224/37489 [===========================>..] - ETA: 0s - loss: 6.1747 - acc: 0.3831 - f1_score: 0.3831Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 5s 146us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 148us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 183us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 30s 787us/step - loss: 0.6799 - acc: 0.6145 - f1_score: 0.6658 - val_loss: 0.6639 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 199us/step - loss: 0.6654 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6622 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 6.1667 - acc: 0.3826 - f1_score: 0.3826 - val_loss: 6.0578 - val_acc: 0.3758 - val_f1_score: 0.3758\n",
      "9372/9372 [==============================] - 1s 117us/steposs: 0.6669 - acc: 0.6145 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 7s 189us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 5s 125us/steps: 0.7041 - acc: 0.5391 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 6s 158us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 155us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 6s 154us/step - loss: 0.6645 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      " 4608/37488 [==>...........................] - ETA: 4s - loss: 0.6649 - acc: 0.6176 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 157us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 6s 150us/step - loss: 0.6646 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 6s 153us/step - loss: 0.6645 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 7s 174us/step - loss: 0.6642 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 7s 178us/step - loss: 0.6644 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 30s 808us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 7s 196us/step - loss: 0.6643 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6170 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 7s 198us/step - loss: 0.6644 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6627 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 7s 195us/step - loss: 0.6641 - acc: 0.6186 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 7s 198us/step - loss: 0.6639 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 7s 199us/step - loss: 0.6637 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 7s 200us/step - loss: 0.6645 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 7s 193us/step - loss: 0.6640 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 197us/step - loss: 0.6639 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 7s 195us/step - loss: 0.6635 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 1s 120us/steposs: 6.4244 - acc: 0.6011 - f1_score: 0.\n",
      "37488/37488 [==============================] - 5s 126us/steps: 6.1607 - acc: 0.6180 - f1_score: 0.\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6170 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 14/20\n",
      "37376/37489 [============================>.] - ETA: 0s - loss: 6.1668 - acc: 0.6176 - f1_score: 0.6170Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 29s 784us/step - loss: 0.6682 - acc: 0.3830 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 176us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 6.1675 - acc: 0.6175 - f1_score: 0.6169 - val_loss: 6.0671 - val_acc: 0.6242 - val_f1_score: 0.6236\n",
      "9372/9372 [==============================] - 1s 113us/steposs: 0.6647 - acc: 0.3803 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 5s 122us/steps: 0.6655 - acc: 0.3818 - f1_score: 0.00\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6655 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6638 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 0.6652 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4992/37489 [==>...........................] - ETA: 4s - loss: 0.6643 - acc: 0.3812 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 0.6653 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 173us/step - loss: 0.6647 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6649 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 30s 797us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6644 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5679 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6644 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5679 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6645 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 7s 191us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6642 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6686 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5681 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 196us/step - loss: 0.6648 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6645 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 0.6645 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 0.6649 - acc: 0.3818 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 7s 192us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 0.6643 - acc: 0.3815 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 122us/steposs: 7.0980 - acc: 0.6124 - f1_score: 0.\n",
      "37489/37489 [==============================] - 5s 125us/steps: 7.0490 - acc: 0.6187 - f1_score: 0.56\n",
      "37489/37489 [==============================] - 7s 186us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5679 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 6s 149us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 5s 147us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 147us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 15/20\n",
      " 5120/37489 [===>..........................] - ETA: 4s - loss: 7.1241 - acc: 0.6174 - f1_score: 0.5639Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 150us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5679 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 168us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5680 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5679 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 29s 784us/step - loss: 0.6676 - acc: 0.3842 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 7.0455 - acc: 0.6186 - f1_score: 0.5681 - val_loss: 6.9617 - val_acc: 0.6242 - val_f1_score: 0.5690\n",
      "37489/37489 [==============================] - 7s 200us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "9372/9372 [==============================] - 1s 128us/steposs: 0.6728 - acc: 0.3966 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 5s 124us/steps: 0.6658 - acc: 0.3828 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 7s 179us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 153us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 151us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37120/37489 [============================>.] - ETA: 0s - loss: 0.6658 - acc: 0.3826 - f1_score: 0.0000e+00Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 157us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 148us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 0.6657 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 30s 803us/step - loss: 0.7045 - acc: 0.6173 - f1_score: 0.6629 - val_loss: 0.6625 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 6s 172us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 7s 191us/step - loss: 0.6653 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 7s 191us/step - loss: 0.6647 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6615 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 0.6645 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6656 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37488/37488 [==============================] - 7s 191us/step - loss: 0.6642 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 7s 198us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 7s 192us/step - loss: 0.6637 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6671 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 7s 195us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 7s 191us/step - loss: 0.6637 - acc: 0.6192 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6251 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 8s 201us/step - loss: 0.6654 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 7s 197us/step - loss: 0.6633 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6648 - val_acc: 0.6205 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 7s 194us/step - loss: 0.6631 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6228 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6653 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 7s 196us/step - loss: 0.6629 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6655 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 129us/steposs: 0.6612 - acc: 0.6223 - f1_score: 0.\n",
      "37488/37488 [==============================] - 7s 188us/step - loss: 0.6629 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6220 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 125us/steps: 0.6628 - acc: 0.6205 - f1_score: 0.66\n",
      "37488/37488 [==============================] - 6s 154us/step - loss: 0.6626 - acc: 0.6196 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 6s 148us/step - loss: 0.6623 - acc: 0.6195 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6245 - val_f1_score: 0.6668\n",
      "Epoch 14/20\n",
      "37488/37488 [==============================] - 6s 152us/step - loss: 0.6624 - acc: 0.6193 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6238 - val_f1_score: 0.6668\n",
      "Epoch 15/20\n",
      "12672/37488 [=========>....................] - ETA: 3s - loss: 0.6601 - acc: 0.6246 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 147us/step - loss: 0.6621 - acc: 0.6201 - f1_score: 0.6667 - val_loss: 0.6604 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37488/37488 [==============================] - 6s 152us/step - loss: 0.6623 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6634 - val_acc: 0.6222 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37488/37488 [==============================] - 6s 149us/step - loss: 0.6619 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6224 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37488/37488 [==============================] - 8s 201us/step - loss: 0.6618 - acc: 0.6199 - f1_score: 0.6667 - val_loss: 0.6643 - val_acc: 0.6209 - val_f1_score: 0.6666\n",
      "Epoch 19/20\n",
      "37488/37488 [==============================] - 8s 209us/step - loss: 0.6618 - acc: 0.6197 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6234 - val_f1_score: 0.6666\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 32s 852us/step - loss: 0.6673 - acc: 0.3837 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 8s 210us/step - loss: 0.6616 - acc: 0.6191 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 1s 143us/steposs: 0.6657 - acc: 0.3825 - f1_sco\n",
      "37489/37489 [==============================] - 8s 213us/step - loss: 0.6657 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 5s 134us/steps: 0.6643 - acc: 0.3806 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6653 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 0.6649 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 158us/step - loss: 0.6646 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "32384/37489 [========================>.....] - ETA: 0s - loss: 0.6641 - acc: 0.3810 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6646 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 0.6641 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 158us/step - loss: 0.6640 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3787 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 6s 163us/step - loss: 0.6638 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 8s 203us/step - loss: 0.6635 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3789 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 31s 835us/step - loss: 7.9913 - acc: 0.3818 - f1_score: 0.3784 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 9s 247us/step - loss: 0.6629 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 10s 256us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 8s 227us/step - loss: 0.6631 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 8s 214us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 8s 224us/step - loss: 0.6630 - acc: 0.3820 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 8s 222us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 8s 217us/step - loss: 0.6627 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 8s 213us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 8s 213us/step - loss: 0.6627 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6612 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 8s 208us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 8s 213us/step - loss: 0.6624 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6672 - val_acc: 0.3795 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 8s 208us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 8s 212us/step - loss: 0.6622 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 8s 207us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 8s 213us/step - loss: 0.6623 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6609 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 8s 212us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 8s 211us/step - loss: 0.6622 - acc: 0.3819 - f1_score: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.3772 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 8s 208us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 8s 214us/step - loss: 0.6620 - acc: 0.3817 - f1_score: 0.0000e+00 - val_loss: 0.6751 - val_acc: 0.3828 - val_f1_score: 0.0000e+00\n",
      "9372/9372 [==============================] - 1s 144us/steposs: 7.9737 - acc: 0.3830 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 8s 208us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 5s 135us/steps: 8.0600 - acc: 0.3852 - f1_score: 0.38\n",
      "37489/37489 [==============================] - 7s 175us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 152us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 15/20\n",
      "24192/37489 [==================>...........] - ETA: 1s - loss: 7.9351 - acc: 0.3786 - f1_score: 0.3785Train on 37489 samples, validate on 5207 samples\n",
      "24576/37489 [==================>...........] - ETA: 1s - loss: 7.9351 - acc: 0.3785 - f1_score: 0.3784Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 154us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 8s 209us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 31s 828us/step - loss: 0.6668 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 7.9660 - acc: 0.3818 - f1_score: 0.3817 - val_loss: 7.9770 - val_acc: 0.3758 - val_f1_score: 0.3759\n",
      "9372/9372 [==============================] - 1s 128us/steposs: 0.6644 - acc: 0.3804 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 8s 211us/step - loss: 0.6648 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 5s 136us/steps: 0.6657 - acc: 0.3831 - f1_score: 0.0000\n",
      "37489/37489 [==============================] - 7s 193us/step - loss: 0.6647 - acc: 0.3814 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3756 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 6s 158us/step - loss: 0.6645 - acc: 0.3813 - f1_score: 0.0000e+00 - val_loss: 0.6614 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 6s 164us/step - loss: 0.6640 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6611 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "13184/37489 [=========>....................] - ETA: 3s - loss: 0.6647 - acc: 0.3836 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6636 - acc: 0.3811 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489/37489 [==============================] - 6s 155us/step - loss: 0.6636 - acc: 0.3816 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 0.6629 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 7s 177us/step - loss: 0.6629 - acc: 0.3810 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3766 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 7s 199us/step - loss: 0.6628 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 31s 835us/step - loss: 0.9301 - acc: 0.6108 - f1_score: 0.6443 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 8s 210us/step - loss: 0.6626 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6692 - val_acc: 0.3826 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 8s 211us/step - loss: 0.6657 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37489/37489 [==============================] - 8s 211us/step - loss: 0.6625 - acc: 0.3806 - f1_score: 0.0000e+00 - val_loss: 0.6697 - val_acc: 0.3808 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 8s 212us/step - loss: 0.6656 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37489/37489 [==============================] - 8s 211us/step - loss: 0.6621 - acc: 0.3801 - f1_score: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.3764 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 8s 210us/step - loss: 0.6653 - acc: 0.6174 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37489/37489 [==============================] - 8s 212us/step - loss: 0.6621 - acc: 0.3807 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3780 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 8s 213us/step - loss: 0.6650 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      "37489/37489 [==============================] - 8s 214us/step - loss: 0.6616 - acc: 0.3803 - f1_score: 0.0000e+00 - val_loss: 0.6613 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 8s 213us/step - loss: 0.6648 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6608 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37489/37489 [==============================] - 8s 217us/step - loss: 0.6619 - acc: 0.3799 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 8s 213us/step - loss: 0.6645 - acc: 0.6172 - f1_score: 0.6667 - val_loss: 0.6614 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n",
      "37489/37489 [==============================] - 8s 215us/step - loss: 0.6616 - acc: 0.3797 - f1_score: 0.0000e+00 - val_loss: 0.6656 - val_acc: 0.3816 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 8s 211us/step - loss: 0.6644 - acc: 0.6175 - f1_score: 0.6667 - val_loss: 0.6612 - val_acc: 0.6232 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37489/37489 [==============================] - 8s 212us/step - loss: 0.6616 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 8s 214us/step - loss: 0.6640 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6610 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 8s 216us/step - loss: 0.6613 - acc: 0.3805 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3783 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 8s 209us/step - loss: 0.6639 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 8s 216us/step - loss: 0.6613 - acc: 0.3801 - f1_score: 0.0000e+00 - val_loss: 0.6622 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "37489/37489 [==============================] - 8s 215us/step - loss: 0.6640 - acc: 0.6178 - f1_score: 0.6667 - val_loss: 0.6602 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "9372/9372 [==============================] - 1s 139us/steposs: 0.6581 - acc: 0.6281 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 143us/steps: 0.6639 - acc: 0.6167 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 7s 194us/step - loss: 0.6636 - acc: 0.6177 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6636 - acc: 0.6182 - f1_score: 0.6667 - val_loss: 0.6601 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 156us/step - loss: 0.6632 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37120/37489 [============================>.] - ETA: 0s - loss: 0.6629 - acc: 0.6182 - f1_score: 0.6667Train on 37488 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 160us/step - loss: 0.6630 - acc: 0.6180 - f1_score: 0.6667 - val_loss: 0.6607 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6628 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 155us/step - loss: 0.6628 - acc: 0.6181 - f1_score: 0.6667 - val_loss: 0.6606 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 160us/step - loss: 0.6628 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6602 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 7s 197us/step - loss: 0.6627 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6605 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37488/37488 [==============================] - 31s 835us/step - loss: 0.6891 - acc: 0.6170 - f1_score: 0.6639 - val_loss: 0.6630 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 2/20\n",
      "37489/37489 [==============================] - 7s 190us/step - loss: 0.6630 - acc: 0.6183 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6226 - val_f1_score: 0.6667\n",
      "9372/9372 [==============================] - 1s 136us/steposs: 0.6657 - acc: 0.6176 - f1_score: 0.66\n",
      "37489/37489 [==============================] - 5s 141us/steps: 0.6649 - acc: 0.6\n",
      "37488/37488 [==============================] - 8s 216us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 6s 164us/step - loss: 0.6649 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6621 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 6s 162us/step - loss: 0.6646 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6623 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 6s 166us/step - loss: 0.6645 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6626 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 6/20\n",
      " 4608/37488 [==>...........................] - ETA: 4s - loss: 0.6587 - acc: 0.6311 - f1_score: 0.6667Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37488/37488 [==============================] - 6s 164us/step - loss: 0.6643 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 6s 162us/step - loss: 0.6640 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37488/37488 [==============================] - 6s 164us/step - loss: 0.6643 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 7s 193us/step - loss: 0.6639 - acc: 0.6190 - f1_score: 0.6667 - val_loss: 0.6619 - val_acc: 0.6244 - val_f1_score: 0.6667\n",
      "Epoch 10/20\n",
      "37489/37489 [==============================] - 32s 843us/step - loss: 0.6729 - acc: 0.3877 - f1_score: 0.0000e+00 - val_loss: 0.6617 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/20\n",
      "37488/37488 [==============================] - 7s 195us/step - loss: 0.6641 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6245 - val_f1_score: 0.6667\n",
      "Epoch 11/20\n",
      "37489/37489 [==============================] - 8s 216us/step - loss: 0.6656 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/20\n",
      "37488/37488 [==============================] - 8s 218us/step - loss: 0.6641 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6620 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 12/20\n",
      "37489/37489 [==============================] - 8s 213us/step - loss: 0.6655 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6638 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/20\n",
      "37488/37488 [==============================] - 8s 220us/step - loss: 0.6638 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6611 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 13/20\n",
      "37489/37489 [==============================] - 8s 217us/step - loss: 0.6653 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/20\n",
      "37488/37488 [==============================] - 8s 218us/step - loss: 0.6636 - acc: 0.6184 - f1_score: 0.6667 - val_loss: 0.6618 - val_acc: 0.6242 - val_f1_score: 0.6667\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 8s 214us/step - loss: 0.6652 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/20\n",
      "37488/37488 [==============================] - 8s 218us/step - loss: 0.6636 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6613 - val_acc: 0.6236 - val_f1_score: 0.6667\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 8s 210us/step - loss: 0.6646 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/20\n",
      "37488/37488 [==============================] - 8s 220us/step - loss: 0.6636 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6636 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 16/20\n",
      "37489/37489 [==============================] - 8s 218us/step - loss: 0.6648 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/20\n",
      "37488/37488 [==============================] - 8s 220us/step - loss: 0.6636 - acc: 0.6187 - f1_score: 0.6667 - val_loss: 0.6617 - val_acc: 0.6240 - val_f1_score: 0.6667\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 8s 216us/step - loss: 0.6644 - acc: 0.3824 - f1_score: 0.0000e+00 - val_loss: 0.6637 - val_acc: 0.3758 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/20\n",
      "37488/37488 [==============================] - 8s 217us/step - loss: 0.6633 - acc: 0.6188 - f1_score: 0.6667 - val_loss: 0.6624 - val_acc: 0.6238 - val_f1_score: 0.6667\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 8s 214us/step - loss: 0.6647 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3760 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/20\n",
      "37488/37488 [==============================] - 8s 216us/step - loss: 0.6632 - acc: 0.6185 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6234 - val_f1_score: 0.6667\n",
      "Epoch 19/20\n",
      "37489/37489 [==============================] - 8s 215us/step - loss: 0.6644 - acc: 0.3823 - f1_score: 0.0000e+00 - val_loss: 0.6623 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/20\n",
      "37488/37488 [==============================] - 8s 222us/step - loss: 0.6629 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6609 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "Epoch 20/20\n",
      "37489/37489 [==============================] - 8s 212us/step - loss: 0.6641 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.3778 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/20\n",
      "37488/37488 [==============================] - 8s 217us/step - loss: 0.6636 - acc: 0.6189 - f1_score: 0.6667 - val_loss: 0.6616 - val_acc: 0.6230 - val_f1_score: 0.6667\n",
      "9373/9373 [==============================] - 1s 143us/steposs: 0.6660 - acc: 0.3872 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 8s 209us/step - loss: 0.6641 - acc: 0.3831 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3776 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/20\n",
      "37488/37488 [==============================] - 5s 139us/steps: 0.6710 - acc: 0.3967 - f1_score: 0.0000e+\n",
      "37489/37489 [==============================] - 6s 171us/step - loss: 0.6645 - acc: 0.3826 - f1_score: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/20\n",
      "37489/37489 [==============================] - 6s 159us/step - loss: 0.6636 - acc: 0.3821 - f1_score: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.3768 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 0.6636 - acc: 0.3825 - f1_score: 0.0000e+00 - val_loss: 0.6621 - val_acc: 0.3770 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/20\n",
      " 9216/37489 [======>.......................] - ETA: 4s - loss: 0.6651 - acc: 0.3853 - f1_score: 0.0000e+00Train on 37489 samples, validate on 5207 samples\n",
      "Epoch 1/20\n",
      "37489/37489 [==============================] - 6s 165us/step - loss: 0.6634 - acc: 0.3828 - f1_score: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/20\n",
      "37489/37489 [==============================] - 6s 161us/step - loss: 0.6637 - acc: 0.3822 - f1_score: 0.0000e+00 - val_loss: 0.6616 - val_acc: 0.3774 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/20\n",
      "37489/37489 [==============================] - 6s 158us/step - loss: 0.6632 - acc: 0.3827 - f1_score: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.3762 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/20\n",
      "13312/37489 [=========>....................] - ETA: 42s - loss: 0.9394 - acc: 0.4251 - f1_score: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "Machine = \"slave05\"\n",
    "# If Machine is \"test\" then, _TEST argument must be True\n",
    "test = False\n",
    "_GPU=True\n",
    "Internet_connection=True\n",
    "n_jobs=-1\n",
    "epochs=20\n",
    "\n",
    "for model in model_info[Machine][\"MODEL_list\"]:\n",
    "    for idx_time_unit in model_info[Machine][\"time_unit\"]:\n",
    "        for idx_window_size in model_info[Machine][\"window_size\"]:\n",
    "            for idx_gap in model_info[Machine][\"gap\"]:\n",
    "                for idx_margin_rate in model_info[Machine][\"margin_rate\"]:\n",
    "                    start(machine=Machine, \n",
    "                         Internet_connection=Internet_connection, \n",
    "                         _TEST=test, \n",
    "                         _GPU=_GPU, \n",
    "                         n_jobs=n_jobs,\n",
    "                         MODEL = model, \n",
    "                         idx_time_unit=idx_time_unit, \n",
    "                         idx_window_size=idx_window_size, \n",
    "                         idx_gap=idx_gap, \n",
    "                         idx_margin_rate=idx_margin_rate,\n",
    "                         epochs=epochs)\n",
    "                Javascript('IPython.notebook.kernel.restart()')\n",
    "                time.sleep(1)\n",
    "                Javascript('IPython.notebook.execute_all_cells()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperio test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "# import keras\n",
    "# from keras.datasets import mnist\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten\n",
    "# from keras.layers import Conv2D, MaxPooling2D\n",
    "# from keras import backend as K\n",
    "\n",
    "# def create_model_SimpleRNN_non_GPU_test(x_train, y_train, x_val, y_val, params):\n",
    "#     model = Sequential()\n",
    "#     model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "#         SimpleRNN(\n",
    "# #             n_state_units, \n",
    "#                   params['first_neuron'],\n",
    "#                   input_dim=x_train.shape[2], # [dataset 크기, 윈도우 사이즈, 32(코인개수*OLHC)]\n",
    "# #                   input_shape=(window_size, 32),\n",
    "# #                   use_bias=True, \n",
    "#                   #activation='relu'\n",
    "#         ))\n",
    "# #                   kernel_initializer='glorot_uniform', \n",
    "# #                   recurrent_initializer='orthogonal', \n",
    "# #                   bias_initializer='zeros', \n",
    "# #                   dropout=0.0,\n",
    "# #                   recurrent_dropout=0.0))\n",
    "    \n",
    "# #     model.add(Dense(units=neurons))\n",
    "# #     model.add(Dropout(dropout_rate))\n",
    "        \n",
    "#     model.add(Dropout(params['dropout']))\n",
    "#     model.add(Dense(y_train.shape[1],\n",
    "#                     activation=params['last_activation']))\n",
    "        \n",
    "# #     model.add(Dense(units=2))\n",
    "# #     model = multi_gpu_model(model, gpus=2)\n",
    "# #     model.compile(optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], params['optimizer'])),\n",
    "# #                   loss=params['loss'],\n",
    "# #                   metrics=['acc'])\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "#     model.compile(optimizer=params['optimizer'](),\n",
    "#                   loss=params['loss'],\n",
    "#                   metrics=['acc', f1_score])\n",
    "    \n",
    "#     out = model.fit(x_train, y_train,\n",
    "#                     batch_size=params['batch_size'],\n",
    "#                     epochs=params['epochs'],\n",
    "#                     verbose=1,\n",
    "#                     validation_data=[x_val, y_val])\n",
    "# #                     callbacks=early_stopper(params['epochs'], mode='strict'))\n",
    "    \n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from keras.optimizers import Adam, Nadam\n",
    "# from keras.activations import softmax\n",
    "# from keras.losses import categorical_crossentropy, logcosh\n",
    "\n",
    "# pickle_load_dir_path = \"./dataset_pickle_tuple_type/\"\n",
    "# X = {}\n",
    "# y = {}\n",
    "\n",
    "\n",
    "# MODEL = [\"SimpleRNN\"]\n",
    "# idx_time_unit = 10     # candle stick minutes\n",
    "# idx_window_size = 25  # Unit: num. of candle sticks\n",
    "# idx_gap = 1            # Unit: num. of candle sticks\n",
    "# idx_margix_rate = 0.1  # Unit: percent\n",
    "\n",
    "# key_name_X = \"X_\"\n",
    "# key_name_y = \"y_\"\n",
    "\n",
    "\n",
    "# key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "# key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margix_rate)\n",
    "\n",
    "# X = Load_Dataset_X(pickle_load_dir_path, idx_time_unit, idx_window_size, idx_gap, idx_margix_rate)\n",
    "# y = Load_Dataset_y(pickle_load_dir_path, idx_time_unit, idx_window_size, idx_gap, idx_margix_rate)\n",
    "\n",
    "# y_single = {}\n",
    "# y_single['BTC'] = y[:, 1]\n",
    "# y_single['ETH'] = y[:, 2]\n",
    "# y_single['XRP'] = y[:, 3]\n",
    "# y_single['BCH'] = y[:, 4]\n",
    "# y_single['LTC'] = y[:, 5]\n",
    "# y_single['DASH'] = y[:, 6]\n",
    "# y_single['ETC'] = y[:, 7]\n",
    "\n",
    "# coin_list2 = [\"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "\n",
    "# y2 = onehottify(y_single['BTC'], n=2) \n",
    "# #                         for coin in coin_list2:\n",
    "# #                             print(\"y_single[\"+coin+\"]\"+\".shape\")\n",
    "# #                             print(y_single[coin].shape)\n",
    "# #                             print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.1, random_state=42)\n",
    "# #     print(\"X_train.shape\")\n",
    "# #     print(X_train.shape)\n",
    "# #     print(\"y_train.shape\")\n",
    "# #     print(y_train.shape)\n",
    "# #     print()\n",
    "# #     print(\"X_test.shape\")\n",
    "# #     print(X_test.shape)\n",
    "# #     print(\"y_test.shape\")\n",
    "# #     print(y_test.shape)\n",
    "# #     print()\n",
    "\n",
    "# n_coins = 8\n",
    "# n_price = 4\n",
    "# n_steps = idx_window_size # 원래 100이었음. reshape 문제 때문에 수정함\n",
    "\n",
    "# X_train_2 = X_train.transpose([0, 2, 1, 3])\n",
    "# X_test_2 = X_test.transpose([0, 2, 1, 3])\n",
    "# #     print(\"X_train_2.shape\")\n",
    "# #     print(X_train_2.shape)\n",
    "# #     print(\"X_test_2.shape\")\n",
    "# #     print(X_test_2.shape)\n",
    "# #     print()\n",
    "\n",
    "# X_train_3 = X_train_2.reshape([X_train.shape[0], n_steps, n_coins * n_price])\n",
    "# X_test_3 = X_test_2.reshape([X_test.shape[0], n_steps, n_coins * n_price])\n",
    "# #     print(\"X_train_3.shape\")\n",
    "# #     print(X_train_3.shape)\n",
    "# #     print(\"X_test_3.shape\")\n",
    "# #     print(X_test_3.shape)\n",
    "# #     print()\n",
    "\n",
    "# X_train_reshape = X_train_2.reshape([X_train.shape[0], n_steps*n_coins * n_price])\n",
    "# X_test_reshape = X_test_2.reshape([X_test.shape[0], n_steps*n_coins * n_price])\n",
    "# #     print(\"X_train_reshape.shape\")\n",
    "# #     print(X_train_reshape.shape)\n",
    "# #     print(\"X_test_reshape.shape\")\n",
    "# #     print(X_test_reshape.shape)\n",
    "# #     print()\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(X_train_reshape)\n",
    "# X_train_scaled = scaler.transform(X_train_reshape)\n",
    "# X_test_scaled = scaler.transform(X_test_reshape)\n",
    "\n",
    "# X_train_scaled = X_train_scaled.reshape(-1, n_steps, n_coins * n_price)\n",
    "\n",
    "# X_test_scaled = X_test_scaled.reshape(-1, n_steps, n_coins * n_price)\n",
    "\n",
    "# X_train_scaled, X_test_scaled = input_reshape(X_train_scaled, X_test_scaled, n_steps, n_coins, n_price)\n",
    "\n",
    "                        \n",
    "# p = {'lr': (0.1, 0.01, 0.001),\n",
    "#      'first_neuron':[4, 8, 16, 32, 64, 128],\n",
    "#      'batch_size': [64,128,256],\n",
    "#      'epochs': [100],\n",
    "#      'activation':['relu', 'softmax'],\n",
    "#      'dropout': (0, 0.40, 10),\n",
    "#      'optimizer': [Adam, Nadam],\n",
    "#      'kernel_initializer':['glorot_uniform', 'uniform', 'he_uniform'],\n",
    "#      'recurrent_initializer':['orthogonal'], \n",
    "#      'bias_initializer':['zeros'],\n",
    "#      'loss': ['categorical_crossentropy', 'logcosh'],\n",
    "#      'last_activation': ['softmax'],\n",
    "#      'weight_regulizer':[None],\n",
    "#      'emb_output_dims': [None]}\n",
    "\n",
    "# import hyperio as hy\n",
    "# h = hy.Hyperio(X_train_scaled, y_train, \n",
    "#                params=p, \n",
    "#                dataset_name='coin', \n",
    "#                experiment_no='1', \n",
    "#                model=create_model_SimpleRNN_non_GPU_test,\n",
    "#                # create_model_SimpleRNN_non_GPU_test(x_train, y_train, x_val, y_val, params)\n",
    "#                grid_downsample=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# h.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './paramter/10_10_1_0.1/SimpleRNN_BCH_10_10_1_0.1_result.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-132274e28995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load pickle file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./paramter/10_10_1_0.1/SimpleRNN_BCH_10_10_1_0.1_result.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mb_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './paramter/10_10_1_0.1/SimpleRNN_BCH_10_10_1_0.1_result.pickle'"
     ]
    }
   ],
   "source": [
    "# load pickle file \n",
    "import pickle\n",
    "b_x = pickle.load(open(\"./paramter/10_10_1_0.1/SimpleRNN_BCH_10_10_1_0.1_result.pickle\", \"rb\"))\n",
    "b_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
