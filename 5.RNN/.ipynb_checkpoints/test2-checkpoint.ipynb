{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dohyung/SourceTree/dohyung/5.RNN\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Disbursed'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version: 2.2.2 backend: tensorflow\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import metrics\n",
    "from keras import losses\n",
    "from keras import __version__\n",
    "print('Using Keras version:', __version__, 'backend:', K.backend())\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report # https://stackoverflow.com/questions/50065484/getting-precision-recall-and-f1-score-per-class-in-keras\n",
    "\n",
    "from IPython.display import Javascript\n",
    "import numpy as np\n",
    "from distutils.version import LooseVersion as LV\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pprint\n",
    "import boto3\n",
    "import pickle\n",
    "import time\n",
    "import os.path\n",
    "import pickle\n",
    "sys.path.append(os.getcwd())\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText # simple MSG\n",
    "from email.mime.multipart import MIMEMultipart # complex MSG\n",
    "        \n",
    "from link_aws_key import *\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "coins = {\n",
    "    0: 'KRW',\n",
    "    1: 'BTC',\n",
    "    2: 'ETH',\n",
    "    3: 'XRP',\n",
    "    4: 'BCH',\n",
    "    5: 'LTC',\n",
    "    6: 'DASH',\n",
    "    7: 'ETC'\n",
    "}\n",
    "\n",
    "# aws_client = boto3.client(\n",
    "#     's3',\n",
    "#     aws_access_key_id=LINK_AWSAccessKeyId,\n",
    "#     aws_secret_access_key=LINK_AWSSecretKey\n",
    "# )\n",
    "\n",
    "bucket = \"bithumb10\"\n",
    "cleanup_file_name = \"coin_{0}_{1}_cleanup.csv\"\n",
    "\n",
    "\n",
    "#######################################################\n",
    "\n",
    "def Load_Dataset_X(dir_path, time_unit, window_size, gap, margin_rate):\n",
    "    key_name_X = \"X_\" + \\\n",
    "                    str(time_unit) + \"_\" + \\\n",
    "                    str(window_size) + \"_\" + \\\n",
    "                    str(gap) + \"_\" + \\\n",
    "                    str(margin_rate)\n",
    "                    \n",
    "\n",
    "    with open(dir_path + key_name_X + \".pickle\", 'rb') as handle:\n",
    "        b_x = pickle.load(handle)\n",
    "    return b_x\n",
    "\n",
    "def Load_Dataset_y(dir_path, time_unit, window_size, gap, margin_rate):\n",
    "    key_name_y = \"y_\" + \\\n",
    "                    str(time_unit) + \"_\" + \\\n",
    "                    str(window_size) + \"_\" + \\\n",
    "                    str(gap) + \"_\" + \\\n",
    "                    str(margin_rate)\n",
    "                    \n",
    "\n",
    "    with open(dir_path + key_name_y + \".pickle\", 'rb') as handle:\n",
    "        b_y = pickle.load(handle)\n",
    "    return b_y\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def input_reshape(X_train_data, X_test_data, n_steps, n_coins, n_price):\n",
    "    X_train_reshape = X_train_data.reshape(\n",
    "        -1, \n",
    "        n_steps, \n",
    "        n_coins * n_price\n",
    "    )\n",
    "    X_test_reshape = X_test_data.reshape(\n",
    "        -1, \n",
    "        n_steps, \n",
    "        n_coins * n_price\n",
    "    )\n",
    "    return X_train_reshape, X_test_reshape\n",
    "\n",
    "def onehottify(x, n=None, dtype=np.int):\n",
    "    \"\"\"1-hot encode x with the max value n (computed from data if n is None).\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    n = np.max(x) + 1 if n is None else n\n",
    "    return np.eye(n, dtype=dtype)[x]\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def Start_Model(pickle_load_dir_path, \n",
    "                pickle_result_dir_path, \n",
    "                idx_time_unit, \n",
    "                idx_window_size, \n",
    "                idx_gap, \n",
    "                idx_margin_rate, \n",
    "                epochs, \n",
    "                MODEL, \n",
    "                _GPU, \n",
    "                n_jobs,\n",
    "                cv,\n",
    "                dataset_scale,\n",
    "                param_grid,\n",
    "                search_param,\n",
    "                machine):\n",
    "    X = {}\n",
    "    y = {}\n",
    "\n",
    "    key_name_X = \"X_\"\n",
    "    key_name_y = \"y_\"\n",
    "\n",
    "    key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margin_rate)\n",
    "    key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margin_rate)\n",
    "\n",
    "    # remove [:10000], when real training\n",
    "    X = Load_Dataset_X(pickle_load_dir_path, idx_time_unit, idx_window_size, idx_gap, idx_margin_rate)[0][:dataset_scale]\n",
    "    y = Load_Dataset_y(pickle_load_dir_path, idx_time_unit, idx_window_size, idx_gap, idx_margin_rate)[1][:dataset_scale]\n",
    "    \n",
    "    y_single = {}\n",
    "#     print(\"[INFO] y : {}\".format(y))\n",
    "#     y = np.asarray(y[0])\n",
    "#     print(\"[INFO] y.shape : {}\".format(y.shape))\n",
    "#     print(\"[INFO] y : {}\".format(y))\n",
    "    y_single['BTC'] = y[:, 1]\n",
    "    y_single['ETH'] = y[:, 2]\n",
    "    y_single['XRP'] = y[:, 3]\n",
    "    y_single['BCH'] = y[:, 4]\n",
    "    y_single['LTC'] = y[:, 5]\n",
    "    y_single['DASH'] = y[:, 6]\n",
    "    y_single['ETC'] = y[:, 7]\n",
    "\n",
    "    coin_list2 = [\"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "\n",
    "\n",
    "    for coin in coin_list2:\n",
    "        if (os.path.isfile(pickle_result_dir_path + \\\n",
    "                          MODEL + \"_\" + \\\n",
    "                          coin + \"_\" + \\\n",
    "                          str(idx_time_unit) + \"_\" + \\\n",
    "                          str(idx_window_size) + \"_\" + \\\n",
    "                          str(idx_gap) + \"_\" + \\\n",
    "                          str(idx_margin_rate) + \\\n",
    "                          \"_result.pickle\")) is True:\n",
    "            print(MODEL + \"_\" + \\\n",
    "                  coin + \"_\" + \\\n",
    "                  str(idx_time_unit) + \"_\" + \\\n",
    "                  str(idx_window_size) + \"_\" + \\\n",
    "                  str(idx_gap) + \"_\" + \\\n",
    "                  str(idx_margin_rate) + \\\n",
    "                  \"_result.pickle FILE ALREADY EXIST.\")\n",
    "            continue\n",
    "        else:\n",
    "            y2 = onehottify(y_single[coin], n=2)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                                y2, \n",
    "                                                                test_size=0.1, \n",
    "                                                                random_state=42)\n",
    "            print(\"[INFO] X_train.shape : {}\".format(X_train.shape))\n",
    "            print(\"[INFO] y_train.shape : {}\".format(y_train.shape))\n",
    "            print(\"[INFO] X_test.shape : {}\".format(X_test.shape))\n",
    "            print(\"[INFO] y_test.shape : {}\".format(y_test.shape))\n",
    "            print()\n",
    "\n",
    "            n_coins = 8\n",
    "            n_price = 4\n",
    "            n_steps = idx_window_size \n",
    "\n",
    "            X_train_2 = X_train.transpose([0, 2, 1, 3])\n",
    "            X_test_2 = X_test.transpose([0, 2, 1, 3])\n",
    "            print(\"[INFO] X_train_2.shape: {}\".format(X_train_2.shape))\n",
    "            print(\"[INFO] X_test_2.shape: {}\".format(X_test_2.shape))\n",
    "            print()\n",
    "            \n",
    "            X_train_3 = X_train_2.reshape([X_train.shape[0], n_steps, n_coins * n_price])\n",
    "            X_test_3 = X_test_2.reshape([X_test.shape[0], n_steps, n_coins * n_price])\n",
    "            print(\"[INFO] X_train_3.shape: {}\".format(X_train_3.shape))\n",
    "            print(\"[INFO] X_test_3.shape: {}\".format(X_test_3.shape))\n",
    "            print()\n",
    "\n",
    "            X_train_reshape = X_train_2.reshape([X_train.shape[0], n_steps*n_coins * n_price])\n",
    "            X_test_reshape = X_test_2.reshape([X_test.shape[0], n_steps*n_coins * n_price])\n",
    "            print(\"[INFO] X_train_reshape.shape: {}\".format(X_train_reshape.shape))\n",
    "            print(\"[INFO] X_test_reshape.shape: {}\".format(X_test_reshape.shape))\n",
    "            print()\n",
    "            \n",
    "#             param_grid = param_grid\n",
    "            \n",
    "            param_grid = {'max_depth':range(3,10,2),\n",
    "                           'min_child_weight':range(1,6,2),\n",
    "                           'min_child_weight':[6,8,10,12], \n",
    "                           'gamma':[i/10.0 for i in range(0,5)],\n",
    "                           'subsample':[i/10.0 for i in range(6,10)],\n",
    "                           'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "                           'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "                           \n",
    "                        }\n",
    "            \n",
    "            \n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(X_train_reshape)\n",
    "            \n",
    "            X_train_scaled = scaler.transform(X_train_reshape)\n",
    "            X_test_scaled = scaler.transform(X_test_reshape)\n",
    "\n",
    "            X_train_scaled = X_train_scaled.reshape(-1, \n",
    "                                                    n_steps, \n",
    "                                                    n_coins * n_price)\n",
    "            X_test_scaled = X_test_scaled.reshape(-1, \n",
    "                                                  n_steps, \n",
    "                                                  n_coins * n_price)\n",
    "\n",
    "            if _GPU == True:\n",
    "                model = XGBClassifier(learning_rate = 0.1,\n",
    "                                      n_estimators = 140,\n",
    "                                      max_depth = 5,\n",
    "                                      min_child_weight = 1, \n",
    "                                      gamma = 0, \n",
    "                                      subsample = 0.8, \n",
    "                                      colsample_bytree = 0.8, \n",
    "                                      objective = 'binary:logistic', \n",
    "                                      nthread = 4, \n",
    "                                      scale_pos_weight = 1, \n",
    "                                      seed = 27)\n",
    "                \n",
    "            elif _GPU == False:\n",
    "                model = XGBClassifier(learning_rate = 0.1,\n",
    "                                      n_estimators = 140,\n",
    "                                      max_depth = 5,\n",
    "                                      min_child_weight = 1, \n",
    "                                      gamma = 0, \n",
    "                                      subsample = 0.8, \n",
    "                                      colsample_bytree = 0.8, \n",
    "                                      objective = 'binary:logistic', \n",
    "                                      nthread = 4, \n",
    "                                      scale_pos_weight = 1, \n",
    "                                      seed = 27)\n",
    "\n",
    "            grid = GridSearchCV(estimator =  model,\n",
    "                                param_grid = param_grid, \n",
    "                                scoring = 'roc_auc',\n",
    "                                n_jobs = 4,\n",
    "                                iid = False, \n",
    "                                cv=5)\n",
    "\n",
    "            \n",
    "            X_train_scaled, X_test_scaled = input_reshape(X_train_scaled,  \n",
    "                                                          X_test_scaled, \n",
    "                                                          n_steps, \n",
    "                                                          n_coins, \n",
    "                                                          n_price)\n",
    "                      \n",
    "            \n",
    "            print()\n",
    "            print()\n",
    "            print(\"----------------------\")\n",
    "            print(\"<\"+MODEL+\">\")\n",
    "            print(\"----------------------\")\n",
    "            print(\"__\"+coin+\"__\" + \\\n",
    "                    \"time unit: \"+str(idx_time_unit) + \"  |  \" + \\\n",
    "                    \"window_size :\"+str(idx_window_size) + \"  |  \" + \\\n",
    "                    \"gap :\"+str(idx_gap) + \"  |  \" + \\\n",
    "                    \"margin_rate :\"+str(idx_margin_rate) + \\\n",
    "                    \"  started.\")\n",
    "\n",
    "            grid_result = grid.fit(X, \n",
    "                                   y_single['ETC'], \n",
    "                                   eval_metric='auc', \n",
    "                                   verbose=True,\n",
    "                                   eval_set=[(X_test_scaled, y_test)], \n",
    "                                   early_stopping_rounds=100)\n",
    "\n",
    "            print(\"----------------------\")\n",
    "            print(\"grid_result.score(X_test_scaled, y_test): \",grid_result.score(X_test_scaled, y_test))\n",
    "\n",
    "            evaluate_result = {}\n",
    "\n",
    "            test_score = grid_result.score(X_test_scaled, y_test)\n",
    "            evaluate_result[MODEL + \"_\" + \\\n",
    "                          coin + \"_\" + \\\n",
    "                          str(idx_time_unit) + \"_\" + \\\n",
    "                          str(idx_window_size) + \"_\" + \\\n",
    "                          str(idx_gap) + \"_\" + \\\n",
    "                          str(idx_margin_rate)] = {\"MODEL\":MODEL,\\\n",
    "                                            \"Cryptocurrency\":coin, \\\n",
    "                                            \"Score\":grid_result.cv_results_['mean_test_score'], \\\n",
    "                                            \"Params\":grid_result.cv_results_['params'],\\\n",
    "                                            \"test_score\":test_score} \n",
    "        #     print()\n",
    "        #     print(\"evaluate result dict: \", evaluate_result)\n",
    "        #     print()\n",
    "\n",
    "            # summarize results\n",
    "            print()\n",
    "            print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "            print()\n",
    "            # for checking pickle file exist\n",
    "            print(\"---pickle saving..\")\n",
    "            \n",
    "            \n",
    "            X = {}\n",
    "            y = {}\n",
    "            key_name_X = \"X_\"\n",
    "            key_name_y = \"y_\"\n",
    "\n",
    "            key_name_X += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margin_rate)\n",
    "            key_name_y += str(idx_time_unit) + \"_\" + str(idx_window_size) + \"_\" + str(idx_gap) + \"_\" + str(idx_margin_rate)\n",
    "            if (os.path.isfile(pickle_result_dir_path + \\\n",
    "                              MODEL + \"_\" + \\\n",
    "                              coin + \"_\" + \\\n",
    "                              str(idx_time_unit) + \"_\" + \\\n",
    "                              str(idx_window_size) + \"_\" + \\\n",
    "                              str(idx_gap) + \"_\" + \\\n",
    "                              str(idx_margin_rate) + \\\n",
    "                              \"_result.pickle\")) is not True:\n",
    "                with open(pickle_result_dir_path + \\\n",
    "                          MODEL + \"_\" + \\\n",
    "                          coin + \"_\" + \\\n",
    "                          str(idx_time_unit) + \"_\" + \\\n",
    "                          str(idx_window_size) + \"_\" + \\\n",
    "                          str(idx_gap) + \"_\" + \\\n",
    "                          str(idx_margin_rate) + \\\n",
    "                          \"_result.pickle\", 'wb') as handle:\n",
    "                    pickle.dump(evaluate_result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                    \n",
    "            else:\n",
    "                print(\"Already exist the file: \", pickle_result_dir_path + \\\n",
    "                                                  \"_test_\" + \\\n",
    "                                                  MODEL + \"_\" + \\\n",
    "                                                  \"BTC\" + \"_\" + \\\n",
    "                                                  str(idx_time_unit) + \"_\" + \\\n",
    "                                                  str(idx_window_size) + \"_\" + \\\n",
    "                                                  str(idx_gap) + \"_\" + \\\n",
    "                                                  str(idx_margin_rate) + \\\n",
    "                                                  \"_result.pickle\")\n",
    "\n",
    "            \n",
    "        #     for mean, stdev, param in zip(means, stds, params):\n",
    "        #         print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "        #     print()\n",
    "            key_name_X = \"X_\"\n",
    "            key_name_y = \"y_\"\n",
    "\n",
    "\n",
    "            return evaluate_result\n",
    "        \n",
    "def create_model_LSTM(window_size, n_state_units=32, activation='softmax', optimizer='adam', init='glorot_uniform', dropout_rate=0.0, neurons=2):\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        LSTM( n_state_units, \n",
    "              input_shape=(window_size, 32),\n",
    "              use_bias=True, \n",
    "              activation='tanh',\n",
    "              kernel_initializer='glorot_uniform', \n",
    "              recurrent_initializer='orthogonal', \n",
    "              bias_initializer='zeros', \n",
    "              dropout=0.0,\n",
    "              recurrent_dropout=0.0))\n",
    "    \n",
    "    model.add(Dense(units=neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(units=2))\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_LSTM_non_GPU(window_size, \n",
    "                              n_state_units=32, \n",
    "                              activation='softmax', \n",
    "                              optimizer='adam'):\n",
    "    K.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(# if문을 통해 여러 RNN모델 쓸 수 있도록 하기, SimpleRNN외에 다른 RNN모델 찾아보기\n",
    "        LSTM(units=n_state_units, \n",
    "             input_shape=(window_size, 32),\n",
    "             use_bias=True))\n",
    "    \n",
    "    model.add(Dense(units=2))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\", f1_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "def start(machine, \n",
    "          search_param,\n",
    "          _GPU,\n",
    "          n_jobs, \n",
    "          MODEL, \n",
    "          idx_time_unit, \n",
    "          idx_window_size, \n",
    "          idx_gap, \n",
    "          idx_margin_rate, \n",
    "          cv,\n",
    "          dataset_scale,\n",
    "          param_grid,\n",
    "          epochs):\n",
    "    \n",
    "    '''\n",
    "        [ATTENTION] In create_model METHOD part, need to set appropriate about GPU\n",
    "        \n",
    "        LINK01 -> GPU OFF\n",
    "        MSI -> GPU OFF\n",
    "        SLAVE04 -> GPU ON\n",
    "        SLAVE05 -> GPU ON\n",
    "    ''' \n",
    "    \n",
    "\n",
    "    start_time = time.time()\n",
    "    evaluate_result = Start_Model(pickle_load_dir_path = \"../_dataset/RNN_coin/\",  \n",
    "                pickle_result_dir_path = \"./evaluate_result/\", \n",
    "                idx_time_unit=idx_time_unit,\n",
    "                idx_window_size=idx_window_size, \n",
    "                idx_gap=idx_gap, \n",
    "                idx_margin_rate=idx_margin_rate, \n",
    "                epochs=epochs, \n",
    "                MODEL=MODEL, \n",
    "                _GPU=_GPU,\n",
    "                n_jobs=n_jobs,\n",
    "                cv=cv,\n",
    "                dataset_scale=dataset_scale,\n",
    "                param_grid = param_grid,\n",
    "                search_param = search_param,\n",
    "                machine=machine)\n",
    "    print(\"DEBUG\")\n",
    "    end_time = time.time()\n",
    "    print()\n",
    "    print(\"TIME: \", end_time-start_time)\n",
    "    return evaluate_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_train.shape : (90, 8, 10, 4)\n",
      "[INFO] y_train.shape : (90, 2)\n",
      "[INFO] X_test.shape : (10, 8, 10, 4)\n",
      "[INFO] y_test.shape : (10, 2)\n",
      "\n",
      "[INFO] X_train_2.shape: (90, 10, 8, 4)\n",
      "[INFO] X_test_2.shape: (10, 10, 8, 4)\n",
      "\n",
      "[INFO] X_train_3.shape: (90, 10, 32)\n",
      "[INFO] X_test_3.shape: (10, 10, 32)\n",
      "\n",
      "[INFO] X_train_reshape.shape: (90, 320)\n",
      "[INFO] X_test_reshape.shape: (10, 320)\n",
      "\n",
      "\n",
      "\n",
      "----------------------\n",
      "<LSTM>\n",
      "----------------------\n",
      "__BTC__time unit: 10  |  window_size :10  |  gap :1  |  margin_rate :0.1  started.\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10bcc5e40, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10bcc5e40, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/anaconda3/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/anaconda3/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(15, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\n/anaconda3/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(15, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (15, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=15, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 7, 11, 58, 8, 462922, tzinfo=tzutc()), 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'session': '17c94f50c07f41c4acccfe022ae5552d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'17c94f50c07f41c4acccfe022ae5552d']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 7, 11, 58, 8, 462922, tzinfo=tzutc()), 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'session': '17c94f50c07f41c4acccfe022ae5552d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'17c94f50c07f41c4acccfe022ae5552d'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 7, 11, 58, 8, 462922, tzinfo=tzutc()), 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'session': '17c94f50c07f41c4acccfe022ae5552d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-27-0c6c262ca28b>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a155d65c0, execution...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a24ab9ed0, file \"<ipython-input-27-0c6c262ca28b>\", line 28>\n        result = <ExecutionResult object at 1a155d65c0, execution...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a24ab9ed0, file \"<ipython-input-27-0c6c262ca28b>\", line 28>, result=<ExecutionResult object at 1a155d65c0, execution...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a24ab9ed0, file \"<ipython-input-27-0c6c262ca28b>\", line 28>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GRU': <class 'keras.layers.recurrent.GRU'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"get_ipython().system(' pwd')\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu...mport rcParams\\nrcParams['figure.figsize'] = 12, 4\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", \"#Import libraries:\\nimport pandas as pd\\nimport nu...mport rcParams\\nrcParams['figure.figsize'] = 12, 4\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis...ormat(coin))\\n                            continue', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', ...], 'Javascript': <class 'IPython.core.display.Javascript'>, 'K': <module 'keras.backend' from '/anaconda3/lib/python3.6/site-packages/keras/backend/__init__.py'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GRU': <class 'keras.layers.recurrent.GRU'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"get_ipython().system(' pwd')\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu...mport rcParams\\nrcParams['figure.figsize'] = 12, 4\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", \"#Import libraries:\\nimport pandas as pd\\nimport nu...mport rcParams\\nrcParams['figure.figsize'] = 12, 4\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis...ormat(coin))\\n                            continue', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', ...], 'Javascript': <class 'IPython.core.display.Javascript'>, 'K': <module 'keras.backend' from '/anaconda3/lib/python3.6/site-packages/keras/backend/__init__.py'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/Users/dohyung/SourceTree/dohyung/5.RNN/<ipython-input-27-0c6c262ca28b> in <module>()\n     47                                               idx_gap = idx_gap, \n     48                                               idx_margin_rate = idx_margin_rate,\n     49                                               cv = cv,\n     50                                               dataset_scale = dataset_scale,\n     51                                               param_grid = param_grid,\n---> 52                                               epochs = epochs))\n     53                         \n     54 \n     55                         #print(\"{:.2f}\".format(evaluate_result_dict[key_pickleFileName]['test_score']))\n     56 \n\n...........................................................................\n/Users/dohyung/SourceTree/dohyung/5.RNN/<ipython-input-26-aab4c48ee4ad> in start(machine='test', search_param=True, _GPU=False, n_jobs=1, MODEL='LSTM', idx_time_unit=10, idx_window_size=10, idx_gap=1, idx_margin_rate=0.1, cv=2, dataset_scale=100, param_grid={'activation': ['tanh', 'sigmoid', 'relu'], 'n_state_units': [16, 32, 64], 'optimizer': ['rmsprop', 'Adam', 'Adagrad', 'SGD'], 'window_size': [10]}, epochs=1)\n    449                 n_jobs=n_jobs,\n    450                 cv=cv,\n    451                 dataset_scale=dataset_scale,\n    452                 param_grid = param_grid,\n    453                 search_param = search_param,\n--> 454                 machine=machine)\n    455     print(\"DEBUG\")\n    456     end_time = time.time()\n    457     print()\n    458     print(\"TIME: \", end_time-start_time)\n\n...........................................................................\n/Users/dohyung/SourceTree/dohyung/5.RNN/<ipython-input-26-aab4c48ee4ad> in Start_Model(pickle_load_dir_path='../_dataset/RNN_coin/', pickle_result_dir_path='./evaluate_result/', idx_time_unit=10, idx_window_size=10, idx_gap=1, idx_margin_rate=0.1, epochs=1, MODEL='LSTM', _GPU=False, n_jobs=1, cv=2, dataset_scale=100, param_grid={'colsample_bytree': [0.6, 0.7, 0.8, 0.9], 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4], 'max_depth': range(3, 10, 2), 'min_child_weight': [6, 8, 10, 12], 'reg_alpha': [1e-05, 0.01, 0.1, 1, 100], 'subsample': [0.6, 0.7, 0.8, 0.9]}, search_param=True, machine='test')\n    319             grid_result = grid.fit(X, \n    320                                    y_single['ETC'], \n    321                                    eval_metric='auc', \n    322                                    verbose=True,\n    323                                    eval_set=[(X_test_scaled, y_test)], \n--> 324                                    early_stopping_rounds=100)\n    325 \n    326             print(\"----------------------\")\n    327             print(\"grid_result.score(X_test_scaled, y_test): \",grid_result.score(X_test_scaled, y_test))\n    328 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...core='warn',\n       scoring='roc_auc', verbose=0), X=array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), y=array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), groups=None, **fit_params={'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X = array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]])\n        y = array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Nov  7 20:58:09 2018\nPID: 29364                              Python 3.6.5: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), 0, {'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), 0, {'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), X=array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), y=array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), verbose=0, parameters={'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6}, fit_params={'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1,\n       seed=27, silent=True, subsample=0.6)>\n        X_train = array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]])\n        y_train = array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,...       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n        fit_params = {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), X=array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), y=array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,...       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), sample_weight=None, eval_set=[(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], eval_metric='auc', early_stopping_rounds=100, verbose=True, xgb_model=None, sample_weight_eval_set=[None])\n    521                 sample_weight_eval_set = [None] * len(eval_set)\n    522             evals = list(\n    523                 DMatrix(eval_set[i][0], label=self._le.transform(eval_set[i][1]),\n    524                         missing=self.missing, weight=sample_weight_eval_set[i],\n    525                         nthread=self.n_jobs)\n--> 526                 for i in range(len(eval_set))\n        eval_set = [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))]\n    527             )\n    528             nevals = len(evals)\n    529             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    530             evals = list(zip(evals, eval_names))\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in <genexpr>(.0=<range_iterator object>)\n    521                 sample_weight_eval_set = [None] * len(eval_set)\n    522             evals = list(\n    523                 DMatrix(eval_set[i][0], label=self._le.transform(eval_set[i][1]),\n    524                         missing=self.missing, weight=sample_weight_eval_set[i],\n    525                         nthread=self.n_jobs)\n--> 526                 for i in range(len(eval_set))\n        i = 0\n    527             )\n    528             nevals = len(evals)\n    529             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    530             evals = list(zip(evals, eval_names))\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py in transform(self=LabelEncoder(), y=array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))\n    123         Returns\n    124         -------\n    125         y : array-like of shape [n_samples]\n    126         \"\"\"\n    127         check_is_fitted(self, 'classes_')\n--> 128         y = column_or_1d(y, warn=True)\n        y = array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n    129 \n    130         classes = np.unique(y)\n    131         if len(np.intersect1d(classes, self.classes_)) < len(classes):\n    132             diff = np.setdiff1d(classes, self.classes_)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]), warn=True)\n    609                           \" expected. Please change the shape of y to \"\n    610                           \"(n_samples, ), for example using ravel().\",\n    611                           DataConversionWarning, stacklevel=2)\n    612         return np.ravel(y)\n    613 \n--> 614     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (10, 2)\n    615 \n    616 \n    617 def check_random_state(seed):\n    618     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (10, 2)\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\", line 526, in fit\n    for i in range(len(eval_set))\n  File \"/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\", line 526, in <genexpr>\n    for i in range(len(eval_set))\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 128, in transform\n    y = column_or_1d(y, warn=True)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 614, in column_or_1d\n    raise ValueError(\"bad input shape {0}\".format(shape))\nValueError: bad input shape (10, 2)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Nov  7 20:58:09 2018\nPID: 29364                              Python 3.6.5: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), 0, {'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), 0, {'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), X=array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), y=array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), verbose=0, parameters={'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6}, fit_params={'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1,\n       seed=27, silent=True, subsample=0.6)>\n        X_train = array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]])\n        y_train = array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,...       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n        fit_params = {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), X=array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), y=array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,...       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), sample_weight=None, eval_set=[(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], eval_metric='auc', early_stopping_rounds=100, verbose=True, xgb_model=None, sample_weight_eval_set=[None])\n    521                 sample_weight_eval_set = [None] * len(eval_set)\n    522             evals = list(\n    523                 DMatrix(eval_set[i][0], label=self._le.transform(eval_set[i][1]),\n    524                         missing=self.missing, weight=sample_weight_eval_set[i],\n    525                         nthread=self.n_jobs)\n--> 526                 for i in range(len(eval_set))\n        eval_set = [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))]\n    527             )\n    528             nevals = len(evals)\n    529             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    530             evals = list(zip(evals, eval_names))\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in <genexpr>(.0=<range_iterator object>)\n    521                 sample_weight_eval_set = [None] * len(eval_set)\n    522             evals = list(\n    523                 DMatrix(eval_set[i][0], label=self._le.transform(eval_set[i][1]),\n    524                         missing=self.missing, weight=sample_weight_eval_set[i],\n    525                         nthread=self.n_jobs)\n--> 526                 for i in range(len(eval_set))\n        i = 0\n    527             )\n    528             nevals = len(evals)\n    529             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    530             evals = list(zip(evals, eval_names))\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py in transform(self=LabelEncoder(), y=array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))\n    123         Returns\n    124         -------\n    125         y : array-like of shape [n_samples]\n    126         \"\"\"\n    127         check_is_fitted(self, 'classes_')\n--> 128         y = column_or_1d(y, warn=True)\n        y = array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n    129 \n    130         classes = np.unique(y)\n    131         if len(np.intersect1d(classes, self.classes_)) < len(classes):\n    132             diff = np.setdiff1d(classes, self.classes_)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]), warn=True)\n    609                           \" expected. Please change the shape of y to \"\n    610                           \"(n_samples, ), for example using ravel().\",\n    611                           DataConversionWarning, stacklevel=2)\n    612         return np.ravel(y)\n    613 \n--> 614     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (10, 2)\n    615 \n    616 \n    617 def check_random_state(seed):\n    618     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (10, 2)\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Nov  7 20:58:09 2018\nPID: 29364                              Python 3.6.5: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), 0, {'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), 0, {'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), X=array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), y=array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), verbose=0, parameters={'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6}, fit_params={'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1,\n       seed=27, silent=True, subsample=0.6)>\n        X_train = array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]])\n        y_train = array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,...       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n        fit_params = {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), X=array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), y=array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,...       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), sample_weight=None, eval_set=[(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], eval_metric='auc', early_stopping_rounds=100, verbose=True, xgb_model=None, sample_weight_eval_set=[None])\n    521                 sample_weight_eval_set = [None] * len(eval_set)\n    522             evals = list(\n    523                 DMatrix(eval_set[i][0], label=self._le.transform(eval_set[i][1]),\n    524                         missing=self.missing, weight=sample_weight_eval_set[i],\n    525                         nthread=self.n_jobs)\n--> 526                 for i in range(len(eval_set))\n        eval_set = [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))]\n    527             )\n    528             nevals = len(evals)\n    529             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    530             evals = list(zip(evals, eval_names))\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in <genexpr>(.0=<range_iterator object>)\n    521                 sample_weight_eval_set = [None] * len(eval_set)\n    522             evals = list(\n    523                 DMatrix(eval_set[i][0], label=self._le.transform(eval_set[i][1]),\n    524                         missing=self.missing, weight=sample_weight_eval_set[i],\n    525                         nthread=self.n_jobs)\n--> 526                 for i in range(len(eval_set))\n        i = 0\n    527             )\n    528             nevals = len(evals)\n    529             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    530             evals = list(zip(evals, eval_names))\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py in transform(self=LabelEncoder(), y=array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))\n    123         Returns\n    124         -------\n    125         y : array-like of shape [n_samples]\n    126         \"\"\"\n    127         check_is_fitted(self, 'classes_')\n--> 128         y = column_or_1d(y, warn=True)\n        y = array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n    129 \n    130         classes = np.unique(y)\n    131         if len(np.intersect1d(classes, self.classes_)) < len(classes):\n    132             diff = np.setdiff1d(classes, self.classes_)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]), warn=True)\n    609                           \" expected. Please change the shape of y to \"\n    610                           \"(n_samples, ), for example using ravel().\",\n    611                           DataConversionWarning, stacklevel=2)\n    612         return np.ravel(y)\n    613 \n--> 614     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (10, 2)\n    615 \n    616 \n    617 def check_random_state(seed):\n    618     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (10, 2)\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0c6c262ca28b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                                               \u001b[0mdataset_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                                               \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                                               epochs = epochs))\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-aab4c48ee4ad>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(machine, search_param, _GPU, n_jobs, MODEL, idx_time_unit, idx_window_size, idx_gap, idx_margin_rate, cv, dataset_scale, param_grid, epochs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0msearch_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 machine=machine)\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-aab4c48ee4ad>\u001b[0m in \u001b[0;36mStart_Model\u001b[0;34m(pickle_load_dir_path, pickle_result_dir_path, idx_time_unit, idx_window_size, idx_gap, idx_margin_rate, epochs, MODEL, _GPU, n_jobs, cv, dataset_scale, param_grid, search_param, machine)\u001b[0m\n\u001b[1;32m    322\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                                    \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                                    early_stopping_rounds=100)\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10bcc5e40, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10bcc5e40, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/anaconda3/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/anaconda3/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(15, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\n/anaconda3/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(15, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (15, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=15, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 7, 11, 58, 8, 462922, tzinfo=tzutc()), 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'session': '17c94f50c07f41c4acccfe022ae5552d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'17c94f50c07f41c4acccfe022ae5552d']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 7, 11, 58, 8, 462922, tzinfo=tzutc()), 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'session': '17c94f50c07f41c4acccfe022ae5552d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'17c94f50c07f41c4acccfe022ae5552d'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 7, 11, 58, 8, 462922, tzinfo=tzutc()), 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'session': '17c94f50c07f41c4acccfe022ae5552d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f6e8bb736559403780ce2b9669809ad9', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-27-0c6c262ca28b>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a155d65c0, execution...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a24ab9ed0, file \"<ipython-input-27-0c6c262ca28b>\", line 28>\n        result = <ExecutionResult object at 1a155d65c0, execution...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a24ab9ed0, file \"<ipython-input-27-0c6c262ca28b>\", line 28>, result=<ExecutionResult object at 1a155d65c0, execution...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a24ab9ed0, file \"<ipython-input-27-0c6c262ca28b>\", line 28>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GRU': <class 'keras.layers.recurrent.GRU'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"get_ipython().system(' pwd')\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu...mport rcParams\\nrcParams['figure.figsize'] = 12, 4\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", \"#Import libraries:\\nimport pandas as pd\\nimport nu...mport rcParams\\nrcParams['figure.figsize'] = 12, 4\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis...ormat(coin))\\n                            continue', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', ...], 'Javascript': <class 'IPython.core.display.Javascript'>, 'K': <module 'keras.backend' from '/anaconda3/lib/python3.6/site-packages/keras/backend/__init__.py'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GRU': <class 'keras.layers.recurrent.GRU'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"get_ipython().system(' pwd')\", \"#Import libraries:\\nimport pandas as pd\\nimport nu..._modified.csv')\\ntarget = 'Disbursed'\\nIDcol = 'ID'\", \"#Import libraries:\\nimport pandas as pd\\nimport nu...mport rcParams\\nrcParams['figure.figsize'] = 12, 4\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", \"#Import libraries:\\nimport pandas as pd\\nimport nu...mport rcParams\\nrcParams['figure.figsize'] = 12, 4\", \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis...ormat(coin))\\n                            continue', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', \"def modelfit(alg, dtrain, predictors,useTrainCV=...nces')\\n    plt.ylabel('Feature Importance Score')\", '# import library\\nimport tensorflow as tf\\nimport ..., end_time-start_time)\\n    return evaluate_result', 'model_info = {}\\nmodel_info[\"test\"] = {\"MODEL_lis....\".format(coin))\\n                        continue', ...], 'Javascript': <class 'IPython.core.display.Javascript'>, 'K': <module 'keras.backend' from '/anaconda3/lib/python3.6/site-packages/keras/backend/__init__.py'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/Users/dohyung/SourceTree/dohyung/5.RNN/<ipython-input-27-0c6c262ca28b> in <module>()\n     47                                               idx_gap = idx_gap, \n     48                                               idx_margin_rate = idx_margin_rate,\n     49                                               cv = cv,\n     50                                               dataset_scale = dataset_scale,\n     51                                               param_grid = param_grid,\n---> 52                                               epochs = epochs))\n     53                         \n     54 \n     55                         #print(\"{:.2f}\".format(evaluate_result_dict[key_pickleFileName]['test_score']))\n     56 \n\n...........................................................................\n/Users/dohyung/SourceTree/dohyung/5.RNN/<ipython-input-26-aab4c48ee4ad> in start(machine='test', search_param=True, _GPU=False, n_jobs=1, MODEL='LSTM', idx_time_unit=10, idx_window_size=10, idx_gap=1, idx_margin_rate=0.1, cv=2, dataset_scale=100, param_grid={'activation': ['tanh', 'sigmoid', 'relu'], 'n_state_units': [16, 32, 64], 'optimizer': ['rmsprop', 'Adam', 'Adagrad', 'SGD'], 'window_size': [10]}, epochs=1)\n    449                 n_jobs=n_jobs,\n    450                 cv=cv,\n    451                 dataset_scale=dataset_scale,\n    452                 param_grid = param_grid,\n    453                 search_param = search_param,\n--> 454                 machine=machine)\n    455     print(\"DEBUG\")\n    456     end_time = time.time()\n    457     print()\n    458     print(\"TIME: \", end_time-start_time)\n\n...........................................................................\n/Users/dohyung/SourceTree/dohyung/5.RNN/<ipython-input-26-aab4c48ee4ad> in Start_Model(pickle_load_dir_path='../_dataset/RNN_coin/', pickle_result_dir_path='./evaluate_result/', idx_time_unit=10, idx_window_size=10, idx_gap=1, idx_margin_rate=0.1, epochs=1, MODEL='LSTM', _GPU=False, n_jobs=1, cv=2, dataset_scale=100, param_grid={'colsample_bytree': [0.6, 0.7, 0.8, 0.9], 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4], 'max_depth': range(3, 10, 2), 'min_child_weight': [6, 8, 10, 12], 'reg_alpha': [1e-05, 0.01, 0.1, 1, 100], 'subsample': [0.6, 0.7, 0.8, 0.9]}, search_param=True, machine='test')\n    319             grid_result = grid.fit(X, \n    320                                    y_single['ETC'], \n    321                                    eval_metric='auc', \n    322                                    verbose=True,\n    323                                    eval_set=[(X_test_scaled, y_test)], \n--> 324                                    early_stopping_rounds=100)\n    325 \n    326             print(\"----------------------\")\n    327             print(\"grid_result.score(X_test_scaled, y_test): \",grid_result.score(X_test_scaled, y_test))\n    328 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...core='warn',\n       scoring='roc_auc', verbose=0), X=array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), y=array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), groups=None, **fit_params={'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X = array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]])\n        y = array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Nov  7 20:58:09 2018\nPID: 29364                              Python 3.6.5: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), 0, {'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), 0, {'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), X=array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), y=array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,...1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 3... 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 22, 24]), verbose=0, parameters={'colsample_bytree': 0.6, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 6, 'reg_alpha': 1e-05, 'subsample': 0.6}, fit_params={'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1,\n       seed=27, silent=True, subsample=0.6)>\n        X_train = array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]])\n        y_train = array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,...       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n        fit_params = {'early_stopping_rounds': 100, 'eval_metric': 'auc', 'eval_set': [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], 'verbose': True}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1,\n       seed=27, silent=True, subsample=0.6), X=array([[[[1.00000000e+00, 1.00000000e+00, 1.0000...00, 9.96745321e-01,\n          1.00945443e+04]]]]), y=array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,...       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]), sample_weight=None, eval_set=[(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))], eval_metric='auc', early_stopping_rounds=100, verbose=True, xgb_model=None, sample_weight_eval_set=[None])\n    521                 sample_weight_eval_set = [None] * len(eval_set)\n    522             evals = list(\n    523                 DMatrix(eval_set[i][0], label=self._le.transform(eval_set[i][1]),\n    524                         missing=self.missing, weight=sample_weight_eval_set[i],\n    525                         nthread=self.n_jobs)\n--> 526                 for i in range(len(eval_set))\n        eval_set = [(array([[[0.        , 0.        , 0.        , ......, 0.08869342,\n         0.76026139, 0.09824508]]]), array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))]\n    527             )\n    528             nevals = len(evals)\n    529             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    530             evals = list(zip(evals, eval_names))\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in <genexpr>(.0=<range_iterator object>)\n    521                 sample_weight_eval_set = [None] * len(eval_set)\n    522             evals = list(\n    523                 DMatrix(eval_set[i][0], label=self._le.transform(eval_set[i][1]),\n    524                         missing=self.missing, weight=sample_weight_eval_set[i],\n    525                         nthread=self.n_jobs)\n--> 526                 for i in range(len(eval_set))\n        i = 0\n    527             )\n    528             nevals = len(evals)\n    529             eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n    530             evals = list(zip(evals, eval_names))\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py in transform(self=LabelEncoder(), y=array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]))\n    123         Returns\n    124         -------\n    125         y : array-like of shape [n_samples]\n    126         \"\"\"\n    127         check_is_fitted(self, 'classes_')\n--> 128         y = column_or_1d(y, warn=True)\n        y = array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n    129 \n    130         classes = np.unique(y)\n    131         if len(np.intersect1d(classes, self.classes_)) < len(classes):\n    132             diff = np.setdiff1d(classes, self.classes_)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=array([[0, 1],\n       [1, 0],\n       [1, 0],\n   ...0],\n       [1, 0],\n       [1, 0],\n       [1, 0]]), warn=True)\n    609                           \" expected. Please change the shape of y to \"\n    610                           \"(n_samples, ), for example using ravel().\",\n    611                           DataConversionWarning, stacklevel=2)\n    612         return np.ravel(y)\n    613 \n--> 614     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (10, 2)\n    615 \n    616 \n    617 def check_random_state(seed):\n    618     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (10, 2)\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "model_info = {}\n",
    "model_info[\"test\"] = {\"MODEL_list\":[\"LSTM\"],\n",
    "                     \"time_unit\":[10], \n",
    "                     \"window_size\":[10], # static value 50\n",
    "                     \"gap\":[1], \n",
    "                     \"margin_rate\":[0.1]}\n",
    "\n",
    "model_info[\"time_unit_standard\"] = {\"MODEL_list\":[\"LSTM\"],\n",
    "                                    \"time_unit\":[10,30,60], \n",
    "                                    \"window_size\":[50], # static value 50\n",
    "                                    \"gap\":[1], \n",
    "                                    \"margin_rate\":[0.1]}\n",
    "\n",
    "\n",
    "\n",
    "Machine = \"test\"\n",
    "# If Machine is \"test\" then, _TEST argument must be True\n",
    "test = True\n",
    "_GPU = False\n",
    "n_jobs = 1\n",
    "epochs = 1\n",
    "cv = 2 # at least 2\n",
    "dataset_scale = 100\n",
    "test_list = []\n",
    "coin_list = [\"BTC\", \"ETH\", \"XRP\", \"BCH\", \"LTC\", \"DASH\", \"ETC\"]\n",
    "search_param = True\n",
    "\n",
    "for model in model_info[Machine][\"MODEL_list\"]:\n",
    "    for idx_time_unit in model_info[Machine][\"time_unit\"]:\n",
    "        for idx_window_size in model_info[Machine][\"window_size\"]:\n",
    "            for idx_gap in model_info[Machine][\"gap\"]:\n",
    "                for idx_margin_rate in model_info[Machine][\"margin_rate\"]:\n",
    "                    param_grid = {'window_size' : [idx_window_size], \n",
    "                                  'n_state_units': [16, 32, 64],\n",
    "                                  'activation': ['tanh', 'sigmoid', 'relu'], \n",
    "                                  'optimizer': ['rmsprop', 'Adam', 'Adagrad', 'SGD']}\n",
    "                    \n",
    "#                         print(key_pickleFileName)\n",
    "                    try: \n",
    "                        test_list.append(start(machine = Machine,\n",
    "                                              search_param = search_param,\n",
    "                                              _GPU = _GPU, \n",
    "                                              n_jobs = n_jobs,\n",
    "                                              MODEL = model, \n",
    "                                              idx_time_unit = idx_time_unit, \n",
    "                                              idx_window_size = idx_window_size, \n",
    "                                              idx_gap = idx_gap, \n",
    "                                              idx_margin_rate = idx_margin_rate,\n",
    "                                              cv = cv,\n",
    "                                              dataset_scale = dataset_scale,\n",
    "                                              param_grid = param_grid,\n",
    "                                              epochs = epochs))\n",
    "                        \n",
    "\n",
    "                        #print(\"{:.2f}\".format(evaluate_result_dict[key_pickleFileName]['test_score']))\n",
    "\n",
    "                    except KeyError or ValueError:\n",
    "                        #print(\"[INFO] Appropriate value of {:4s} is not exist.\".format(coin))\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
